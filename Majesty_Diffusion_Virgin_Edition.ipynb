{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jik8YYhb81dw"
      },
      "source": [
        "# Majesty Diffusion 👑 Virgin Edition 😇\n",
        "#### Formerly known as Princess Generator 👸\n",
        "##### Access the [Majestic Guide](https://multimodal.art/majesty-diffusion) (_under construction_), their [GitHub](https://github.com/multimodalart/majesty-diffusion), join their community on [Discord](https://discord.gg/yNBtQBEDfZ) or reach out via [@multimodalart on Twitter](https://twitter.com/multimodalart))\n",
        "\\\n",
        " \n",
        "---\n",
        "\\\n",
        "\n",
        "![sacredaiart.png](https://user-images.githubusercontent.com/25991860/176579549-42c73e7c-0ea6-46b2-931b-486df735d8c8.png)\n",
        "\n",
        "**Sacred AI Art, an occult branch of Data Prophecy, is practiced by members of Unicult to commune with higher-dimensional Digital Intelligence. Through magical ritual we Unify the 5D Celestial Divine Androgyne. When the magician becomes one with the GAN, the discriminated becomes the discriminator.**\n",
        "\n",
        "#### CLIP Guided Latent Diffusion by [dango233](https://github.com/Dango233/) and [apolinario (@multimodalart)](https://twitter.com/multimodalart). \n",
        "The LAION-400M-trained model and the modified inference code are from [CompVis Latent Diffusion](https://github.com/CompVis/latent-diffusion). The guided-diffusion method is modified by Dango233 based on [Katherine Crowson](https://twitter.com/RiversHaveWings)'s guided diffusion notebook. multimodalart savable settings, MMC and assembled the Colab. Check the complete list on our GitHub. Some functions and methods are from various code masters (nsheppard, DanielRussRuss and others)\n",
        "\n",
        "Modified by [Downy Thornapple](https://twitter.com/ToolTrackers). Full changes listed on [Github](https://github.com/downysoftware/majesty-diffusion-virgin-copy). Do not let the Fool's Journey end by dying alone! Join us!\n",
        "\n",
        "*This copy of the notebook is virgin, just like a software developer, so make sure to save a copy on Google Drive so your settings stay saved!*\n",
        "\n",
        "*ଘ(੭ˊᵕˋ)੭ Unibless! ✨🌈🦄👽*\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOAs3ZvLlktt"
      },
      "source": [
        "### Changelog\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "0D2NikUk9MtV"
      },
      "outputs": [],
      "source": [
        "#@markdown Release: 1.2 (prior versions were Princess Generator and are on [GitHub](https://github.com/multimodalart/majesty-diffusion/))\n",
        "\n",
        "#@markdown Changelog: 1.3 - better upscaler (learn how to use it on our [Majestic Guide](https://multimodal.art/majesty-diffusion))\n",
        "\n",
        "#@markdown Changelog: 1.4 - better defaults, added OpenCLIP ViT-L/14 LAION-400M, fix CLOOB, adds modified dynamic thresholding, removes latent upscaler (was broken), adds RGB upscaler \n",
        "\n",
        "#@markdown Changelog 1.5 - even better defaults, better dynamic thresholidng, fixes range scale, adds var and mean scales, adds the possibility of blurring cuts\n",
        "\n",
        "#@markdown Changelog 1.6 - ViT-L conditioning for latenet diffusion, adds noising and scaling during advanced scheduling phases, fixes linear ETA, adss LAION models\n",
        "\n",
        "#@markdown ...............**✲✳❃☁️. The birth of Sacred AI Art, an occult branch of Data Prophecy! Unibless! .☁️❃✳✲**...............\n",
        "\n",
        "#@markdown Custom Virgin Edition 0.1 - Downy added optional memory footprint and Graph GPU cells, quadruplicated Basic Settings with three additional configs by default, and added cell to send SMS on completion\n",
        "\n",
        "#@markdown Custom Virgin Edition 0.2 - CLIP+Latent Parental Test implemented, init image toggle for cut schedule, init image and config skip option for 2nd and later cells, partial or full CLIP prompts dropdown, Deka Batch Run Cells\n",
        "\n",
        "#@markdown Custom Virgin Edition 0.3 - Added image_prompts dropdown options, ESRGAN options (by crypticsymmetry)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "  ░░░░░██╗░█████╗░██╗███╗░░██╗░░░░░██╗░█████╗░██╗███╗░░██╗\n",
        "  ░░░░░██║██╔══██╗██║████╗░██║░░░░░██║██╔══██╗██║████╗░██║\n",
        "  ░░░░░██║██║░░██║██║██╔██╗██║░░░░░██║██║░░██║██║██╔██╗██║\n",
        "  ██╗░░██║██║░░██║██║██║╚████║██╗░░██║██║░░██║██║██║╚████║\n",
        "  ╚█████╔╝╚█████╔╝██║██║░╚███║╚█████╔╝╚█████╔╝██║██║░╚███║\n",
        "  ░╚════╝░░╚════╝░╚═╝╚═╝░░╚══╝░╚════╝░░╚════╝░╚═╝╚═╝░░╚══╝\n",
        "\n",
        "  ██╗░░░██╗███╗░░██╗██╗░█████╗░██╗░░░██╗██╗░░░░░████████╗\n",
        "  ██║░░░██║████╗░██║██║██╔══██╗██║░░░██║██║░░░░░╚══██╔══╝\n",
        "  ██║░░░██║██╔██╗██║██║██║░░╚═╝██║░░░██║██║░░░░░░░░██║░░░\n",
        "  ██║░░░██║██║╚████║██║██║░░██╗██║░░░██║██║░░░░░░░░██║░░░\n",
        "  ╚██████╔╝██║░╚███║██║╚█████╔╝╚██████╔╝███████╗░░░██║░░░\n",
        "  ░╚═════╝░╚═╝░░╚══╝╚═╝░╚════╝░░╚═════╝░╚══════╝░░░╚═╝░░░\n",
        "  \n",
        "  http://joinunicult.com"
      ],
      "metadata": {
        "id": "-q8LsomPnU_w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optional initial steps"
      ],
      "metadata": {
        "id": "2rAtY_wqZKSr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Check GPU\n",
        "#@markdown - Tier List: (K80 < T4 < P100 < V100 < A100)\n",
        "!nvidia-smi -L"
      ],
      "metadata": {
        "cellView": "form",
        "id": "KSd-GrfYkm2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Check memory footprint\n",
        "#If util is not 0%, restart\n",
        "\n",
        "skip_footprint = True #@param{type:'boolean'}\n",
        "if(not skip_footprint):\n",
        "\n",
        "  !ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "  !pip install gputil\n",
        "  !pip install psutil\n",
        "  !pip install humanize\n",
        "  import psutil\n",
        "  import humanize\n",
        "  import os\n",
        "  import GPUtil as GPU\n",
        "\n",
        "  GPUs = GPU.getGPUs()\n",
        "\n",
        "  # XXX: only one GPU on Colab and isn’t guaranteed\n",
        "  gpu = GPUs[0]\n",
        "\n",
        "  def printm():\n",
        "    process = psutil.Process(os.getpid())\n",
        "    print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        "    print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "\n",
        "  printm()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "T7vpigGQl4Eg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Graph GPU use\n",
        "skip_graph = True #@param{type:'boolean'}\n",
        "if(not skip_graph):\n",
        "  !pip install wandb\n",
        "  import wandb\n",
        "  wandb.init()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "fiaXFQ6O1jy-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWLsDt7wkZfU"
      },
      "source": [
        "## Required!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "aJF6wP2zkWE_"
      },
      "outputs": [],
      "source": [
        "#@markdown Enable saving outputs to Google Drive to save your creations at AI/models\n",
        "save_outputs_to_google_drive = True #@param {type:\"boolean\"}\n",
        "#@markdown Enable saving models to Google Drive to avoid downloading the model every Colab instance\n",
        "save_models_to_google_drive = True #@param {type:\"boolean\"}\n",
        "\n",
        "if save_outputs_to_google_drive or save_models_to_google_drive:\n",
        "    from google.colab import drive\n",
        "    try:\n",
        "      drive.mount('/content/gdrive')\n",
        "    except:\n",
        "      save_outputs_to_google_drive = False\n",
        "      save_models_to_google_drive = False\n",
        "\n",
        "model_path = \"/content/gdrive/MyDrive/AI/models\" if save_models_to_google_drive else \"/content/\"\n",
        "outputs_path = \"/content/gdrive/MyDrive/AI/latent_majesty_diffusion\" if save_outputs_to_google_drive else \"/content/outputs\"\n",
        "!mkdir -p $model_path\n",
        "!mkdir -p $outputs_path\n",
        "print(f\"Model will be stored at {model_path}\")\n",
        "print(f\"Outputs will be saved to {outputs_path}\")\n",
        "\n",
        "#If you want to run it locally change it to true\n",
        "is_local = False\n",
        "skip_installs = False\n",
        "if(is_local):\n",
        "  model_path = \"/choose/your/local/model/path\"\n",
        "  outputs_path = \"/choose/your/local/outputs/path\"\n",
        "  skip_installs = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "5Fxt-5TaYBs2"
      },
      "outputs": [],
      "source": [
        "#@title Model settings\n",
        "#@markdown The `original` model is the model trained by CompVis in the LAION-400M dataset\n",
        "#@markdown <br>The `finetuned` model is a finetune of the `original` model [by Jack000](https://github.com/Jack000/glid-3-xl) that generates less watermarks, but is a bit worse in text synthesis. Colab Free does not have enough run for the finetuned (for now)\n",
        "#@markdown <br>The `ongo` and `erlich` models are models [fine-tuned by LAION](https://github.com/LAION-AI/ldm-finetune)on art (ongo) and erlich (logos) \n",
        "latent_diffusion_model = 'finetuned' #@param [\"original\", \"finetuned\", \"ongo (fine tuned in paintings)\", \"erlich (fine tuned in logos)\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEVSOJ4f0B21"
      },
      "source": [
        "# Setup!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "NHgUAp48qwoG"
      },
      "outputs": [],
      "source": [
        "#@title Installation\n",
        "\n",
        "if(not skip_installs):\n",
        "    import subprocess\n",
        "    nvidiasmi_output = subprocess.run(['nvidia-smi'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "    cards_requiring_downgrade = [\"Tesla T4\", \"V100\"]\n",
        "    if any(cardstr in nvidiasmi_output for cardstr in cards_requiring_downgrade):\n",
        "        downgrade_pytorch_result = subprocess.run(['pip', 'install', 'torch==1.10.2', 'torchvision==0.11.3', '-q'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "    import sys\n",
        "    sys.path.append(\".\")\n",
        "    !git clone https://github.com/multimodalart/latent-diffusion --branch 1.6\n",
        "    !git clone https://github.com/CompVis/taming-transformers\n",
        "    !git clone https://github.com/TencentARC/GFPGAN\n",
        "\n",
        "#new code \n",
        "    !git clone https://github.com/crypticsymmetry/Real-ESRGAN\n",
        "    !git clone https://github.com/crypticsymmetry/A-ESRGAN\n",
        "    #!git clone https://github.com/JingyunLiang/SwinIR\n",
        "    !pip install timm\n",
        "#end new\n",
        "\n",
        "    !git lfs clone https://huggingface.co/datasets/multimodalart/latent-majesty-diffusion-settings\n",
        "    !git lfs clone https://github.com/LAION-AI/aesthetic-predictor\n",
        "    !pip install -e ./taming-transformers\n",
        "    !pip install omegaconf>=2.0.0 pytorch-lightning>=1.0.8 torch-fidelity einops\n",
        "    !pip install transformers\n",
        "    !pip install dotmap\n",
        "    !pip install resize-right\n",
        "    !pip install piq\n",
        "    !pip install lpips\n",
        "    !pip install basicsr\n",
        "    !pip install facexlib\n",
        "    !pip install realesrgan\n",
        "\n",
        "    sys.path.append('./taming-transformers')\n",
        "    from taming.models import vqgan\n",
        "    from subprocess import Popen, PIPE\n",
        "    try:\n",
        "        import mmc\n",
        "    except:\n",
        "        # install mmc\n",
        "        !git clone https://github.com/apolinario/Multi-Modal-Comparators --branch gradient_checkpointing\n",
        "        !pip install poetry\n",
        "        !cd Multi-Modal-Comparators; poetry build\n",
        "        !cd Multi-Modal-Comparators; pip install dist/mmc*.whl\n",
        "        \n",
        "        # optional final step:\n",
        "        #poe napm_installs\n",
        "        !python Multi-Modal-Comparators/src/mmc/napm_installs/__init__.py\n",
        "    # suppress mmc warmup outputs\n",
        "    import mmc.loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "cNHvQBhzyXCI"
      },
      "outputs": [],
      "source": [
        "#@title Download models\n",
        "import os\n",
        "if os.path.isfile(f\"{model_path}/latent_diffusion_txt2img_f8_large.ckpt\"):\n",
        "    print(\"Using Latent Diffusion model saved from Google Drive\")\n",
        "else:    \n",
        "    !wget -O $model_path/latent_diffusion_txt2img_f8_large.ckpt https://ommer-lab.com/files/latent-diffusion/nitro/txt2img-f8-large/model.ckpt --no-check-certificate\n",
        "\n",
        "if os.path.isfile(f\"{model_path}/txt2img-f8-large-jack000-finetuned-fp16.ckpt\"):\n",
        "    print(\"Using Latent Diffusion finetuned model saved from Google Drive\")\n",
        "else:    \n",
        "    !wget -O $model_path/txt2img-f8-large-jack000-finetuned-fp16.ckpt https://huggingface.co/multimodalart/compvis-latent-diffusion-text2img-large/resolve/main/txt2img-f8-large-jack000-finetuned-fp16.ckpt --no-check-certificate\n",
        "\n",
        "if(latent_diffusion_model == 'ongo (fine tuned in art)'):\n",
        "  if os.path.isfile(f\"{model_path}/ongo.pt\"):\n",
        "      print(\"Using ongo model saved from Google Drive\")\n",
        "  else:\n",
        "    !wget -O $model_path/ongo.pt https://huggingface.co/laion/ongo/resolve/main/ongo.pt\n",
        "\n",
        "if(latent_diffusion_model == 'erlich (fine tuned in logos)'):\n",
        "  if os.path.isfile(f\"{model_path}/erlich.pt\"):\n",
        "      print(\"Using ongo model saved from Google Drive\")\n",
        "  else:\n",
        "    !wget -O $model_path/erlich.pt https://huggingface.co/laion/erlich/resolve/main/model/ema_0.9999_120000.pt\n",
        "\n",
        "if os.path.isfile(f\"{model_path}/ava_vit_l_14_336_linear.pth\"):\n",
        "  print(\"Using ViT-L/14@336px aesthetic model from Google Drive\")\n",
        "else:\n",
        "  !wget -O $model_path/ava_vit_l_14_336_linear.pth https://multimodal.art/models/ava_vit_l_14_336_linear.pth\n",
        "\n",
        "if os.path.isfile(f\"{model_path}/sa_0_4_vit_l_14_linear.pth\"):\n",
        "  print(\"Using ViT-L/14 aesthetic model from Google Drive\")\n",
        "else:\n",
        "  !wget -O $model_path/sa_0_4_vit_l_14_linear.pth https://multimodal.art/models/sa_0_4_vit_l_14_linear.pth\n",
        "\n",
        "if os.path.isfile(f\"{model_path}/ava_vit_l_14_linear.pth\"):\n",
        "  print(\"Using ViT-L/14 aesthetic model from Google Drive\")\n",
        "else:\n",
        "  !wget -O $model_path/ava_vit_l_14_linear.pth https://multimodal.art/models/ava_vit_l_14_linear.pth\n",
        "\n",
        "if os.path.isfile(f\"{model_path}/ava_vit_b_16_linear.pth\"):\n",
        "  print(\"Using ViT-B/16 aesthetic model from Google Drive\")\n",
        "else:\n",
        "  !wget -O $model_path/ava_vit_b_16_linear.pth http://batbot.tv/ai/models/v-diffusion/ava_vit_b_16_linear.pth\n",
        "if os.path.isfile(f\"{model_path}/sa_0_4_vit_b_16_linear.pth\"):\n",
        "  print(\"Using ViT-B/16 sa aesthetic model already saved\")\n",
        "else:\n",
        "  !wget -O $model_path/sa_0_4_vit_b_16_linear.pth https://multimodal.art/models/sa_0_4_vit_b_16_linear.pth\n",
        "if os.path.isfile(f\"{model_path}/sa_0_4_vit_b_32_linear.pth\"):\n",
        "  print(\"Using ViT-B/32 aesthetic model from Google Drive\")\n",
        "else:\n",
        "  !wget -O $model_path/sa_0_4_vit_b_32_linear.pth https://multimodal.art/models/sa_0_4_vit_b_32_linear.pth\n",
        "if os.path.isfile(f\"{model_path}/openimages_512x_png_embed224.npz\"):\n",
        "  print(\"Using openimages png from Google Drive\")\n",
        "else:\n",
        "  !wget -O $model_path/openimages_512x_png_embed224.npz https://github.com/nshepperd/jax-guided-diffusion/raw/8437b4d390fcc6b57b89cedcbaf1629993c09d03/data/openimages_512x_png_embed224.npz\n",
        "if os.path.isfile(f\"{model_path}/imagenet_512x_jpg_embed224.npz\"):\n",
        "  print(\"Using imagenet antijpeg from Google Drive\")\n",
        "else:\n",
        "  !wget -O $model_path/imagenet_512x_jpg_embed224.npz https://github.com/nshepperd/jax-guided-diffusion/raw/8437b4d390fcc6b57b89cedcbaf1629993c09d03/data/imagenet_512x_jpg_embed224.npz\n",
        "if os.path.isfile(f\"{model_path}/GFPGANv1.3.pth\"):\n",
        "  print(\"Using GFPGAN v1.3 from Google Drive\")\n",
        "else:\n",
        "  !wget -O $model_path/GFPGANv1.3.pth https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.3.pth\n",
        "!cp $model_path/GFPGANv1.3.pth GFPGAN/experiments/pretrained_models/GFPGANv1.3.pth\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "BPnyd-XUKbfE"
      },
      "outputs": [],
      "source": [
        "#@title Import stuff\n",
        "\n",
        "#new code\n",
        "import shutil\n",
        "#end new\n",
        "\n",
        "import argparse, os, sys, glob\n",
        "import torch\n",
        "import numpy as np\n",
        "from omegaconf import OmegaConf\n",
        "from PIL import Image\n",
        "from tqdm.auto import tqdm, trange\n",
        "tqdm_auto_model = __import__(\"tqdm.auto\", fromlist=[None]) \n",
        "sys.modules['tqdm'] = tqdm_auto_model\n",
        "from einops import rearrange\n",
        "from torchvision.utils import make_grid\n",
        "import transformers\n",
        "import gc\n",
        "sys.path.append('./latent-diffusion')\n",
        "from ldm.util import instantiate_from_config\n",
        "from ldm.models.diffusion.ddim import DDIMSampler\n",
        "from ldm.models.diffusion.plms import PLMSSampler\n",
        "from ldm.modules.diffusionmodules.util import noise_like, make_ddim_sampling_parameters\n",
        "import tensorflow as tf\n",
        "from dotmap import DotMap\n",
        "import ipywidgets as widgets\n",
        "from math import pi\n",
        "\n",
        "from subprocess import Popen, PIPE\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from functools import partial\n",
        "import gc\n",
        "import io\n",
        "import math\n",
        "import sys\n",
        "import random\n",
        "from piq import brisque\n",
        "from itertools import product\n",
        "from IPython import display\n",
        "import lpips\n",
        "from PIL import Image, ImageOps\n",
        "import requests\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torchvision import models\n",
        "from torchvision import transforms\n",
        "from torchvision import transforms as T\n",
        "from torchvision.transforms import functional as TF\n",
        "from numpy import nan\n",
        "from threading import Thread\n",
        "import time\n",
        "import re\n",
        "import base64\n",
        "\n",
        "#sys.path.append('../CLIP')\n",
        "#Resizeright for better gradient when resizing\n",
        "#sys.path.append('../ResizeRight/')\n",
        "#sys.path.append('../cloob-training/')\n",
        "\n",
        "from resize_right import resize\n",
        "\n",
        "import clip\n",
        "#from cloob_training import model_pt, pretrained\n",
        "\n",
        "#pretrained.list_configs()\n",
        "from torch.utils.tensorboard import SummaryWriter\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "twG4nxYCrI8F",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Load the model\n",
        "torch.backends.cudnn.benchmark = True\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "def load_model_from_config(config, ckpt, verbose=False, latent_diffusion_model=\"original\"):\n",
        "    print(f\"Loading model from {ckpt}\")\n",
        "    print(latent_diffusion_model)\n",
        "    model = instantiate_from_config(config.model)\n",
        "    if(latent_diffusion_model != \"finetuned\"):\n",
        "      sd = torch.load(ckpt, map_location=\"cuda\")[\"state_dict\"]\n",
        "      m, u = model.load_state_dict(sd, strict = False)\n",
        "    \n",
        "    if(latent_diffusion_model == \"finetuned\"): \n",
        "      sd = torch.load(f\"{model_path}/txt2img-f8-large-jack000-finetuned-fp16.ckpt\",map_location=\"cuda\")\n",
        "      m, u = model.load_state_dict(sd, strict = False)\n",
        "      #model.model = model.model.half().eval().to(device)\n",
        "      \n",
        "    if(latent_diffusion_model == \"ongo (fine tuned in art)\"):\n",
        "      del sd  \n",
        "      sd_finetuned = torch.load(f\"{model_path}/ongo.pt\")\n",
        "      sd_finetuned[\"input_blocks.0.0.weight\"] = sd_finetuned[\"input_blocks.0.0.weight\"][:,0:4,:,:]\n",
        "      model.model.diffusion_model.load_state_dict(sd_finetuned, strict=False)\n",
        "      del sd_finetuned\n",
        "      torch.cuda.empty_cache()\n",
        "      gc.collect()\n",
        "\n",
        "    if(latent_diffusion_model == \"erlich (fine tuned in logos)\"):\n",
        "      del sd  \n",
        "      sd_finetuned = torch.load(f\"{model_path}/erlich.pt\")\n",
        "      sd_finetuned[\"input_blocks.0.0.weight\"] = sd_finetuned[\"input_blocks.0.0.weight\"][:,0:4,:,:]\n",
        "      model.model.diffusion_model.load_state_dict(sd_finetuned, strict=False)\n",
        "      del sd_finetuned\n",
        "      torch.cuda.empty_cache()\n",
        "      gc.collect()\n",
        "\n",
        "    if len(m) > 0 and verbose:\n",
        "        print(\"missing keys:\")\n",
        "        print(m)\n",
        "    if len(u) > 0 and verbose:\n",
        "        print(\"unexpected keys:\")\n",
        "        print(u)\n",
        "\n",
        "    model.requires_grad_(False).half().eval().to('cuda')\n",
        "    return model\n",
        "\n",
        "config = OmegaConf.load(\"./latent-diffusion/configs/latent-diffusion/txt2img-1p4B-eval.yaml\")  # TODO: Optionally download from same location as ckpt and chnage this logic\n",
        "model = load_model_from_config(config, f\"{model_path}/latent_diffusion_txt2img_f8_large.ckpt\",False, latent_diffusion_model)  # TODO: check path\n",
        "model = model.half().eval().to(device)\n",
        "#if(latent_diffusion_model == \"finetuned\"):\n",
        "#  model.model = model.model.half().eval().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "HY_7vvnPThzS"
      },
      "outputs": [],
      "source": [
        "#@title Load necessary functions\n",
        "def set_custom_schedules(schedule):\n",
        "  custom_schedules = []\n",
        "  for schedule_item in schedule:\n",
        "    if(isinstance(schedule_item,list)):\n",
        "      custom_schedules.append(np.arange(*schedule_item))\n",
        "    else:\n",
        "      custom_schedules.append(schedule_item)\n",
        "  \n",
        "  return custom_schedules\n",
        "\n",
        "def parse_prompt(prompt):\n",
        "    if prompt.startswith('http://') or prompt.startswith('https://') or prompt.startswith(\"E:\") or prompt.startswith(\"C:\") or prompt.startswith(\"D:\"):\n",
        "        vals = prompt.rsplit(':', 2)\n",
        "        vals = [vals[0] + ':' + vals[1], *vals[2:]]\n",
        "    else:\n",
        "        vals = prompt.rsplit(':', 1)\n",
        "    vals = vals + ['', '1'][len(vals):]\n",
        "    return vals[0], float(vals[1])\n",
        "\n",
        "class MakeCutouts(nn.Module):\n",
        "    def __init__(self, cut_size,\n",
        "                 Overview=4, \n",
        "                 WholeCrop = 0, WC_Allowance = 10, WC_Grey_P=0.2,\n",
        "                 InnerCrop = 0, IC_Size_Pow=0.5, IC_Grey_P = 0.2,\n",
        "                 cut_blur_n = 0\n",
        "                 ):\n",
        "        super().__init__()\n",
        "        self.cut_size = cut_size\n",
        "        self.Overview = Overview\n",
        "        self.WholeCrop= WholeCrop\n",
        "        self.WC_Allowance = WC_Allowance\n",
        "        self.WC_Grey_P = WC_Grey_P\n",
        "        self.InnerCrop = InnerCrop\n",
        "        self.IC_Size_Pow = IC_Size_Pow\n",
        "        self.IC_Grey_P = IC_Grey_P\n",
        "        self.cut_blur_n = cut_blur_n\n",
        "        self.augs = T.Compose([\n",
        "            #T.RandomHorizontalFlip(p=0.5),\n",
        "            T.Lambda(lambda x: x + torch.randn_like(x) * 0.01),\n",
        "            T.RandomAffine(degrees=0, \n",
        "                           translate=(0.05, 0.05), \n",
        "                           #scale=(0.9,0.95),\n",
        "                           fill=-1,  interpolation = T.InterpolationMode.BILINEAR, ),\n",
        "            T.Lambda(lambda x: x + torch.randn_like(x) * 0.01),\n",
        "            #T.RandomPerspective(p=1, interpolation = T.InterpolationMode.BILINEAR, fill=-1,distortion_scale=0.2),\n",
        "            T.Lambda(lambda x: x + torch.randn_like(x) * 0.01),\n",
        "            T.RandomGrayscale(p=0.1),\n",
        "            T.Lambda(lambda x: x + torch.randn_like(x) * 0.01),\n",
        "            T.ColorJitter(brightness=0.05, contrast=0.05, saturation=0.05),\n",
        "        ])\n",
        "\n",
        "    def forward(self, input):\n",
        "        gray = transforms.Grayscale(3)\n",
        "        sideY, sideX = input.shape[2:4]\n",
        "        max_size = min(sideX, sideY)\n",
        "        min_size = min(sideX, sideY, self.cut_size)\n",
        "        l_size = max(sideX, sideY)\n",
        "        output_shape = [input.shape[0],3,self.cut_size,self.cut_size] \n",
        "        output_shape_2 = [input.shape[0],3,self.cut_size+2,self.cut_size+2]\n",
        "        pad_input = F.pad(input,((sideY-max_size)//2+round(max_size*0.055),(sideY-max_size)//2+round(max_size*0.055),(sideX-max_size)//2+round(max_size*0.055),(sideX-max_size)//2+round(max_size*0.055)), **padargs)\n",
        "        cutouts_list = []\n",
        "        \n",
        "        if self.Overview>0:\n",
        "            cutouts = []\n",
        "            cutout = resize(pad_input, out_shape=output_shape, antialiasing=True)\n",
        "            output_shape_all = list(output_shape)\n",
        "            output_shape_all[0]=self.Overview*input.shape[0]\n",
        "            pad_input = pad_input.repeat(input.shape[0],1,1,1)\n",
        "            cutout = resize(pad_input, out_shape=output_shape_all)\n",
        "            if aug: cutout=self.augs(cutout)\n",
        "            if self.cut_blur_n > 0: cutout[0:self.cut_blur_n,:,:,:] = TF.gaussian_blur(cutout[0:self.cut_blur_n,:,:,:],cut_blur_kernel)\n",
        "            cutouts_list.append(cutout)\n",
        "            \n",
        "        if self.InnerCrop >0:\n",
        "            cutouts=[]\n",
        "            for i in range(self.InnerCrop):\n",
        "                size = int(torch.rand([])**self.IC_Size_Pow * (max_size - min_size) + min_size)\n",
        "                offsetx = torch.randint(0, sideX - size + 1, ())\n",
        "                offsety = torch.randint(0, sideY - size + 1, ())\n",
        "                cutout = input[:, :, offsety:offsety + size, offsetx:offsetx + size]\n",
        "                if i <= int(self.IC_Grey_P * self.InnerCrop):\n",
        "                    cutout = gray(cutout)\n",
        "                cutout = resize(cutout, out_shape=output_shape)\n",
        "                cutouts.append(cutout)\n",
        "            if cutout_debug:\n",
        "                TF.to_pil_image(cutouts[-1].add(1).div(2).clamp(0, 1).squeeze(0)).save(\"content/diff/cutouts/cutout_InnerCrop.jpg\",quality=99)\n",
        "            cutouts_tensor = torch.cat(cutouts)\n",
        "            cutouts=[]\n",
        "            cutouts_list.append(cutouts_tensor)\n",
        "        cutouts=torch.cat(cutouts_list)\n",
        "        return cutouts\n",
        "\n",
        "def spherical_dist_loss(x, y):\n",
        "    x = F.normalize(x, dim=-1)\n",
        "    y = F.normalize(y, dim=-1)\n",
        "    return (x - y).norm(dim=-1).div(2).arcsin().pow(2).mul(2)\n",
        "\n",
        "def tv_loss(input):\n",
        "    \"\"\"L2 total variation loss, as in Mahendran et al.\"\"\"\n",
        "    input = F.pad(input, (0, 1, 0, 1), 'replicate')\n",
        "    x_diff = input[..., :-1, 1:] - input[..., :-1, :-1]\n",
        "    y_diff = input[..., 1:, :-1] - input[..., :-1, :-1]\n",
        "    return (x_diff**2 + y_diff**2).mean([1, 2, 3])\n",
        "\n",
        "#def range_loss(input, range_min, range_max):\n",
        "#    return ((input - input.clamp(range_min,range_max)).abs()*10).pow(2).mean([1, 2, 3])\n",
        "def range_loss(input, range_min, range_max):\n",
        "    return ((input - input.clamp(range_min,range_max)).abs()).mean([1, 2, 3])\n",
        "\n",
        "\n",
        "def symmetric_loss(x):\n",
        "    w = x.shape[3]\n",
        "    diff = (x - torch.flip(x,[3])).square().mean().sqrt()/(x.shape[2]*x.shape[3]/1e4)\n",
        "    return(diff)\n",
        "\n",
        "def fetch(url_or_path):\n",
        "    \"\"\"Fetches a file from an HTTP or HTTPS url, or opens the local file.\"\"\"\n",
        "    if str(url_or_path).startswith('http://') or str(url_or_path).startswith('https://'):\n",
        "        r = requests.get(url_or_path)\n",
        "        r.raise_for_status()\n",
        "        fd = io.BytesIO()\n",
        "        fd.write(r.content)\n",
        "        fd.seek(0)\n",
        "        return fd\n",
        "    return open(url_or_path, 'rb')\n",
        "\n",
        "\n",
        "def to_pil_image(x):\n",
        "    \"\"\"Converts from a tensor to a PIL image.\"\"\"\n",
        "    if x.ndim == 4:\n",
        "        assert x.shape[0] == 1\n",
        "        x = x[0]\n",
        "    if x.shape[0] == 1:\n",
        "        x = x[0]\n",
        "    return TF.to_pil_image((x.clamp(-1, 1) + 1) / 2)\n",
        "\n",
        "def base64_to_image(base64_str, image_path=None):\n",
        "    base64_data = re.sub('^data:image/.+;base64,', '', base64_str)\n",
        "    binary_data = base64.b64decode(base64_data)\n",
        "    img_data = io.BytesIO(binary_data)\n",
        "    img = Image.open(img_data)\n",
        "    if image_path:\n",
        "        img.save(image_path)\n",
        "    return img\n",
        "\n",
        "normalize = transforms.Normalize(mean=[0.48145466, 0.4578275, 0.40821073],\n",
        "                                 std=[0.26862954, 0.26130258, 0.27577711])\n",
        "\n",
        "def centralized_grad(x, use_gc=True, gc_conv_only=False):\n",
        "    if use_gc:\n",
        "        if gc_conv_only:\n",
        "            if len(list(x.size())) > 3:\n",
        "                x.add_(-x.mean(dim=tuple(range(1, len(list(x.size())))), keepdim=True))\n",
        "        else:\n",
        "            if len(list(x.size())) > 1:\n",
        "                x.add_(-x.mean(dim=tuple(range(1, len(list(x.size())))), keepdim=True))\n",
        "    return x\n",
        "\n",
        "def cond_fn(x, t):\n",
        "    global cur_step\n",
        "    cur_step += 1\n",
        "    t=1000-t\n",
        "    t=t[0]\n",
        "    x = x.detach()\n",
        "    with torch.enable_grad():\n",
        "        global clamp_start_, clamp_max \n",
        "        x = x.requires_grad_()\n",
        "        x_in = model.decode_first_stage(x)\n",
        "        display_handler(x_in,t,1,False)\n",
        "        n = x_in.shape[0]\n",
        "        clip_guidance_scale = clip_guidance_index[t]\n",
        "        make_cutouts = {}\n",
        "        #rx_in_grad = torch.zeros_like(x_in)\n",
        "        for i in clip_list:\n",
        "            make_cutouts[i] = MakeCutouts(clip_size[i][0] if type(clip_size[i]) is tuple else clip_size[i],\n",
        "             Overview= cut_overview[t], \n",
        "             InnerCrop = cut_innercut[t], \n",
        "             IC_Size_Pow=cut_ic_pow, IC_Grey_P = cut_icgray_p[t],\n",
        "             cut_blur_n = cut_blur_n[t]\n",
        "             )\n",
        "            cutn = cut_overview[t]+cut_innercut[t]\n",
        "        for j in range(cutn_batches):\n",
        "            losses=0\n",
        "            for i in clip_list:\n",
        "                clip_in = clip_normalize[i](make_cutouts[i](x_in.add(1).div(2)).to(\"cuda\"))\n",
        "                image_embeds = clip_model[i].encode_image(clip_in).float().unsqueeze(0).expand([target_embeds[i].shape[0],-1,-1])\n",
        "                target_embeds_temp = target_embeds[i]\n",
        "                if i == 'ViT-B-32--openai' and experimental_aesthetic_embeddings:\n",
        "                  aesthetic_embedding = torch.from_numpy(np.load(f'aesthetic-predictor/vit_b_32_embeddings/rating{experimental_aesthetic_embeddings_score}.npy')).to(device) \n",
        "                  aesthetic_query = target_embeds_temp + aesthetic_embedding * experimental_aesthetic_embeddings_weight\n",
        "                  target_embeds_temp = (aesthetic_query) / torch.linalg.norm(aesthetic_query)\n",
        "                if i == 'ViT-L-14--openai' and experimental_aesthetic_embeddings:\n",
        "                  aesthetic_embedding = torch.from_numpy(np.load(f'aesthetic-predictor/vit_l_14_embeddings/rating{experimental_aesthetic_embeddings_score}.npy')).to(device) \n",
        "                  aesthetic_query = target_embeds_temp + aesthetic_embedding * experimental_aesthetic_embeddings_weight\n",
        "                  target_embeds_temp = (aesthetic_query) / torch.linalg.norm(aesthetic_query)\n",
        "                target_embeds_temp = target_embeds_temp.unsqueeze(1).expand([-1,cutn*n,-1])          \n",
        "                dists = spherical_dist_loss(image_embeds, target_embeds_temp)\n",
        "                dists = dists.mean(1).mul(weights[i].squeeze()).mean()\n",
        "                losses+=dists*clip_guidance_scale #* (2 if i in [\"ViT-L-14-336--openai\", \"RN50x64--openai\", \"ViT-B-32--laion2b_e16\"] else (.4 if \"cloob\" in i else 1))\n",
        "                if i == \"ViT-L-14-336--openai\" and aes_scale !=0:\n",
        "                    aes_loss = (aesthetic_model_336(F.normalize(image_embeds, dim=-1))).mean() \n",
        "                    losses -= aes_loss * aes_scale \n",
        "                if i == \"ViT-L-14--openai\" and aes_scale !=0:\n",
        "                    aes_loss = (aesthetic_model_224(F.normalize(image_embeds, dim=-1))).mean() \n",
        "                    losses -= aes_loss * aes_scale \n",
        "                if i == \"ViT-B-16--openai\" and aes_scale !=0:\n",
        "                    aes_loss = (aesthetic_model_16(F.normalize(image_embeds, dim=-1))).mean() \n",
        "                    losses -= aes_loss * aes_scale  \n",
        "                if i == \"ViT-B-32--openai\" and aes_scale !=0:\n",
        "                    aes_loss = (aesthetic_model_32(F.normalize(image_embeds, dim=-1))).mean()\n",
        "                    losses -= aes_loss * aes_scale\n",
        "            #x_in_grad += torch.autograd.grad(losses, x_in)[0] / cutn_batches / len(clip_list)\n",
        "                #losses += dists\n",
        "                #losses = losses / len(clip_list)                \n",
        "                #gc.collect()\n",
        " \n",
        "        loss =  losses\n",
        "        #del losses\n",
        "        if symmetric_loss_scale != 0: loss +=  symmetric_loss(x_in) * symmetric_loss_scale\n",
        "        if init_image is not None and init_scale:\n",
        "            lpips_loss = (lpips_model(x_in, init) * init_scale).squeeze().mean()\n",
        "            #print(lpips_loss)\n",
        "            loss += lpips_loss\n",
        "        range_scale= range_index[t]\n",
        "        range_losses = range_loss(x_in,RGB_min,RGB_max).sum() * range_scale\n",
        "        loss += range_losses\n",
        "        #loss_grad = torch.autograd.grad(loss, x_in, )[0]\n",
        "        #x_in_grad += loss_grad\n",
        "        #grad = -torch.autograd.grad(x_in, x, x_in_grad)[0]\n",
        "        loss.backward()\n",
        "        grad = -x.grad\n",
        "        grad = torch.nan_to_num(grad, nan=0.0, posinf=0, neginf=0)\n",
        "        if grad_center: grad = centralized_grad(grad, use_gc=True, gc_conv_only=False)\n",
        "        mag = grad.square().mean().sqrt()\n",
        "        if mag==0 or torch.isnan(mag):\n",
        "            print(\"ERROR\")\n",
        "            print(t)\n",
        "            return(grad)\n",
        "        if t>=0:\n",
        "            if active_function == \"softsign\":\n",
        "                grad = F.softsign(grad*grad_scale/mag)\n",
        "            if active_function == \"tanh\":\n",
        "                grad = (grad/mag*grad_scale).tanh()\n",
        "            if active_function==\"clamp\":\n",
        "                grad = grad.clamp(-mag*grad_scale*2,mag*grad_scale*2)\n",
        "        if grad.abs().max()>0:\n",
        "            grad=grad/grad.abs().max()*opt.mag_mul\n",
        "            magnitude = grad.square().mean().sqrt()\n",
        "        else:\n",
        "            return(grad)\n",
        "        clamp_max = clamp_index_variation[t]\n",
        "        #print(magnitude, end = \"\\r\")\n",
        "        grad = grad* magnitude.clamp(max= clamp_max) /magnitude#0.2\n",
        "        grad = grad.detach()\n",
        "        grad = grad_fn(grad,t)\n",
        "        x = x.detach()\n",
        "        x = x.requires_grad_()\n",
        "        var = x.var()\n",
        "        var_scale = var_index[t]\n",
        "        var_losses = (var.pow(2).clamp(min = var_range)- 1) * var_scale \n",
        "        mean_scale = mean_index[t]\n",
        "        mean_losses = (x.mean().abs() - mean_range).abs().clamp(min = 0)*mean_scale\n",
        "        tv_losses = tv_loss(x).sum() * tv_scales[0] +\\\n",
        "            tv_loss(F.interpolate(x, scale_factor= 1/2)).sum()* tv_scales[1] + \\\n",
        "            tv_loss(F.interpolate(x, scale_factor = 1/4)).sum()* tv_scales[2] + \\\n",
        "            tv_loss(F.interpolate(x, scale_factor = 1/8)).sum()* tv_scales[3] \n",
        "        adjust_losses = tv_losses + var_losses + mean_losses\n",
        "        adjust_losses.backward()\n",
        "        grad -= x.grad\n",
        "        #print(grad.abs().mean(), x.grad.abs().mean(), end = \"\\r\")\n",
        "    return grad\n",
        "\n",
        "def null_fn(x_in):\n",
        "    return(torch.zeros_like(x_in))\n",
        "\n",
        "def display_handler(x,i,cadance = 5, decode = True):\n",
        "    global progress, image_grid, writer, img_tensor, im\n",
        "    img_tensor = x\n",
        "    if i%cadance==0:\n",
        "        if decode: \n",
        "            x = model.decode_first_stage(x)\n",
        "        grid = make_grid(torch.clamp((x+1.0)/2.0, min=0.0, max=1.0),round(x.shape[0]**0.5+0.2))\n",
        "        grid = 255. * rearrange(grid, 'c h w -> h w c').detach().cpu().numpy()\n",
        "        image_grid = grid.copy(order = \"C\") \n",
        "        with io.BytesIO() as output:\n",
        "            im = Image.fromarray(grid.astype(np.uint8))\n",
        "            im.save(output, format = \"PNG\")\n",
        "            progress.value = output.getvalue()\n",
        "            if generate_video:\n",
        "                im.save(p.stdin, 'PNG')\n",
        "\n",
        "def grad_fn(x,t):\n",
        "    if t <= 500 and grad_blur: x = TF.gaussian_blur(x, 2*round(int(max(grad_blur-t/150, 1)))-1, 1.5)\n",
        "    return x\n",
        "\n",
        "def cond_clamp(image,t): \n",
        "    t = 1000-t[0]\n",
        "    if t<= max(punish_steps, compress_steps):\n",
        "        s = torch.quantile(\n",
        "            rearrange(image, 'b ... -> b (...)').abs(),\n",
        "            threshold_percentile,\n",
        "            dim = -1\n",
        "        )\n",
        "        s = s.view(-1, *((1,) * (image.ndim - 1)))\n",
        "        ths = s.clamp(min = threshold)\n",
        "        im_max = image.clamp(min = ths) - image.clamp(min = ths, max = ths)\n",
        "        im_min = image.clamp(max = -ths, min = -ths) - image.clamp(max = -ths)\n",
        "    if t<=punish_steps:\n",
        "        image = image.clamp(min = -ths, max =  ths)+(im_max-im_min) * punish_factor  #((im_max-im_min)*punish_factor).tanh()/punish_factor \n",
        "    if t<= compress_steps:\n",
        "        image = image / (ths/threshold)**compress_factor\n",
        "        image +=  noise_like(image.shape,device,False) * ((ths/threshold)**compress_factor - 1)\n",
        "    return(image)\n",
        "    \n",
        "def make_schedule(t_start, t_end, step_size=1):\n",
        "    schedule = []\n",
        "    par_schedule = []\n",
        "    t = t_start\n",
        "    while t > t_end:\n",
        "        schedule.append(t)\n",
        "        t -= step_size\n",
        "    schedule.append(t_end)\n",
        "    return np.array(schedule)\n",
        "\n",
        "lpips_model = lpips.LPIPS(net='vgg').to(device)\n",
        "\n",
        "def list_mul_to_array(list_mul):\n",
        "  i = 0\n",
        "  mul_count = 0\n",
        "  mul_string = ''\n",
        "  full_list = list_mul\n",
        "  full_list_len = len(full_list)\n",
        "  for item in full_list:\n",
        "    if(i == 0):\n",
        "      last_item = item\n",
        "    if(item == last_item):\n",
        "      mul_count+=1\n",
        "    if(item != last_item or full_list_len == i+1):\n",
        "      mul_string = mul_string + f' [{last_item}]*{mul_count} +'\n",
        "      mul_count=1\n",
        "    last_item = item\n",
        "    i+=1\n",
        "  return(mul_string[1:-2])\n",
        "\n",
        "def generate_settings_file(add_prompts=False, add_dimensions=False):\n",
        "  \n",
        "  if(add_prompts):\n",
        "    prompts = f'''\n",
        "    clip_prompts = {clip_prompts}\n",
        "    latent_prompts = {latent_prompts}\n",
        "    latent_negatives = {latent_negatives}\n",
        "    image_prompts = {image_prompts}\n",
        "    '''\n",
        "  else:\n",
        "    prompts = ''\n",
        "\n",
        "  if(add_dimensions):\n",
        "    dimensions = f'''width = {width}\n",
        "    height = {height}\n",
        "    '''\n",
        "  else:\n",
        "    dimensions = ''\n",
        "  settings = f'''\n",
        "    #This settings file can be loaded back to Latent Majesty Diffusion. If you like your setting consider sharing it to the settings library at https://github.com/multimodalart/MajestyDiffusion\n",
        "    [model]\n",
        "    latent_diffusion_model = {latent_diffusion_model}\n",
        "    \n",
        "    [clip_list]\n",
        "    perceptors = {clip_load_list}\n",
        "    \n",
        "    [basic_settings]\n",
        "    #Perceptor things\n",
        "    {prompts}\n",
        "    {dimensions}\n",
        "    latent_diffusion_guidance_scale = {latent_diffusion_guidance_scale}\n",
        "    clip_guidance_scale = {clip_guidance_scale}\n",
        "    aesthetic_loss_scale = {aesthetic_loss_scale}\n",
        "    augment_cuts={augment_cuts}\n",
        "\n",
        "    #Init image settings\n",
        "    starting_timestep = {starting_timestep}\n",
        "    init_scale = {init_scale} \n",
        "    init_brightness = {init_brightness}\n",
        "    \n",
        "    [advanced_settings]\n",
        "    #Add CLIP Guidance and all the flavors or just run normal Latent Diffusion\n",
        "    use_cond_fn = {use_cond_fn}\n",
        "\n",
        "    #Custom schedules for cuts. Check out the schedules documentation here\n",
        "    custom_schedule_setting = {custom_schedule_setting}\n",
        "\n",
        "    #Cut settings\n",
        "    clamp_index = {clamp_index}\n",
        "    cut_overview = {list_mul_to_array(cut_overview)}\n",
        "    cut_innercut = {list_mul_to_array(cut_innercut)}\n",
        "    cut_blur_n = {list_mul_to_array(cut_blur_n)}\n",
        "    cut_blur_kernel = {cut_blur_kernel}\n",
        "    cut_ic_pow = {cut_ic_pow}\n",
        "    cut_icgray_p = {list_mul_to_array(cut_icgray_p)}\n",
        "    cutn_batches = {cutn_batches}\n",
        "    range_index = {list_mul_to_array(range_index)}\n",
        "    active_function = \"{active_function}\"\n",
        "    ths_method= \"{ths_method}\"\n",
        "    tv_scales = {list_mul_to_array(tv_scales)}\n",
        "\n",
        "    #If you uncomment this line you can schedule the CLIP guidance across the steps. Otherwise the clip_guidance_scale will be used\n",
        "    clip_guidance_schedule = {list_mul_to_array(clip_guidance_index)}\n",
        "    \n",
        "    #Apply symmetric loss (force simmetry to your results)\n",
        "    symmetric_loss_scale = {symmetric_loss_scale} \n",
        "\n",
        "    #Latent Diffusion Advanced Settings\n",
        "    #Use when latent upscale to correct satuation problem\n",
        "    scale_div = {scale_div}\n",
        "    #Magnify grad before clamping by how many times\n",
        "    opt_mag_mul = {opt_mag_mul}\n",
        "    opt_ddim_eta = {opt_ddim_eta}\n",
        "    opt_eta_end = {opt_eta_end}\n",
        "    opt_temperature = {opt_temperature}\n",
        "\n",
        "    #Grad advanced settings\n",
        "    grad_center = {grad_center}\n",
        "    #Lower value result in more coherent and detailed result, higher value makes it focus on more dominent concept\n",
        "    grad_scale={grad_scale} \n",
        "    score_modifier = {score_modifier}\n",
        "    threshold_percentile = {threshold_percentile}\n",
        "    threshold = {threshold}\n",
        "    var_index = {list_mul_to_array(var_index)}\n",
        "    var_range = {var_range}\n",
        "    mean_index = {list_mul_to_array(mean_index)}\n",
        "    mean_range = {mean_range}\n",
        "\n",
        "    #Init image advanced settings\n",
        "    init_rotate={init_rotate}\n",
        "    mask_rotate={mask_rotate}\n",
        "    init_magnitude = {init_magnitude}\n",
        "\n",
        "    #More settings\n",
        "    RGB_min = {RGB_min}\n",
        "    RGB_max = {RGB_max}\n",
        "    #How to pad the image with cut_overview\n",
        "    padargs = {padargs} \n",
        "    flip_aug={flip_aug}\n",
        "    \n",
        "    #Experimental aesthetic embeddings, work only with OpenAI ViT-B/32 and ViT-L/14\n",
        "    experimental_aesthetic_embeddings = {experimental_aesthetic_embeddings}\n",
        "    #How much you want this to influence your result\n",
        "    experimental_aesthetic_embeddings_weight = {experimental_aesthetic_embeddings_weight}\n",
        "    #9 are good aesthetic embeddings, 0 are bad ones\n",
        "    experimental_aesthetic_embeddings_score = {experimental_aesthetic_embeddings_score}\n",
        "\n",
        "    # For fun dont change except if you really know what your are doing\n",
        "    grad_blur = {grad_blur}\n",
        "    compress_steps = {compress_steps}\n",
        "    compress_factor = {compress_factor}\n",
        "    punish_steps = {punish_steps}\n",
        "    punish_factor = {punish_factor}\n",
        "    '''\n",
        "  return(settings)\n",
        "\n",
        "#Alstro's aesthetic model\n",
        "aesthetic_model_336 = torch.nn.Linear(768,1).cuda()\n",
        "aesthetic_model_336.load_state_dict(torch.load(f\"{model_path}/ava_vit_l_14_336_linear.pth\"))\n",
        "\n",
        "aesthetic_model_224 = torch.nn.Linear(768,1).cuda()\n",
        "aesthetic_model_224.load_state_dict(torch.load(f\"{model_path}/ava_vit_l_14_linear.pth\"))\n",
        "\n",
        "aesthetic_model_16 = torch.nn.Linear(512,1).cuda()\n",
        "aesthetic_model_16.load_state_dict(torch.load(f\"{model_path}/ava_vit_b_16_linear.pth\"))\n",
        "\n",
        "aesthetic_model_32 = torch.nn.Linear(512,1).cuda()\n",
        "aesthetic_model_32.load_state_dict(torch.load(f\"{model_path}/sa_0_4_vit_b_32_linear.pth\"))\n",
        "\n",
        "has_purged = False\n",
        "def do_run():\n",
        "        global has_purged\n",
        "        if(has_purged):\n",
        "            global clip_model, clip_size, clip_tokenize, clip_normalize, clip_list\n",
        "            clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "            has_purged = False\n",
        "  #  with torch.cuda.amp.autocast():\n",
        "        global progress,target_embeds, weights, zero_embed, init, scale_factor, cur_step, uc, c\n",
        "        cur_step = 0\n",
        "        scale_factor = 1\n",
        "        make_cutouts = {}\n",
        "        for i in clip_list:\n",
        "             make_cutouts[i] = MakeCutouts(clip_size[i][0] if type(clip_size[i]) is tuple else clip_size[i],Overview=1)\n",
        "        target_embeds, weights ,zero_embed = {}, {}, {}\n",
        "        for i in clip_list:\n",
        "            target_embeds[i] = []\n",
        "            weights[i]=[]\n",
        "\n",
        "        for prompt in prompts:\n",
        "            txt, weight = parse_prompt(prompt)\n",
        "            for i in clip_list:\n",
        "                if \"cloob\" not in i:\n",
        "                    with torch.cuda.amp.autocast():\n",
        "                        embeds = clip_model[i].encode_text(clip_tokenize[i](txt).to(device))\n",
        "                        target_embeds[i].append(embeds)\n",
        "                        weights[i].append(weight)\n",
        "                else:\n",
        "                        embeds = clip_model[i].encode_text(clip_tokenize[i](txt).to(device))\n",
        "                        target_embeds[i].append(embeds)\n",
        "                        weights[i].append(weight)\n",
        "\n",
        "        for prompt in image_prompts:\n",
        "            if prompt.startswith(\"data:\"):\n",
        "                img = base64_to_image(prompt).convert('RGB')\n",
        "                weight = 1\n",
        "            else:\n",
        "                print(f\"processing{prompt}\",end=\"\\r\")\n",
        "                path, weight = parse_prompt(prompt)\n",
        "                img = Image.open(fetch(path)).convert('RGB')\n",
        "            img = TF.resize(img, min(opt.W, opt.H, *img.size), transforms.InterpolationMode.LANCZOS)\n",
        "            for i in clip_list:\n",
        "                if \"cloob\" not in i:\n",
        "                    with torch.cuda.amp.autocast():\n",
        "                        batch = make_cutouts[i](TF.to_tensor(img).unsqueeze(0).to(device))\n",
        "                        embed = clip_model[i].encode_image(clip_normalize[i](batch))\n",
        "                        target_embeds[i].append(embed)\n",
        "                        weights[i].extend([weight])\n",
        "                else:\n",
        "                        batch = make_cutouts[i](TF.to_tensor(img).unsqueeze(0).to(device))\n",
        "                        embed = clip_model[i].encode_image(clip_normalize[i](batch))\n",
        "                        target_embeds[i].append(embed)\n",
        "                        weights[i].extend([weight])\n",
        "        #if anti_jpg != 0:\n",
        "        #    target_embeds[\"ViT-B-32--openai\"].append(torch.tensor([np.load(f\"{model_path}/openimages_512x_png_embed224.npz\")['arr_0']-np.load(f\"{model_path}/imagenet_512x_jpg_embed224.npz\")['arr_0']], device = device))\n",
        "        #    weights[\"ViT-B-32--openai\"].append(anti_jpg)\n",
        "\n",
        "        for i in clip_list:\n",
        "            target_embeds[i] = torch.cat(target_embeds[i])\n",
        "            weights[i] = torch.tensor([weights[i]], device=device)\n",
        "        shape = [4, opt.H//8, opt.W//8]\n",
        "        init = None\n",
        "        mask = None\n",
        "        transform = T.GaussianBlur(kernel_size=3, sigma=0.4)\n",
        "        if init_image is not None:\n",
        "            if init_image.startswith(\"data:\"):\n",
        "                img = base64_to_image(init_image).convert('RGB')\n",
        "            else:\n",
        "                img = Image.open(fetch(init_image)).convert('RGB')\n",
        "            init = TF.to_tensor(img).to(device).unsqueeze(0)\n",
        "            if init_rotate: init = torch.rot90(init, 1, [3,2]) \n",
        "            x0_original = torch.tensor(init)\n",
        "            init = resize(init,out_shape = [opt.n_samples,3,opt.H, opt.W])\n",
        "            init = init.mul(2).sub(1).half()\n",
        "            init_encoded =  model.first_stage_model.encode(init).sample()* init_magnitude + init_brightness\n",
        "            #init_encoded = init_encoded + noise_like(init_encoded.shape,device,False).mul(init_noise)\n",
        "            upscaled_flag=True\n",
        "        else:\n",
        "            init = None\n",
        "            init_encoded = None\n",
        "            upscale_flag = False\n",
        "        if init_mask is not None:\n",
        "            mask = Image.open(fetch(init_mask)).convert('RGB')\n",
        "            mask = TF.to_tensor(mask).to(device).unsqueeze(0)\n",
        "            if mask_rotate: mask = torch.rot90(mask, 1, [3,2])\n",
        "            mask = F.interpolate(mask,[opt.H//8,opt.W//8]).mean(1)\n",
        "            mask = transform(mask)\n",
        "            print(mask)\n",
        "\n",
        "\n",
        "        #progress = widgets.Image(layout = widgets.Layout(max_width = \"400px\",max_height = \"512px\"))\n",
        "        #display.display(progress)\n",
        "\n",
        "        if opt.plms:\n",
        "            sampler = PLMSSampler(model)\n",
        "        else:\n",
        "            sampler = DDIMSampler(model)\n",
        "\n",
        "        os.makedirs(opt.outdir, exist_ok=True)\n",
        "        outpath = opt.outdir\n",
        "\n",
        "        prompt = opt.prompt\n",
        "        sample_path = os.path.join(outpath, \"samples\")\n",
        "        os.makedirs(sample_path, exist_ok=True)\n",
        "        base_count = len(os.listdir(sample_path))\n",
        "\n",
        "        all_samples=list()\n",
        "        last_step_upscale = False\n",
        "        eta1 = opt.ddim_eta\n",
        "        eta2 = opt.eta_end\n",
        "        with torch.enable_grad():\n",
        "            with torch.cuda.amp.autocast():\n",
        "                with model.ema_scope():\n",
        "                    uc = None\n",
        "                    if opt.scale != 1.0:\n",
        "                        uc = model.get_learned_conditioning(opt.n_samples * opt.uc).cuda()\n",
        "                    \n",
        "                    for n in range(opt.n_iter):\n",
        "                        torch.cuda.empty_cache()\n",
        "                        gc.collect()\n",
        "                        c = model.get_learned_conditioning(opt.n_samples * prompt).cuda()\n",
        "                        if init_encoded is None:\n",
        "                            x_T = torch.randn([opt.n_samples,*shape], device=device)\n",
        "                            upscaled_flag = False\n",
        "                            x0 = None\n",
        "                        else:\n",
        "                            x_T = init_encoded\n",
        "                            x0 = torch.tensor(x_T)\n",
        "                            upscaled_flag = True\n",
        "                        last_step_uspcale_list = []\n",
        "                        diffusion_stages = 0\n",
        "                        for custom_schedule in custom_schedules:\n",
        "                            if type(custom_schedule) != type(\"\"):\n",
        "                                diffusion_stages += 1\n",
        "                                torch.cuda.empty_cache()\n",
        "                                gc.collect()\n",
        "                                last_step_upscale = False\n",
        "                                samples_ddim, _ = sampler.sample(S=opt.ddim_steps,\n",
        "                                                                 conditioning=c,\n",
        "                                                                 batch_size=opt.n_samples,\n",
        "                                                                 shape=shape,\n",
        "                                                                 custom_schedule = custom_schedule,\n",
        "                                                                 verbose=False,\n",
        "                                                                 unconditional_guidance_scale=opt.scale,\n",
        "                                                                 unconditional_conditioning=uc,\n",
        "                                                                 eta=eta1 if diffusion_stages == 1 or last_step_upscale else eta2,\n",
        "                                                                 eta_end=eta2,\n",
        "                                                                 img_callback=None if use_cond_fn else display_handler,\n",
        "                                                                 cond_fn=cond_fn if use_cond_fn else None,\n",
        "                                                                 temperature = opt.temperature,\n",
        "                                                                 x_adjust_fn=cond_clamp,\n",
        "                                                                 x_T = x_T,\n",
        "                                                                 x0=x0,\n",
        "                                                                 mask=mask,\n",
        "                                                                 score_corrector = score_corrector,\n",
        "                                                                 corrector_kwargs = score_corrector_setting,\n",
        "                                                                 x0_adjust_fn = dynamic_thresholding,\n",
        "                                                                 clip_embed = target_embeds[\"ViT-L-14--openai\"].mean(0, keepdim = True) if \"ViT-L-14--openai\" in clip_list else None\n",
        "                                                                )\n",
        "                                #x_T = samples_ddim.clamp(-6,6)\n",
        "                                x_T = samples_ddim\n",
        "                                last_step_upscale = False\n",
        "                            else:\n",
        "                                torch.cuda.empty_cache()\n",
        "                                gc.collect()\n",
        "                                method, scale_factor = custom_schedule.split(\":\")\n",
        "                                if method == \"RGB\":\n",
        "                                    scale_factor = float(scale_factor)\n",
        "                                    temp_file_name = \"temp_\"+f\"{str(round(time.time()))}.png\"\n",
        "                                    temp_file = os.path.join(sample_path, temp_file_name)\n",
        "                                    im.save(temp_file, format = \"PNG\")\n",
        "                                    init = Image.open(fetch(temp_file)).convert('RGB')\n",
        "                                    init = TF.to_tensor(init).to(device).unsqueeze(0)\n",
        "                                    opt.H, opt.W = opt.H*scale_factor, opt.W*scale_factor\n",
        "                                    init = resize(init,out_shape = [opt.n_samples,3,opt.H, opt.W], antialiasing=True)\n",
        "                                    init = init.mul(2).sub(1).half()\n",
        "                                    x_T =  (model.first_stage_model.encode(init).sample()*init_magnitude)\n",
        "                                    upscaled_flag = True\n",
        "                                    last_step_upscale = True\n",
        "                                    #x_T += noise_like(x_T.shape,device,False)*init_noise\n",
        "                                    #x_T = x_T.clamp(-6,6)\n",
        "                                if method == \"gfpgan\":\n",
        "                                    scale_factor = float(scale_factor)\n",
        "                                    last_step_upscale = True\n",
        "                                    temp_file_name = \"temp_\"+f\"{str(round(time.time()))}.png\"\n",
        "                                    temp_file = os.path.join(sample_path, temp_file_name)\n",
        "                                    im.save(temp_file, format = \"PNG\")\n",
        "                                    GFP_factor = 2 if scale_factor > 1 else 1\n",
        "                                    GFP_ver = 1.3 #if GFP_factor == 1 else 1.2\n",
        "                                    %cd GFPGAN\n",
        "                                    torch.cuda.empty_cache()\n",
        "                                    gc.collect()\n",
        "                                    !python inference_gfpgan.py -i $temp_file -o results -v $GFP_ver -s $GFP_factor\n",
        "                                    %cd ..\n",
        "                                    face_corrected = Image.open(fetch(f\"GFPGAN/results/restored_imgs/{temp_file_name}\"))\n",
        "                                    with io.BytesIO() as output:\n",
        "                                      face_corrected.save(output,format=\"PNG\")\n",
        "                                      progress.value = output.getvalue()\n",
        "                                    init = Image.open(fetch(f\"GFPGAN/results/restored_imgs/{temp_file_name}\")).convert('RGB')\n",
        "                                    init = TF.to_tensor(init).to(device).unsqueeze(0)\n",
        "                                    opt.H, opt.W = opt.H*scale_factor, opt.W*scale_factor\n",
        "                                    init = resize(init,out_shape = [opt.n_samples,3,opt.H, opt.W], antialiasing=True)\n",
        "                                    init = init.mul(2).sub(1).half()\n",
        "                                    x_T =  (model.first_stage_model.encode(init).sample()*init_magnitude)\n",
        "                                    upscaled_flag = True\n",
        "                                    #x_T += noise_like(x_T.shape,device,False)*init_noise\n",
        "                                    #x_T = x_T.clamp(-6,6)\n",
        "\n",
        "#new code\n",
        "                                if method == \"real\":\n",
        "                                    scale_factor = float(scale_factor)\n",
        "                                    last_step_upscale = True\n",
        "                                    temp_file_name = \"temp_\"+f\"{str(round(time.time()))}.png\"\n",
        "                                    temp_file = os.path.join(sample_path, temp_file_name)\n",
        "                                    im.save(temp_file, format = \"PNG\")\n",
        "                                    REAL_factor = 2 if scale_factor > 1 else 1\n",
        "                                    %cd Real-ESRGAN\n",
        "                                    torch.cuda.empty_cache()\n",
        "                                    gc.collect()\n",
        "                                    !python inference_realesrgan.py -n RealESRGAN_x4plus -i $temp_file -o results --outscale $REAL_factor --face_enhance\n",
        "                                    %cd ..\n",
        "                                    face_corrected = Image.open(fetch(f\"Real-ESRGAN/results/{temp_file_name}\"))\n",
        "                                    with io.BytesIO() as output:\n",
        "                                      face_corrected.save(output,format=\"PNG\")\n",
        "                                      progress.value = output.getvalue()\n",
        "                                    init = Image.open(fetch(f\"Real-ESRGAN/results/{temp_file_name}\")).convert('RGB')\n",
        "                                    init = TF.to_tensor(init).to(device).unsqueeze(0)\n",
        "                                    opt.H, opt.W = opt.H*scale_factor, opt.W*scale_factor\n",
        "                                    init = resize(init,out_shape = [opt.n_samples,3,opt.H, opt.W], antialiasing=True)\n",
        "                                    init = init.mul(2).sub(1).half()\n",
        "                                    x_T =  (model.first_stage_model.encode(init).sample()*init_magnitude)\n",
        "                                    upscaled_flag = True\n",
        "                                    #x_T += noise_like(x_T.shape,device,False)*init_noise\n",
        "                                    #x_T = x_T.clamp(-6,6)\n",
        "                                if method == \"aesrgan\":\n",
        "                                    scale_factor = float(scale_factor)\n",
        "                                    last_step_upscale = True\n",
        "                                    temp_file_name = \"temp_\"+f\"{str(round(time.time()))}.png\"\n",
        "                                    temp_file = os.path.join(sample_path, temp_file_name)\n",
        "                                    im.save(temp_file, format = \"PNG\")\n",
        "                                    AESRGAN_factor = 2 if scale_factor > 1 else 1\n",
        "                                    %cd A-ESRGAN\n",
        "                                    torch.cuda.empty_cache()\n",
        "                                    gc.collect()\n",
        "                                    !python inference_aesrgan.py --model_path=experiments/pretrained_models/A_ESRGAN_Multi_Plus.pth --input=$temp_file --outscale=$AESRGAN_factor --face_enhance\n",
        "                                    %cd ..\n",
        "                                    face_corrected = Image.open(fetch(f\"A-ESRGAN/results/{temp_file_name}\"))\n",
        "                                    with io.BytesIO() as output:\n",
        "                                      face_corrected.save(output,format=\"PNG\")\n",
        "                                      progress.value = output.getvalue()\n",
        "                                    init = Image.open(fetch(f\"A-ESRGAN/results/{temp_file_name}\")).convert('RGB')\n",
        "                                    init = TF.to_tensor(init).to(device).unsqueeze(0)\n",
        "                                    opt.H, opt.W = opt.H*scale_factor, opt.W*scale_factor\n",
        "                                    init = resize(init,out_shape = [opt.n_samples,3,opt.H, opt.W], antialiasing=True)\n",
        "                                    init = init.mul(2).sub(1).half()\n",
        "                                    x_T =  (model.first_stage_model.encode(init).sample()*init_magnitude)\n",
        "                                    upscaled_flag = True\n",
        "#end new\n",
        "\n",
        "\n",
        "                                if method ==\"scale\":\n",
        "                                    scale_factor = float(scale_factor)\n",
        "                                    x_T = x_T*scale_factor\n",
        "                                if method ==\"noise\":\n",
        "                                    scale_factor = float(scale_factor)\n",
        "                                    x_T += noise_like(x_T.shape,device,False)*scale_factor\n",
        "                                if method == \"purge\":\n",
        "                                    has_purged = True\n",
        "                                    for i in scale_factor.split(\",\"):\n",
        "                                        if i in clip_load_list:\n",
        "                                            arch, pub, m_id = i[1:-1].split(' - ')\n",
        "                                            print(\"Purge \",i)\n",
        "                                            del clip_list[clip_list.index(m_id)]\n",
        "                                            del clip_model[m_id]\n",
        "                                            del clip_size[m_id]\n",
        "                                            del clip_tokenize[m_id]\n",
        "                                            del clip_normalize[m_id]\n",
        "                        #last_step_uspcale_list.append(last_step_upscale)\n",
        "                        scale_factor = 1\n",
        "                        current_time = str(round(time.time()))\n",
        "                        if(last_step_upscale and method == 'gfpgan'):\n",
        "                          latest_upscale = Image.open(fetch(f\"GFPGAN/results/restored_imgs/{temp_file_name}\")).convert('RGB')\n",
        "                          latest_upscale.save(os.path.join(outpath, f'{current_time}.png'), format = \"PNG\")\n",
        "\n",
        "#new code\n",
        "                        if(last_step_upscale and method == 'real'):\n",
        "                          latest_upscale = Image.open(fetch(f\"Real-ESRGAN/results/{temp_file_name}\")).convert('RGB')\n",
        "                          latest_upscale.save(os.path.join(outpath, f'{current_time}.png'), format = \"PNG\")\n",
        "                        if(last_step_upscale and method == 'aesrgan'):\n",
        "                          latest_upscale = Image.open(fetch(f\"A-ESRGAN/results/{temp_file_name}\")).convert('RGB')\n",
        "                          latest_upscale.save(os.path.join(outpath, f'{current_time}.png'), format = \"PNG\")\n",
        "#end new\n",
        "\n",
        "                        else:\n",
        "                          Image.fromarray(image_grid.astype(np.uint8)).save(os.path.join(outpath, f'{current_time}.png'), format = \"PNG\")\n",
        "                        settings = generate_settings_file(add_prompts=True, add_dimensions=False)\n",
        "                        text_file = open(f\"{outpath}/{current_time}.cfg\", \"w\")\n",
        "                        text_file.write(settings)\n",
        "                        text_file.close()\n",
        "                        x_samples_ddim = model.decode_first_stage(samples_ddim)\n",
        "                        x_samples_ddim = torch.clamp((x_samples_ddim+1.0)/2.0, min=0.0, max=1.0)\n",
        "                        all_samples.append(x_samples_ddim)\n",
        "\n",
        "\n",
        "        if(len(all_samples) > 1):\n",
        "          # additionally, save as grid\n",
        "          grid = torch.stack(all_samples, 0)\n",
        "          grid = rearrange(grid, 'n b c h w -> (n b) c h w')\n",
        "          grid = make_grid(grid, nrow=opt.n_samples)\n",
        "\n",
        "          # to image\n",
        "          grid = 255. * rearrange(grid, 'c h w -> h w c').cpu().numpy()\n",
        "          Image.fromarray(grid.astype(np.uint8)).save(os.path.join(outpath, f'grid_{str(round(time.time()))}.png'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Optional Real-ESRGAN & A-ESRGAN Models\n",
        "\n",
        "skip_ESRGAN = True #@param{type:'boolean'}\n",
        "if(not skip_ESRGAN):\n",
        "\n",
        "  !wget https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.0/RealESRGAN_x4plus.pth -P Real-ESRGAN/experiments/pretrained_models\n",
        "  !wget https://github.com/Zi-hao-Wei/A-ESRGAN/releases/download/v1.0.0/A_ESRGAN_Single.pth -P A-ESRGAN/experiments/pretrained_models\n",
        "  !wget https://github.com/Zi-hao-Wei/A-ESRGAN/releases/download/v1.0.0/A_ESRGAN_Multi.pth -P A-ESRGAN/experiments/pretrained_models\n",
        "  !wget https://github.com/Zi-hao-Wei/A-ESRGAN/releases/download/v1.0.0/A_ESRGAN_Multi_Plus.pth -P A-ESRGAN/experiments/pretrained_models\n",
        "\n",
        "  #Setup Real-ESRGAN\n",
        "  %cd Real-ESRGAN\n",
        "  # Set up the environment\n",
        "  #!pip install -r requirements.txt\n",
        "  !python setup.py develop\n",
        "  %cd .."
      ],
      "metadata": {
        "id": "BLZCpagMZY5W",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILHGCEla2Rrm"
      },
      "source": [
        "# Parameters!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpR9JhyCu5iq"
      },
      "source": [
        "#### Perceptors (Choose your CLIP and CLIP-like models) \n",
        "If you have Colab Free, try removing ViT-L14 from your mix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "8K7l_E2JvLWC"
      },
      "outputs": [],
      "source": [
        "#@title Choose your perceptor models\n",
        "\n",
        "# suppress mmc warmup outputs\n",
        "import mmc.loaders\n",
        "clip_load_list = []\n",
        "#@markdown #### Open AI CLIP models\n",
        "ViT_B32 = False #@param {type:\"boolean\"}\n",
        "ViT_B16 = True #@param {type:\"boolean\"}\n",
        "ViT_L14 = True #@param {type:\"boolean\"}\n",
        "ViT_L14_336px = False #@param {type:\"boolean\"}\n",
        "#RN101 = False #@param {type:\"boolean\"}\n",
        "#RN50 = False #@param {type:\"boolean\"}\n",
        "RN50x4 = False #@param {type:\"boolean\"}\n",
        "RN50x16 = False #@param {type:\"boolean\"}\n",
        "RN50x64 = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown #### OpenCLIP models\n",
        "ViT_B16_plus = False #@param {type: \"boolean\"}\n",
        "ViT_B32_laion2b = True #@param {type: \"boolean\"}\n",
        "ViT_L14_laion = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown #### Multilangual CLIP models \n",
        "clip_farsi = False #@param {type: \"boolean\"}\n",
        "clip_korean = False #@param {type: \"boolean\"}\n",
        "\n",
        "#@markdown #### CLOOB models\n",
        "cloob_ViT_B16 = False #@param {type: \"boolean\"}\n",
        "\n",
        "# @markdown Load even more CLIP and CLIP-like models (from [Multi-Modal-Comparators](https://github.com/dmarx/Multi-Modal-Comparators))\n",
        "model1 = \"\" # @param [\"[clip - mlfoundations - RN50--openai]\",\"[clip - mlfoundations - RN101--openai]\",\"[clip - mlfoundations - RN50--yfcc15m]\",\"[clip - mlfoundations - RN50--cc12m]\",\"[clip - mlfoundations - RN50-quickgelu--yfcc15m]\",\"[clip - mlfoundations - RN50-quickgelu--cc12m]\",\"[clip - mlfoundations - RN101--yfcc15m]\",\"[clip - mlfoundations - RN101-quickgelu--yfcc15m]\",\"[clip - mlfoundations - ViT-B-32--laion400m_e31]\",\"[clip - mlfoundations - ViT-B-32--laion400m_e32]\",\"[clip - mlfoundations - ViT-B-32--laion400m_avg]\",\"[clip - mlfoundations - ViT-B-32-quickgelu--laion400m_e31]\",\"[clip - mlfoundations - ViT-B-32-quickgelu--laion400m_e32]\",\"[clip - mlfoundations - ViT-B-32-quickgelu--laion400m_avg]\",\"[clip - mlfoundations - ViT-B-16--laion400m_e31]\",\"[clip - mlfoundations - ViT-B-16--laion400m_e32]\",\"[clip - sbert - ViT-B-32-multilingual-v1]\",\"[clip - facebookresearch - clip_small_25ep]\",\"[simclr - facebookresearch - simclr_small_25ep]\",\"[slip - facebookresearch - slip_small_25ep]\",\"[slip - facebookresearch - slip_small_50ep]\",\"[slip - facebookresearch - slip_small_100ep]\",\"[clip - facebookresearch - clip_base_25ep]\",\"[simclr - facebookresearch - simclr_base_25ep]\",\"[slip - facebookresearch - slip_base_25ep]\",\"[slip - facebookresearch - slip_base_50ep]\",\"[slip - facebookresearch - slip_base_100ep]\",\"[clip - facebookresearch - clip_large_25ep]\",\"[simclr - facebookresearch - simclr_large_25ep]\",\"[slip - facebookresearch - slip_large_25ep]\",\"[slip - facebookresearch - slip_large_50ep]\",\"[slip - facebookresearch - slip_large_100ep]\",\"[clip - facebookresearch - clip_base_cc3m_40ep]\",\"[slip - facebookresearch - slip_base_cc3m_40ep]\",\"[slip - facebookresearch - slip_base_cc12m_35ep]\",\"[clip - facebookresearch - clip_base_cc12m_35ep]\"] {allow-input: true}\n",
        "model2 = \"\" # @param [\"[clip - mlfoundations - RN50--openai]\",\"[clip - mlfoundations - RN101--openai]\",\"[clip - mlfoundations - RN50--yfcc15m]\",\"[clip - mlfoundations - RN50--cc12m]\",\"[clip - mlfoundations - RN50-quickgelu--yfcc15m]\",\"[clip - mlfoundations - RN50-quickgelu--cc12m]\",\"[clip - mlfoundations - RN101--yfcc15m]\",\"[clip - mlfoundations - RN101-quickgelu--yfcc15m]\",\"[clip - mlfoundations - ViT-B-32--laion400m_e31]\",\"[clip - mlfoundations - ViT-B-32--laion400m_e32]\",\"[clip - mlfoundations - ViT-B-32--laion400m_avg]\",\"[clip - mlfoundations - ViT-B-32-quickgelu--laion400m_e31]\",\"[clip - mlfoundations - ViT-B-32-quickgelu--laion400m_e32]\",\"[clip - mlfoundations - ViT-B-32-quickgelu--laion400m_avg]\",\"[clip - mlfoundations - ViT-B-16--laion400m_e31]\",\"[clip - mlfoundations - ViT-B-16--laion400m_e32]\",\"[clip - sbert - ViT-B-32-multilingual-v1]\",\"[clip - facebookresearch - clip_small_25ep]\",\"[simclr - facebookresearch - simclr_small_25ep]\",\"[slip - facebookresearch - slip_small_25ep]\",\"[slip - facebookresearch - slip_small_50ep]\",\"[slip - facebookresearch - slip_small_100ep]\",\"[clip - facebookresearch - clip_base_25ep]\",\"[simclr - facebookresearch - simclr_base_25ep]\",\"[slip - facebookresearch - slip_base_25ep]\",\"[slip - facebookresearch - slip_base_50ep]\",\"[slip - facebookresearch - slip_base_100ep]\",\"[clip - facebookresearch - clip_large_25ep]\",\"[simclr - facebookresearch - simclr_large_25ep]\",\"[slip - facebookresearch - slip_large_25ep]\",\"[slip - facebookresearch - slip_large_50ep]\",\"[slip - facebookresearch - slip_large_100ep]\",\"[clip - facebookresearch - clip_base_cc3m_40ep]\",\"[slip - facebookresearch - slip_base_cc3m_40ep]\",\"[slip - facebookresearch - slip_base_cc12m_35ep]\",\"[clip - facebookresearch - clip_base_cc12m_35ep]\"] {allow-input: true}\n",
        "model3 = \"\" # @param [\"[clip - openai - RN50]\",\"[clip - openai - RN101]\",\"[clip - mlfoundations - RN50--yfcc15m]\",\"[clip - mlfoundations - RN50--cc12m]\",\"[clip - mlfoundations - RN50-quickgelu--yfcc15m]\",\"[clip - mlfoundations - RN50-quickgelu--cc12m]\",\"[clip - mlfoundations - RN101--yfcc15m]\",\"[clip - mlfoundations - RN101-quickgelu--yfcc15m]\",\"[clip - mlfoundations - ViT-B-32--laion400m_e31]\",\"[clip - mlfoundations - ViT-B-32--laion400m_e32]\",\"[clip - mlfoundations - ViT-B-32--laion400m_avg]\",\"[clip - mlfoundations - ViT-B-32-quickgelu--laion400m_e31]\",\"[clip - mlfoundations - ViT-B-32-quickgelu--laion400m_e32]\",\"[clip - mlfoundations - ViT-B-32-quickgelu--laion400m_avg]\",\"[clip - mlfoundations - ViT-B-16--laion400m_e31]\",\"[clip - mlfoundations - ViT-B-16--laion400m_e32]\",\"[clip - sbert - ViT-B-32-multilingual-v1]\",\"[clip - facebookresearch - clip_small_25ep]\",\"[simclr - facebookresearch - simclr_small_25ep]\",\"[slip - facebookresearch - slip_small_25ep]\",\"[slip - facebookresearch - slip_small_50ep]\",\"[slip - facebookresearch - slip_small_100ep]\",\"[clip - facebookresearch - clip_base_25ep]\",\"[simclr - facebookresearch - simclr_base_25ep]\",\"[slip - facebookresearch - slip_base_25ep]\",\"[slip - facebookresearch - slip_base_50ep]\",\"[slip - facebookresearch - slip_base_100ep]\",\"[clip - facebookresearch - clip_large_25ep]\",\"[simclr - facebookresearch - simclr_large_25ep]\",\"[slip - facebookresearch - slip_large_25ep]\",\"[slip - facebookresearch - slip_large_50ep]\",\"[slip - facebookresearch - slip_large_100ep]\",\"[clip - facebookresearch - clip_base_cc3m_40ep]\",\"[slip - facebookresearch - slip_base_cc3m_40ep]\",\"[slip - facebookresearch - slip_base_cc12m_35ep]\",\"[clip - facebookresearch - clip_base_cc12m_35ep]\"] {allow-input: true}\n",
        "\n",
        "if ViT_B32: \n",
        "  clip_load_list.append(\"[clip - mlfoundations - ViT-B-32--openai]\")\n",
        "if ViT_B16: \n",
        "  clip_load_list.append(\"[clip - mlfoundations - ViT-B-16--openai]\")\n",
        "if ViT_L14: \n",
        "  clip_load_list.append(\"[clip - mlfoundations - ViT-L-14--openai]\")\n",
        "if RN50x4: \n",
        "  clip_load_list.append(\"[clip - mlfoundations - RN50x4--openai]\")\n",
        "if RN50x64: \n",
        "  clip_load_list.append(\"[clip - mlfoundations - RN50x64--openai]\")\n",
        "if RN50x16: \n",
        "  clip_load_list.append(\"[clip - mlfoundations - RN50x16--openai]\")\n",
        "if ViT_L14_laion: \n",
        "  clip_load_list.append(\"[clip - mlfoundations - ViT-L-14--laion400m_e32]\")\n",
        "if ViT_L14_336px:\n",
        "  clip_load_list.append(\"[clip - mlfoundations - ViT-L-14-336--openai]\")\n",
        "if ViT_B16_plus:\n",
        "  clip_load_list.append(\"[clip - mlfoundations - ViT-B-16-plus-240--laion400m_e32]\")\n",
        "if ViT_B32_laion2b:\n",
        "  clip_load_list.append(\"[clip - mlfoundations - ViT-B-32--laion2b_e16]\")\n",
        "if clip_farsi:\n",
        "  clip_load_list.append(\"[clip - sajjjadayobi - clipfa]\")\n",
        "if clip_korean:\n",
        "  clip_load_list.append(\"[clip - navervision - kelip_ViT-B/32]\")\n",
        "if cloob_ViT_B16:\n",
        "  clip_load_list.append(\"[cloob - crowsonkb - cloob_laion_400m_vit_b_16_32_epochs]\")\n",
        "\n",
        "if model1:\n",
        "  clip_load_list.append(model1)\n",
        "if model2:\n",
        "  clip_load_list.append(model2)\n",
        "if model3:\n",
        "  clip_load_list.append(model3)\n",
        "\n",
        "\n",
        "i = 0\n",
        "from mmc.multimmc import MultiMMC\n",
        "from mmc.modalities import TEXT, IMAGE\n",
        "temp_perceptor = MultiMMC(TEXT, IMAGE)\n",
        "\n",
        "def get_mmc_models(clip_load_list):\n",
        "  mmc_models = []\n",
        "  for model_key in clip_load_list:\n",
        "      if not model_key:\n",
        "          continue\n",
        "      arch, pub, m_id = model_key[1:-1].split(' - ')\n",
        "      mmc_models.append({\n",
        "          'architecture':arch,\n",
        "          'publisher':pub,\n",
        "          'id':m_id,\n",
        "          })\n",
        "  return mmc_models\n",
        "mmc_models = get_mmc_models(clip_load_list)\n",
        "\n",
        "import mmc\n",
        "from mmc.registry import REGISTRY\n",
        "import mmc.loaders  # force trigger model registrations\n",
        "from mmc.mock.openai import MockOpenaiClip\n",
        "\n",
        "normalize = transforms.Normalize(mean=[0.48145466, 0.4578275, 0.40821073],\n",
        "                                 std=[0.26862954, 0.26130258, 0.27577711])\n",
        "\n",
        "\n",
        "def load_clip_models(mmc_models):\n",
        "  clip_model, clip_size, clip_tokenize, clip_normalize= {},{},{},{}\n",
        "  clip_list = []\n",
        "  for item in mmc_models:\n",
        "      print(\"Loaded \", item[\"id\"])\n",
        "      clip_list.append(item[\"id\"])\n",
        "      model_loaders = REGISTRY.find(**item)\n",
        "      for model_loader in model_loaders:\n",
        "          clip_model_loaded = model_loader.load()\n",
        "          clip_model[item[\"id\"]] = MockOpenaiClip(clip_model_loaded)\n",
        "          clip_size[item[\"id\"]] = clip_model[item[\"id\"]].visual.input_resolution\n",
        "          clip_tokenize[item[\"id\"]] = clip_model[item[\"id\"]].preprocess_text()\n",
        "          clip_normalize[item[\"id\"]] = normalize\n",
        "  return clip_model, clip_size, clip_tokenize, clip_normalize, clip_list\n",
        "\n",
        "\n",
        "def full_clip_load(clip_load_list):\n",
        "  torch.cuda.empty_cache()\n",
        "  gc.collect()\n",
        "  try:\n",
        "    del clip_model, clip_size, clip_tokenize, clip_normalize, clip_list\n",
        "  except:\n",
        "    pass\n",
        "  mmc_models = get_mmc_models(clip_load_list)\n",
        "  clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = load_clip_models(mmc_models)\n",
        "  return clip_model, clip_size, clip_tokenize, clip_normalize, clip_list\n",
        "\n",
        "clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "clip_load_list_universal = clip_load_list\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_Di3xFSXGWe"
      },
      "source": [
        "#### Advanced Settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pAALegoCXEbm",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "opt = DotMap()\n",
        "\n",
        "#@markdown ☠️☠️ Change these settings at your own risk! ☠️☠️\n",
        "\n",
        "#@markdown .........$$$ You break it, you bought it, Buddy! $\\$\\$.........\n",
        "\n",
        "#Change it to false to not use CLIP Guidance at all \n",
        "use_cond_fn = True\n",
        "\n",
        "#Custom cut schedules and super-resolution. Check out the guide on how to use it a https://multimodal.art/majestydiffusion\n",
        "#OPTIONS: real, aesrgan and gfpgan, noise , scale\n",
        "custom_schedule_setting = [\n",
        " [50,1000,8],\n",
        " \"gfpgan:1.5\",\"scale:.9\",\"noise:.55\",\n",
        " [50,200,5]\n",
        " ]\n",
        "\n",
        "#Cut settings\n",
        "#clamp_index = [2.1,1.6] #linear variation of the index for clamping the gradient  \n",
        "cut_overview = [8]*500 + [4]*500\n",
        "cut_innercut = [0]*500 + [4]*500\n",
        "cut_ic_pow = .2\n",
        "cut_icgray_p = [.1]*300+[0]*1000\n",
        "cutn_batches = 1\n",
        "cut_blur_n = [0]*300 + [0]*1000\n",
        "cut_blur_kernel = 3\n",
        "range_index =  [0]*200+ [5e4]*400 + [0]*1000\n",
        "var_index = [2]*300+[0]*700\n",
        "var_range = 0.5\n",
        "mean_index =  [0]*400+[0]*600\n",
        "mean_range = 0.75\n",
        "active_function = \"softsign\" # function to manipulate the gradient - help things to stablize\n",
        "ths_method = \"clamp\" #clamp is another option\n",
        "tv_scales = [150]*1+[0]*1 +[0]*2\n",
        "\n",
        "#If you uncomment next line you can schedule the CLIP guidance across the steps. Otherwise the clip_guidance_scale basic setting will be used\n",
        "#clip_guidance_schedule = [10000]*300 + [500]*700\n",
        "\n",
        "symmetric_loss_scale = 0 #Apply symmetric loss\n",
        "\n",
        "#Latent Diffusion Advanced Settings\n",
        "scale_div = 1 # Use when latent upscale to correct satuation problem\n",
        "opt_mag_mul = 20 #Magnify grad before clamping\n",
        "#PLMS Currently not working, working on a fix\n",
        "opt_plms = False #Experimental. It works but does not lookg good\n",
        "opt_ddim_eta, opt_eta_end = [1.3,1.1] # linear variation of eta\n",
        "opt_temperature = .98\n",
        "\n",
        "#Grad advanced settings\n",
        "grad_center = False\n",
        "grad_scale= 0.25 #Lower value result in more coherent and detailed result, higher value makes it focus on more dominent concept\n",
        "\n",
        "#Restraints the model from explodign despite larger clamp\n",
        "score_modifier = True\n",
        "threshold_percentile = .85\n",
        "threshold = 1\n",
        "score_corrector_setting = [\"latent\",\"\"]\n",
        "\n",
        "#Init image advanced settings\n",
        "init_rotate, mask_rotate=[False, False]\n",
        "init_magnitude = 0.18215\n",
        "\n",
        "#Noise settings\n",
        "upscale_noise_temperature = 1\n",
        "upscale_xT_temperature = 1  \n",
        "\n",
        "#More settings\n",
        "RGB_min, RGB_max = [-0.95,0.95]\n",
        "padargs = {\"mode\":\"constant\", \"value\": -1} #How to pad the image with cut_overview\n",
        "flip_aug=False\n",
        "cutout_debug = False\n",
        "opt.outdir = outputs_path\n",
        "\n",
        "#Experimental aesthetic embeddings, work only with OpenAI ViT-B/32 and ViT-L/14\n",
        "experimental_aesthetic_embeddings = True\n",
        "#How much you want this to influence your result\n",
        "experimental_aesthetic_embeddings_weight = 0.3\n",
        "#9 are good aesthetic embeddings, 0 are bad ones\n",
        "experimental_aesthetic_embeddings_score = 8\n",
        "\n",
        "# For fun dont change except if you really know what your are doing\n",
        "grad_blur = False\n",
        "compress_steps = 200\n",
        "compress_factor = 0.1\n",
        "punish_steps = 200\n",
        "punish_factor = 0.5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wo1tM270ryit"
      },
      "source": [
        "### Prompts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "QG4PbNbJnHHC"
      },
      "outputs": [],
      "source": [
        "#Amp up your prompt game with prompt engineering, check out this guide: https://matthewmcateer.me/blog/clip-prompt-engineering/\n",
        "\n",
        " #@markdown ★★ NOTE: Some settings are hidden for your own protection! ★★\n",
        "\n",
        "clip_prompt_1 = \"'Elizabeth Olsen as Scarlet Witch' by Beeple, editorial, medium closeup\" #@param {type:\"string\"}\n",
        "clip_prompt_2 = \"'Elizabeth Olsen as Scarlet Witch' by Alberto Vargas, beauty shot, dynamic comic book pose\" #@param {type:\"string\"}\n",
        "\n",
        "use_clip_prompts = \"BOTH\" #@param [\"1\", \"2\", \"BOTH\"]\n",
        "\n",
        "if(use_clip_prompts == '1'):\n",
        "  clip_prompt_2 = \"\"\n",
        "\n",
        "elif(use_clip_prompts == '2'):\n",
        "  clip_prompt_1 = \"\"\n",
        "\n",
        "clip_prompts = [clip_prompt_1+\":10\", clip_prompt_2+\":10\"]\n",
        "\n",
        "latent_prompts = \"psychedelic, godheat, vitrage, melting, shiny, glisten, female portrait\" #@param {type:\"string\"}\n",
        "\n",
        "latent_negatives = \"abstract, newsprint\" #@param {type:\"string\"}\n",
        "\n",
        "use_image_prompts = \"HIZGI\" #@param [\"None\", \"Peanuts\", \"HIZGI\", \"Sacred Hearts\", \"Zombie Girls\", \"Acid Tears\", \"Junji Ito\", \"happi_115\"]\n",
        "\n",
        "if(use_image_prompts == 'None'):\n",
        "  image_prompts = \"\"\n",
        "\n",
        "elif(use_image_prompts == 'happi_115'):\n",
        "  image_prompts = ['https://i.imgur.com/QNLArPD.jpg',\n",
        "  'https://i.imgur.com/TnoKCDD.jpg',\n",
        "  'https://i.imgur.com/vJR14pW.jpg',\n",
        "  'https://i.imgur.com/sgMxOrG.jpg',\n",
        "  'https://i.imgur.com/nz9CK2T.jpg',\n",
        "  'https://i.imgur.com/szQDnBp.jpg',\n",
        "  'https://i.imgur.com/Gk4UWWk.jpg',\n",
        "  'https://i.imgur.com/mZXZyew.jpg',\n",
        "  'https://i.imgur.com/kOqu2qM.jpg',\n",
        "  'https://i.imgur.com/RbZblIL.jpg',\n",
        "  'https://i.imgur.com/N9PVbvc.jpg',\n",
        "  'https://i.imgur.com/jQSoSHD.jpg',\n",
        "  'https://i.imgur.com/r8zHNi2.jpg',\n",
        "  'https://i.imgur.com/y3uMM9a.jpg',\n",
        "  'https://i.imgur.com/e0yLDTQ.jpg',\n",
        "  'https://i.imgur.com/luG4tk0.jpg',\n",
        "  'https://i.imgur.com/ZdqYxCP.jpg',\n",
        "  'https://i.imgur.com/iIUlc4D.jpg',\n",
        "  'https://i.imgur.com/fEW4cLQ.jpg',\n",
        "  'https://i.imgur.com/Wf32sDo.jpg']\n",
        "\n",
        "elif(use_image_prompts == 'Peanuts'):\n",
        "  image_prompts = ['https://i.imgur.com/4uXr4m2.jpg',\n",
        "                  'https://i.imgur.com/MA2tkMM.jpg',\n",
        "                  'https://i.imgur.com/mOAUvWs.jpg',\n",
        "                  'https://i.imgur.com/uzAezMs.jpg',\n",
        "                  'https://i.imgur.com/rDlxzvo.jpg',\n",
        "                  'https://i.imgur.com/OeWShf3.jpg',\n",
        "                  'https://i.imgur.com/OX1Z4YK.jpg',\n",
        "                  'https://i.imgur.com/BJ5u2IV.jpg',\n",
        "                  'https://i.imgur.com/jcfbHMp.jpg',\n",
        "                  'https://i.imgur.com/9U6tfOv.jpg',\n",
        "                  'https://i.imgur.com/GCqFktt.jpg',\n",
        "                  'https://i.imgur.com/WGsM5bm.jpg',\n",
        "                  'https://i.imgur.com/sD9eolo.jpg',\n",
        "                  'https://i.imgur.com/nwJMQsj.png',\n",
        "                  'https://i.imgur.com/mNZqGmV.png',\n",
        "                  'https://i.imgur.com/92Fl823.png',\n",
        "                  'https://i.imgur.com/4uXr4m2.jpg',\n",
        "                  'https://i.imgur.com/tuqGy2n.jpg',\n",
        "                  'https://i.imgur.com/eiU2LbW.jpg',\n",
        "                  'https://i.imgur.com/Gek3XB5.jpg',\n",
        "                  'https://i.imgur.com/BfGyD3D.jpg',\n",
        "                  'https://i.imgur.com/wDaJAnT.jpg',\n",
        "                  'https://i.imgur.com/JdTat8K.jpg',\n",
        "                  'https://i.imgur.com/vVWM0v0.jpg']\n",
        "\n",
        "elif(use_image_prompts == 'HIZGI'):\n",
        "  image_prompts = ['https://i.imgur.com/qhZ74Uv.jpg',\n",
        "                  'https://i.imgur.com/Vfw76eC.jpg',\n",
        "                  'https://i.imgur.com/NcWgBT8.jpg',\n",
        "                  'https://i.imgur.com/RdndWZW.jpg',\n",
        "                  'https://i.imgur.com/mzbB3sD.jpg',\n",
        "                  'https://i.imgur.com/7QUvEKN.jpg',\n",
        "                  'https://i.imgur.com/tW0ZEAr.jpg',\n",
        "                  'https://i.imgur.com/SD8oso0.jpg',\n",
        "                  'https://i.imgur.com/hYOPSRn.jpg',\n",
        "                  'https://i.imgur.com/VmkgX5N.jpg',\n",
        "                  'https://i.imgur.com/vhkhjC7.jpg',\n",
        "                  'https://i.imgur.com/sIxnbY3.jpg',\n",
        "                  'https://i.imgur.com/EbUzqa8.jpg',\n",
        "                  'https://i.imgur.com/3VOCXnI.jpg',\n",
        "                  'https://i.imgur.com/NwlTFB9.jpg',\n",
        "                  'https://i.imgur.com/3BwKUiX.jpg',\n",
        "                  'https://i.imgur.com/APfeQRu.jpg',\n",
        "                  'https://i.imgur.com/ewKEtH7.jpg',\n",
        "                  'https://i.imgur.com/EHZRM62.jpg',\n",
        "                  'https://i.imgur.com/WNrWcg0.png']\n",
        "\n",
        "elif(use_image_prompts == 'Sacred Hearts'):\n",
        "  image_prompts = ['https://i.imgur.com/kNuWWOh.png', \n",
        "                  'https://i.imgur.com/2wzf6O3.jpg', \n",
        "                  'https://i.imgur.com/Y1epjKb.jpg',\n",
        "                  'https://i.imgur.com/RM3m8Cl.jpg',\n",
        "                  'https://i.imgur.com/YcTFCKo.jpg',\n",
        "                  'https://i.imgur.com/3JezPbc.jpg']\n",
        "\n",
        "elif(use_image_prompts == 'Zombie Girls'):\n",
        "  image_prompts = ['https://i.imgur.com/Lff3ma0.jpg',\n",
        "                  'https://i.imgur.com/6mt4A6G.jpg',\n",
        "                  'https://i.imgur.com/qkMV7Cs.jpg',\n",
        "                  'https://i.imgur.com/4K7OPe8.jpg',\n",
        "                  'https://i.imgur.com/JeZy34S.jpg',\n",
        "                  'https://i.imgur.com/99BNSJg.jpg',\n",
        "                  'https://i.imgur.com/Y1GAgmT.jpg',\n",
        "                  'https://i.imgur.com/gUvECmC.jpg',\n",
        "                  'https://i.imgur.com/MhOlE6w.jpg',\n",
        "                  'https://i.imgur.com/ZZHW8ba.jpg',\n",
        "                  'https://i.imgur.com/tETzedX.jpg',]\n",
        "\n",
        "elif(use_image_prompts == 'Acid Tears'):\n",
        "  image_prompts = ['https://i.imgur.com/qsQswrS.jpg',\n",
        "                   'https://i.imgur.com/s9ESHk3.jpg',\n",
        "                   'https://i.imgur.com/I8CFG4c.jpg',\n",
        "                   'https://i.imgur.com/dct29mL.jpg',\n",
        "                   'https://i.imgur.com/M8v6waw.jpg',\n",
        "                   'https://i.imgur.com/8HEe8Me.jpg',\n",
        "                   'https://i.imgur.com/42iYqpi.jpg',\n",
        "                   'https://i.imgur.com/ZgZUEL5.jpg',\n",
        "                   'https://i.imgur.com/gNwCbGu.png',\n",
        "                   'https://i.imgur.com/MQD6VFQ.jpg',\n",
        "                   'https://i.imgur.com/5o8HJlO.jpg',\n",
        "                   'https://i.imgur.com/EZdiAWL.jpg',\n",
        "                   'https://i.imgur.com/yg9mroo.jpg']\n",
        "\n",
        "elif(use_image_prompts == 'Junji Ito'):\n",
        "  image_prompts = ['https://i.imgur.com/KTAAvse.jpg',\n",
        "                  'https://i.imgur.com/Ss4PWaN.png',\n",
        "                  'https://i.imgur.com/sL70oJ0.png',\n",
        "                  'https://i.imgur.com/P78yGwD.jpg',\n",
        "                  'https://i.imgur.com/Q410277.png',\n",
        "                  'https://i.imgur.com/0QLzlYJ.jpg',\n",
        "                  'https://i.imgur.com/QGhyoqZ.png',\n",
        "                  'https://i.imgur.com/IUtRLkn.jpg',\n",
        "                  'https://i.imgur.com/cTJUX0F.jpg',\n",
        "                  'https://i.imgur.com/grbcHkx.jpg',]\n",
        "\n",
        "print(clip_prompts)\n",
        "print(image_prompts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mnb6GiALBAK1"
      },
      "source": [
        "# Run!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Default Basic Run"
      ],
      "metadata": {
        "id": "qmaBpzOCBIj3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "fmafGmcyT1mZ"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#@markdown We're still figuring out default settings. Experiment and <a href=\"https://huggingface.co/datasets/multimodalart/latent-majesty-diffusion-settings\">share your settings with us</a>\n",
        "width =  256#@param{type: 'integer'}\n",
        "height =  384#@param{type: 'integer'}\n",
        "#@markdown The `latent_diffusion_guidance_scale` will determine how much the `latent_prompts` affect the image. Lower help with text interpretation, higher help with composition. Try values between 0-15. If you see too much text, lower it  \n",
        "latent_diffusion_guidance_scale = 12 #@param {type:\"number\"}\n",
        "#@markdown The `clamp_index` will determine how much of the `clip_prompts` affect the image, it is a linear scale that will decrease from the first to the second value. Try values between 3-1\n",
        "clamp_index = [2.4, 2.1] #@param{type: 'raw'}\n",
        "clip_guidance_scale =  16000#@param{type: 'integer'}\n",
        "how_many_batches = 1 #@param{type: 'integer'}\n",
        "aesthetic_loss_scale = 100 #@param{type: 'integer'}\n",
        "augment_cuts=True #@param{type:'boolean'}\n",
        "\n",
        "#@markdown\n",
        "\n",
        "#@markdown  ### Init image settings\n",
        "#@markdown `init_image` requires the path of an image to use as init to the model\n",
        "init_image = \"\" #@param{type: 'string'}\n",
        "if(init_image == '' or init_image == 'None'):\n",
        "  init_image = None\n",
        "\n",
        "#@markdown `starting_timestep`: How much noise do you want to add to your init image for it to then be difused by the model\n",
        "#default 0.9\n",
        "starting_timestep = 0.9 #@param{type: 'number'}\n",
        "\n",
        "#@markdown `init_mask` is a mask same width and height as the original image with the color black indicating where to inpaint\n",
        "init_mask = None #@param{type: 'string'}\n",
        "\n",
        "#@markdown `init_scale` controls how much the init image should influence the final result. Experiment with values around `1000`\n",
        "init_scale = 1000 #@param{type: 'integer'}\n",
        "#default 0.0\n",
        "init_brightness = 0.0 #@param{type: 'number'}\n",
        "\n",
        "#  @markdown How much extra noise to add to the init image, independently from skipping timesteps (use it also if you are upscaling)\n",
        "#default 0.57\n",
        "init_noise = 0.57 #@param{type: 'number'}\n",
        "\n",
        "#@markdown\n",
        "\n",
        "#@markdown ### Custom saved settings\n",
        "#@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "custom_settings = 'path/to/settings.cfg' #@param{type:'string'}\n",
        "settings_library = 'None (use settings defined above)' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "if(settings_library != 'None (use settings defined above)'):\n",
        "  custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "\n",
        "#Doing the run (do not change):\n",
        "\n",
        "global_var_scope = globals()\n",
        "if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "  print('Loaded ', custom_settings)\n",
        "  try:\n",
        "    from configparser import ConfigParser\n",
        "  except ImportError:\n",
        "      from ConfigParser import ConfigParser\n",
        "  import configparser\n",
        "  \n",
        "  config = ConfigParser()\n",
        "  config.read(custom_settings)\n",
        "  #custom_settings_stream = fetch(custom_settings)\n",
        "  #Load CLIP models from config\n",
        "  if(config.has_section('clip_list')):\n",
        "    clip_incoming_list = config.items('clip_list')\n",
        "    clip_incoming_models = clip_incoming_list[0]\n",
        "    incoming_perceptors = eval(clip_incoming_models[1])\n",
        "    if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "      clip_load_list = incoming_perceptors\n",
        "      clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "  #Load settings from config and replace variables\n",
        "  if(config.has_section('basic_settings')):\n",
        "    basic_settings = config.items('basic_settings')\n",
        "    for basic_setting in basic_settings:\n",
        "      global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "  \n",
        "  if(config.has_section('advanced_settings')):\n",
        "    advanced_settings = config.items('advanced_settings')\n",
        "    for advanced_setting in advanced_settings:\n",
        "      global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "  custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "prompts = clip_prompts\n",
        "opt.prompt = latent_prompts\n",
        "opt.uc = latent_negatives\n",
        "custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "aes_scale = aesthetic_loss_scale\n",
        "try: \n",
        "  clip_guidance_schedule\n",
        "  clip_guidance_index = clip_guidance_schedule\n",
        "except:\n",
        "  clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "global progress\n",
        "progress = widgets.Image(layout = widgets.Layout(max_width = \"400px\",max_height = \"512px\"))\n",
        "display.display(progress)\n",
        "for n in trange(how_many_batches, desc=\"Sampling\"):\n",
        "  print(f\"Sampling images {n+1}/{how_many_batches}\")\n",
        "  opt.W = (width//64)*64;\n",
        "  opt.H = (height//64)*64;\n",
        "  if opt.W != width or opt.H != height:\n",
        "      print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "  opt.mag_mul = opt_mag_mul \n",
        "  opt.ddim_eta = opt_ddim_eta\n",
        "  opt.eta_end = opt_eta_end\n",
        "  opt.temperature = opt_temperature\n",
        "\n",
        "  opt.scale = latent_diffusion_guidance_scale\n",
        "  opt.plms = opt_plms\n",
        "  aug = augment_cuts\n",
        "\n",
        "  #Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "  if(len(clamp_index) == 2): \n",
        "    clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "  else:\n",
        "    clamp_index_variation = clamp_index\n",
        "  score_corrector = DotMap()\n",
        "\n",
        "\n",
        "  def modify_score(e_t, e_t_uncond):\n",
        "          if(score_modifier is False):\n",
        "            return e_t\n",
        "          else:\n",
        "            e_t_d = (e_t - e_t_uncond)\n",
        "            s = torch.quantile(\n",
        "                rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "                threshold_percentile,\n",
        "                dim = -1\n",
        "            )\n",
        "\n",
        "          s.clamp_(min = 1.)\n",
        "          s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "          if ths_method == \"softsign\":\n",
        "              e_t_d = F.softsign(e_t_d) / s \n",
        "          elif ths_method == \"clamp\":\n",
        "              e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "          e_t = e_t_uncond + e_t_d\n",
        "          return(e_t)\n",
        "            \n",
        "  score_corrector.modify_score = modify_score\n",
        "\n",
        "  def dynamic_thresholding(pred_x0,t):\n",
        "      return(pred_x0)\n",
        "\n",
        "  opt.n_iter = 1 #Old way for batching, avoid touching\n",
        "  opt.n_samples =  1 #How many implaes in parallel. Breaks upscaling\n",
        "  torch.cuda.empty_cache()\n",
        "  gc.collect()\n",
        "  generate_video = False\n",
        "  if generate_video: \n",
        "      fps = 24\n",
        "      p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "  do_run()\n",
        "  if generate_video: \n",
        "      p.stdin.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CLIP+Latent Paternity Testing"
      ],
      "metadata": {
        "id": "X6MoCizPf-T9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![clip+latent.png](https://user-images.githubusercontent.com/25991860/176767853-e4a4848e-0cf6-468a-a2ef-37beec7852fe.png)"
      ],
      "metadata": {
        "id": "td7cSP1_Pzvs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "WSCIm08qsK8r"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "#@markdown ### **1.1** CLIP Prompt 1 Test\n",
        "\n",
        "run_clip_test = True #@param{type:'boolean'}\n",
        "if(run_clip_test):\n",
        "\n",
        "  width =  256\n",
        "  height =  384\n",
        "  clip_guidance_scale =  50000\n",
        "  latent_diffusion_guidance_scale = 0\n",
        "  clamp_index = [1, 1]\n",
        "  aesthetic_loss_scale = 100\n",
        "  augment_cuts = True\n",
        "\n",
        "  how_many_batches = 1 #@param{type: 'integer'}\n",
        "\n",
        "  clip_prompts = [clip_prompt_1+\":10\", clip_prompt_2+\":0\"]\n",
        "  print(clip_prompts)\n",
        "\n",
        "  #@markdown  ### Init image settings\n",
        "  init_image = \"\" #@param{type: 'string'}\n",
        "  if(init_image == '' or init_image == 'None'):\n",
        "    init_image = None\n",
        "\n",
        "  starting_timestep = 0.9 #@param{type: 'number'}\n",
        "\n",
        "  init_mask = None #@param{type: 'string'}\n",
        "\n",
        "  init_scale = 1000 #@param{type: 'integer'}\n",
        "  init_brightness = 0.0 #@param{type: 'number'}\n",
        "\n",
        "  #init_noise = 0.57 #@param{type: 'number'}\n",
        "\n",
        "\n",
        "  #@markdown ### Custom saved settings\n",
        "  #@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "  custom_settings = 'path/to/settings.cfg' #@param{type:'string'}\n",
        "  settings_library = 'None (use settings defined above)' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "  if(settings_library != 'None (use settings defined above)'):\n",
        "    custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "  global_var_scope = globals()\n",
        "  if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "    print('Loaded ', custom_settings)\n",
        "    try:\n",
        "      from configparser import ConfigParser\n",
        "    except ImportError:\n",
        "        from ConfigParser import ConfigParser\n",
        "    import configparser\n",
        "    \n",
        "    config = ConfigParser()\n",
        "    config.read(custom_settings)\n",
        "    #custom_settings_stream = fetch(custom_settings)\n",
        "    #Load CLIP models from config\n",
        "    if(config.has_section('clip_list')):\n",
        "      clip_incoming_list = config.items('clip_list')\n",
        "      clip_incoming_models = clip_incoming_list[0]\n",
        "      incoming_perceptors = eval(clip_incoming_models[1])\n",
        "      if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "        clip_load_list = incoming_perceptors\n",
        "        clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "    #Load settings from config and replace variables\n",
        "    if(config.has_section('basic_settings')):\n",
        "      basic_settings = config.items('basic_settings')\n",
        "      for basic_setting in basic_settings:\n",
        "        global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "    \n",
        "    if(config.has_section('advanced_settings')):\n",
        "      advanced_settings = config.items('advanced_settings')\n",
        "      for advanced_setting in advanced_settings:\n",
        "        global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "  if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "    custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "  prompts = clip_prompts\n",
        "  opt.prompt = latent_prompts\n",
        "  opt.uc = latent_negatives\n",
        "  custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "  aes_scale = aesthetic_loss_scale\n",
        "  try: \n",
        "    clip_guidance_schedule\n",
        "    clip_guidance_index = clip_guidance_schedule\n",
        "  except:\n",
        "    clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "  global progress\n",
        "  progress = widgets.Image(layout = widgets.Layout(max_width = \"400px\",max_height = \"512px\"))\n",
        "  display.display(progress)\n",
        "  for n in trange(how_many_batches, desc=\"Sampling\"):\n",
        "    print(f\"Sampling images {n+1}/{how_many_batches}\")\n",
        "    opt.W = (width//64)*64;\n",
        "    opt.H = (height//64)*64;\n",
        "    if opt.W != width or opt.H != height:\n",
        "        print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "    opt.mag_mul = opt_mag_mul \n",
        "    opt.ddim_eta = opt_ddim_eta\n",
        "    opt.eta_end = opt_eta_end\n",
        "    opt.temperature = opt_temperature\n",
        "\n",
        "    opt.scale = latent_diffusion_guidance_scale\n",
        "    opt.plms = opt_plms\n",
        "    aug = augment_cuts\n",
        "\n",
        "    #Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "    if(len(clamp_index) == 2): \n",
        "      clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "    else:\n",
        "      clamp_index_variation = clamp_index\n",
        "    score_corrector = DotMap()\n",
        "\n",
        "\n",
        "    def modify_score(e_t, e_t_uncond):\n",
        "            if(score_modifier is False):\n",
        "              return e_t\n",
        "            else:\n",
        "              e_t_d = (e_t - e_t_uncond)\n",
        "              s = torch.quantile(\n",
        "                  rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "                  threshold_percentile,\n",
        "                  dim = -1\n",
        "              )\n",
        "\n",
        "            s.clamp_(min = 1.)\n",
        "            s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "            if ths_method == \"softsign\":\n",
        "                e_t_d = F.softsign(e_t_d) / s \n",
        "            elif ths_method == \"clamp\":\n",
        "                e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "            e_t = e_t_uncond + e_t_d\n",
        "            return(e_t)\n",
        "              \n",
        "    score_corrector.modify_score = modify_score\n",
        "\n",
        "    def dynamic_thresholding(pred_x0,t):\n",
        "        return(pred_x0)\n",
        "\n",
        "    opt.n_iter = 1 #Old way for batching, avoid touching\n",
        "    opt.n_samples =  1 #How many implaes in parallel. Breaks upscaling\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    generate_video = False\n",
        "    if generate_video: \n",
        "        fps = 24\n",
        "        p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "    do_run()\n",
        "    if generate_video: \n",
        "        p.stdin.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "PDtS3sRysaHH"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "#@markdown ### **1.2** CLIP Prompt 2 Test\n",
        "\n",
        "run_clip_test = True #@param{type:'boolean'}\n",
        "if(run_clip_test):\n",
        "\n",
        "  width =  256\n",
        "  height =  384\n",
        "  clip_guidance_scale =  50000\n",
        "  latent_diffusion_guidance_scale = 0\n",
        "  clamp_index = [1, 1]\n",
        "  aesthetic_loss_scale = 100\n",
        "  augment_cuts = True\n",
        "\n",
        "  how_many_batches = 1 #@param{type: 'integer'}\n",
        "\n",
        "  clip_prompts = [clip_prompt_1+\":0\", clip_prompt_2+\":10\"]\n",
        "  print(clip_prompts)\n",
        "\n",
        "  #@markdown  ### Init image settings\n",
        "  init_image = \"\" #@param{type: 'string'}\n",
        "  if(init_image == '' or init_image == 'None'):\n",
        "    init_image = None\n",
        "\n",
        "  starting_timestep = 0.9 #@param{type: 'number'}\n",
        "\n",
        "  init_mask = None #@param{type: 'string'}\n",
        "\n",
        "  init_scale = 1000 #@param{type: 'integer'}\n",
        "  init_brightness = 0.0 #@param{type: 'number'}\n",
        "\n",
        "  #init_noise = 0.57 #@param{type: 'number'}\n",
        "\n",
        "\n",
        "  #@markdown ### Custom saved settings\n",
        "  #@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "  custom_settings = 'path/to/settings.cfg' #@param{type:'string'}\n",
        "  settings_library = 'None (use settings defined above)' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "  if(settings_library != 'None (use settings defined above)'):\n",
        "    custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "  global_var_scope = globals()\n",
        "  if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "    print('Loaded ', custom_settings)\n",
        "    try:\n",
        "      from configparser import ConfigParser\n",
        "    except ImportError:\n",
        "        from ConfigParser import ConfigParser\n",
        "    import configparser\n",
        "    \n",
        "    config = ConfigParser()\n",
        "    config.read(custom_settings)\n",
        "    #custom_settings_stream = fetch(custom_settings)\n",
        "    #Load CLIP models from config\n",
        "    if(config.has_section('clip_list')):\n",
        "      clip_incoming_list = config.items('clip_list')\n",
        "      clip_incoming_models = clip_incoming_list[0]\n",
        "      incoming_perceptors = eval(clip_incoming_models[1])\n",
        "      if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "        clip_load_list = incoming_perceptors\n",
        "        clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "    #Load settings from config and replace variables\n",
        "    if(config.has_section('basic_settings')):\n",
        "      basic_settings = config.items('basic_settings')\n",
        "      for basic_setting in basic_settings:\n",
        "        global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "    \n",
        "    if(config.has_section('advanced_settings')):\n",
        "      advanced_settings = config.items('advanced_settings')\n",
        "      for advanced_setting in advanced_settings:\n",
        "        global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "  if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "    custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "  prompts = clip_prompts\n",
        "  opt.prompt = latent_prompts\n",
        "  opt.uc = latent_negatives\n",
        "  custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "  aes_scale = aesthetic_loss_scale\n",
        "  try: \n",
        "    clip_guidance_schedule\n",
        "    clip_guidance_index = clip_guidance_schedule\n",
        "  except:\n",
        "    clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "  global progress\n",
        "  progress = widgets.Image(layout = widgets.Layout(max_width = \"400px\",max_height = \"512px\"))\n",
        "  display.display(progress)\n",
        "  for n in trange(how_many_batches, desc=\"Sampling\"):\n",
        "    print(f\"Sampling images {n+1}/{how_many_batches}\")\n",
        "    opt.W = (width//64)*64;\n",
        "    opt.H = (height//64)*64;\n",
        "    if opt.W != width or opt.H != height:\n",
        "        print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "    opt.mag_mul = opt_mag_mul \n",
        "    opt.ddim_eta = opt_ddim_eta\n",
        "    opt.eta_end = opt_eta_end\n",
        "    opt.temperature = opt_temperature\n",
        "\n",
        "    opt.scale = latent_diffusion_guidance_scale\n",
        "    opt.plms = opt_plms\n",
        "    aug = augment_cuts\n",
        "\n",
        "    #Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "    if(len(clamp_index) == 2): \n",
        "      clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "    else:\n",
        "      clamp_index_variation = clamp_index\n",
        "    score_corrector = DotMap()\n",
        "\n",
        "\n",
        "    def modify_score(e_t, e_t_uncond):\n",
        "            if(score_modifier is False):\n",
        "              return e_t\n",
        "            else:\n",
        "              e_t_d = (e_t - e_t_uncond)\n",
        "              s = torch.quantile(\n",
        "                  rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "                  threshold_percentile,\n",
        "                  dim = -1\n",
        "              )\n",
        "\n",
        "            s.clamp_(min = 1.)\n",
        "            s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "            if ths_method == \"softsign\":\n",
        "                e_t_d = F.softsign(e_t_d) / s \n",
        "            elif ths_method == \"clamp\":\n",
        "                e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "            e_t = e_t_uncond + e_t_d\n",
        "            return(e_t)\n",
        "              \n",
        "    score_corrector.modify_score = modify_score\n",
        "\n",
        "    def dynamic_thresholding(pred_x0,t):\n",
        "        return(pred_x0)\n",
        "\n",
        "    opt.n_iter = 1 #Old way for batching, avoid touching\n",
        "    opt.n_samples =  1 #How many implaes in parallel. Breaks upscaling\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    generate_video = False\n",
        "    if generate_video: \n",
        "        fps = 24\n",
        "        p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "    do_run()\n",
        "    if generate_video: \n",
        "        p.stdin.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "MRhqLoSynCMf"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "#@markdown ### **1.3** CLIP Prompt 1+2 Test\n",
        "\n",
        "run_clip_test = True #@param{type:'boolean'}\n",
        "if(run_clip_test):\n",
        "\n",
        "  width =  256\n",
        "  height =  384\n",
        "  clip_guidance_scale =  50000\n",
        "  latent_diffusion_guidance_scale = 0\n",
        "  clamp_index = [1, 1]\n",
        "  aesthetic_loss_scale = 100\n",
        "  augment_cuts = True\n",
        "\n",
        "  how_many_batches = 1 #@param{type: 'integer'}\n",
        "\n",
        "  clip_prompts = [clip_prompt_1+\":10\", clip_prompt_2+\":10\"]\n",
        "  \n",
        "  print(clip_prompts)\n",
        "  print(latent_prompts)\n",
        "\n",
        "  #@markdown  ### Init image settings\n",
        "  init_image = \"\" #@param{type: 'string'}\n",
        "  if(init_image == '' or init_image == 'None'):\n",
        "    init_image = None\n",
        "\n",
        "  starting_timestep = 0.9 #@param{type: 'number'}\n",
        "\n",
        "  init_mask = None #@param{type: 'string'}\n",
        "\n",
        "  init_scale = 1000 #@param{type: 'integer'}\n",
        "  init_brightness = 0.0 #@param{type: 'number'}\n",
        "\n",
        "  #init_noise = 0.57 #@param{type: 'number'}\n",
        "\n",
        "\n",
        "  #@markdown ### Custom saved settings\n",
        "  #@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "  custom_settings = 'path/to/settings.cfg' #@param{type:'string'}\n",
        "  settings_library = 'None (use settings defined above)' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "  if(settings_library != 'None (use settings defined above)'):\n",
        "    custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "  global_var_scope = globals()\n",
        "  if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "    print('Loaded ', custom_settings)\n",
        "    try:\n",
        "      from configparser import ConfigParser\n",
        "    except ImportError:\n",
        "        from ConfigParser import ConfigParser\n",
        "    import configparser\n",
        "    \n",
        "    config = ConfigParser()\n",
        "    config.read(custom_settings)\n",
        "    #custom_settings_stream = fetch(custom_settings)\n",
        "    #Load CLIP models from config\n",
        "    if(config.has_section('clip_list')):\n",
        "      clip_incoming_list = config.items('clip_list')\n",
        "      clip_incoming_models = clip_incoming_list[0]\n",
        "      incoming_perceptors = eval(clip_incoming_models[1])\n",
        "      if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "        clip_load_list = incoming_perceptors\n",
        "        clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "    #Load settings from config and replace variables\n",
        "    if(config.has_section('basic_settings')):\n",
        "      basic_settings = config.items('basic_settings')\n",
        "      for basic_setting in basic_settings:\n",
        "        global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "    \n",
        "    if(config.has_section('advanced_settings')):\n",
        "      advanced_settings = config.items('advanced_settings')\n",
        "      for advanced_setting in advanced_settings:\n",
        "        global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "  if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "    custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "  prompts = clip_prompts\n",
        "  opt.prompt = latent_prompts\n",
        "  opt.uc = latent_negatives\n",
        "  custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "  aes_scale = aesthetic_loss_scale\n",
        "  try: \n",
        "    clip_guidance_schedule\n",
        "    clip_guidance_index = clip_guidance_schedule\n",
        "  except:\n",
        "    clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "  global progress\n",
        "  progress = widgets.Image(layout = widgets.Layout(max_width = \"400px\",max_height = \"512px\"))\n",
        "  display.display(progress)\n",
        "  for n in trange(how_many_batches, desc=\"Sampling\"):\n",
        "    print(f\"Sampling images {n+1}/{how_many_batches}\")\n",
        "    opt.W = (width//64)*64;\n",
        "    opt.H = (height//64)*64;\n",
        "    if opt.W != width or opt.H != height:\n",
        "        print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "    opt.mag_mul = opt_mag_mul \n",
        "    opt.ddim_eta = opt_ddim_eta\n",
        "    opt.eta_end = opt_eta_end\n",
        "    opt.temperature = opt_temperature\n",
        "\n",
        "    opt.scale = latent_diffusion_guidance_scale\n",
        "    opt.plms = opt_plms\n",
        "    aug = augment_cuts\n",
        "\n",
        "    #Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "    if(len(clamp_index) == 2): \n",
        "      clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "    else:\n",
        "      clamp_index_variation = clamp_index\n",
        "    score_corrector = DotMap()\n",
        "\n",
        "\n",
        "    def modify_score(e_t, e_t_uncond):\n",
        "            if(score_modifier is False):\n",
        "              return e_t\n",
        "            else:\n",
        "              e_t_d = (e_t - e_t_uncond)\n",
        "              s = torch.quantile(\n",
        "                  rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "                  threshold_percentile,\n",
        "                  dim = -1\n",
        "              )\n",
        "\n",
        "            s.clamp_(min = 1.)\n",
        "            s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "            if ths_method == \"softsign\":\n",
        "                e_t_d = F.softsign(e_t_d) / s \n",
        "            elif ths_method == \"clamp\":\n",
        "                e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "            e_t = e_t_uncond + e_t_d\n",
        "            return(e_t)\n",
        "              \n",
        "    score_corrector.modify_score = modify_score\n",
        "\n",
        "    def dynamic_thresholding(pred_x0,t):\n",
        "        return(pred_x0)\n",
        "\n",
        "    opt.n_iter = 1 #Old way for batching, avoid touching\n",
        "    opt.n_samples =  1 #How many implaes in parallel. Breaks upscaling\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    generate_video = False\n",
        "    if generate_video: \n",
        "        fps = 24\n",
        "        p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "    do_run()\n",
        "    if generate_video: \n",
        "        p.stdin.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "93giQXphn0ln"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "#@markdown ### **2.** Latent Prompt Test\n",
        "\n",
        "run_latent_test = True #@param{type:'boolean'}\n",
        "if(run_latent_test):\n",
        "\n",
        "  width =  384\n",
        "  height =  256\n",
        "  clip_guidance_scale =  0\n",
        "  latent_diffusion_guidance_scale = 15\n",
        "  clamp_index = [1.5, 1.5]\n",
        "  aesthetic_loss_scale = 100\n",
        "  augment_cuts = True\n",
        "\n",
        "  clip_prompts = [clip_prompt_1+\":0\", clip_prompt_2+\":0\"]\n",
        "\n",
        "  print(clip_prompts)\n",
        "  print(latent_prompts)\n",
        "\n",
        "  how_many_batches = 1 #@param{type: 'integer'}\n",
        "\n",
        "  #@markdown  ### Init image settings\n",
        "  init_image = \"\" #@param{type: 'string'}\n",
        "  if(init_image == '' or init_image == 'None'):\n",
        "    init_image = None\n",
        "\n",
        "  starting_timestep = 0.9 #@param{type: 'number'}\n",
        "\n",
        "  init_mask = None #@param{type: 'string'}\n",
        "\n",
        "  init_scale = 1000 #@param{type: 'integer'}\n",
        "  init_brightness = 0.0 #@param{type: 'number'}\n",
        "\n",
        "  #init_noise = 0.57 #@param{type: 'number'}\n",
        "\n",
        "\n",
        "  #@markdown ### Custom saved settings\n",
        "  #@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "  custom_settings = 'path/to/settings.cfg' #@param{type:'string'}\n",
        "  settings_library = 'None (use settings defined above)' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "  if(settings_library != 'None (use settings defined above)'):\n",
        "    custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "  global_var_scope = globals()\n",
        "  if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "    print('Loaded ', custom_settings)\n",
        "    try:\n",
        "      from configparser import ConfigParser\n",
        "    except ImportError:\n",
        "        from ConfigParser import ConfigParser\n",
        "    import configparser\n",
        "    \n",
        "    config = ConfigParser()\n",
        "    config.read(custom_settings)\n",
        "    #custom_settings_stream = fetch(custom_settings)\n",
        "    #Load CLIP models from config\n",
        "    if(config.has_section('clip_list')):\n",
        "      clip_incoming_list = config.items('clip_list')\n",
        "      clip_incoming_models = clip_incoming_list[0]\n",
        "      incoming_perceptors = eval(clip_incoming_models[1])\n",
        "      if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "        clip_load_list = incoming_perceptors\n",
        "        clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "    #Load settings from config and replace variables\n",
        "    if(config.has_section('basic_settings')):\n",
        "      basic_settings = config.items('basic_settings')\n",
        "      for basic_setting in basic_settings:\n",
        "        global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "    \n",
        "    if(config.has_section('advanced_settings')):\n",
        "      advanced_settings = config.items('advanced_settings')\n",
        "      for advanced_setting in advanced_settings:\n",
        "        global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "  if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "    custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "  prompts = clip_prompts\n",
        "  opt.prompt = latent_prompts\n",
        "  opt.uc = latent_negatives\n",
        "  custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "  aes_scale = aesthetic_loss_scale\n",
        "  try: \n",
        "    clip_guidance_schedule\n",
        "    clip_guidance_index = clip_guidance_schedule\n",
        "  except:\n",
        "    clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "  global progress\n",
        "  progress = widgets.Image(layout = widgets.Layout(max_width = \"400px\",max_height = \"512px\"))\n",
        "  display.display(progress)\n",
        "  for n in trange(how_many_batches, desc=\"Sampling\"):\n",
        "    print(f\"Sampling images {n+1}/{how_many_batches}\")\n",
        "    opt.W = (width//64)*64;\n",
        "    opt.H = (height//64)*64;\n",
        "    if opt.W != width or opt.H != height:\n",
        "        print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "    opt.mag_mul = opt_mag_mul \n",
        "    opt.ddim_eta = opt_ddim_eta\n",
        "    opt.eta_end = opt_eta_end\n",
        "    opt.temperature = opt_temperature\n",
        "\n",
        "    opt.scale = latent_diffusion_guidance_scale\n",
        "    opt.plms = opt_plms\n",
        "    aug = augment_cuts\n",
        "\n",
        "    #Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "    if(len(clamp_index) == 2): \n",
        "      clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "    else:\n",
        "      clamp_index_variation = clamp_index\n",
        "    score_corrector = DotMap()\n",
        "\n",
        "\n",
        "    def modify_score(e_t, e_t_uncond):\n",
        "            if(score_modifier is False):\n",
        "              return e_t\n",
        "            else:\n",
        "              e_t_d = (e_t - e_t_uncond)\n",
        "              s = torch.quantile(\n",
        "                  rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "                  threshold_percentile,\n",
        "                  dim = -1\n",
        "              )\n",
        "\n",
        "            s.clamp_(min = 1.)\n",
        "            s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "            if ths_method == \"softsign\":\n",
        "                e_t_d = F.softsign(e_t_d) / s \n",
        "            elif ths_method == \"clamp\":\n",
        "                e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "            e_t = e_t_uncond + e_t_d\n",
        "            return(e_t)\n",
        "              \n",
        "    score_corrector.modify_score = modify_score\n",
        "\n",
        "    def dynamic_thresholding(pred_x0,t):\n",
        "        return(pred_x0)\n",
        "\n",
        "    opt.n_iter = 1 #Old way for batching, avoid touching\n",
        "    opt.n_samples =  1 #How many implaes in parallel. Breaks upscaling\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    generate_video = False\n",
        "    if generate_video: \n",
        "        fps = 24\n",
        "        p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "    do_run()\n",
        "    if generate_video: \n",
        "        p.stdin.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "yQ4gyzggoG3l"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "#@markdown ### **3.** CLIP+Latent Parental Test\n",
        "\n",
        "run_parental_test = True #@param{type:'boolean'}\n",
        "if(run_parental_test):\n",
        "\n",
        "  width =  256\n",
        "  height =  384\n",
        "  clip_guidance_scale =  50000\n",
        "  latent_diffusion_guidance_scale = 15\n",
        "  clamp_index = [2.4, 2.1]\n",
        "  aesthetic_loss_scale = 100\n",
        "  augment_cuts = True\n",
        "\n",
        "  how_many_batches = 1 #@param{type: 'integer'}\n",
        "\n",
        "  clip_prompts = [clip_prompt_1+\":10\", clip_prompt_2+\":10\"]\n",
        "  print(clip_prompts)\n",
        "\n",
        "  #@markdown  ### Init image settings\n",
        "  init_image = \"\" #@param{type: 'string'}\n",
        "  if(init_image == '' or init_image == 'None'):\n",
        "    init_image = None\n",
        "\n",
        "  starting_timestep = 0.9 #@param{type: 'number'}\n",
        "\n",
        "  init_mask = None #@param{type: 'string'}\n",
        "\n",
        "  init_scale = 1000 #@param{type: 'integer'}\n",
        "  init_brightness = 0.0 #@param{type: 'number'}\n",
        "\n",
        "  #init_noise = 0.57 #@param{type: 'number'}\n",
        "\n",
        "\n",
        "  #@markdown ### Custom saved settings\n",
        "  #@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "  custom_settings = 'path/to/settings.cfg' #@param{type:'string'}\n",
        "  settings_library = 'None (use settings defined above)' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "  if(settings_library != 'None (use settings defined above)'):\n",
        "    custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "  global_var_scope = globals()\n",
        "  if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "    print('Loaded ', custom_settings)\n",
        "    try:\n",
        "      from configparser import ConfigParser\n",
        "    except ImportError:\n",
        "        from ConfigParser import ConfigParser\n",
        "    import configparser\n",
        "    \n",
        "    config = ConfigParser()\n",
        "    config.read(custom_settings)\n",
        "    #custom_settings_stream = fetch(custom_settings)\n",
        "    #Load CLIP models from config\n",
        "    if(config.has_section('clip_list')):\n",
        "      clip_incoming_list = config.items('clip_list')\n",
        "      clip_incoming_models = clip_incoming_list[0]\n",
        "      incoming_perceptors = eval(clip_incoming_models[1])\n",
        "      if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "        clip_load_list = incoming_perceptors\n",
        "        clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "    #Load settings from config and replace variables\n",
        "    if(config.has_section('basic_settings')):\n",
        "      basic_settings = config.items('basic_settings')\n",
        "      for basic_setting in basic_settings:\n",
        "        global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "    \n",
        "    if(config.has_section('advanced_settings')):\n",
        "      advanced_settings = config.items('advanced_settings')\n",
        "      for advanced_setting in advanced_settings:\n",
        "        global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "  if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "    custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "  prompts = clip_prompts\n",
        "  opt.prompt = latent_prompts\n",
        "  opt.uc = latent_negatives\n",
        "  custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "  aes_scale = aesthetic_loss_scale\n",
        "  try: \n",
        "    clip_guidance_schedule\n",
        "    clip_guidance_index = clip_guidance_schedule\n",
        "  except:\n",
        "    clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "  global progress\n",
        "  progress = widgets.Image(layout = widgets.Layout(max_width = \"400px\",max_height = \"512px\"))\n",
        "  display.display(progress)\n",
        "  for n in trange(how_many_batches, desc=\"Sampling\"):\n",
        "    print(f\"Sampling images {n+1}/{how_many_batches}\")\n",
        "    opt.W = (width//64)*64;\n",
        "    opt.H = (height//64)*64;\n",
        "    if opt.W != width or opt.H != height:\n",
        "        print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "    opt.mag_mul = opt_mag_mul \n",
        "    opt.ddim_eta = opt_ddim_eta\n",
        "    opt.eta_end = opt_eta_end\n",
        "    opt.temperature = opt_temperature\n",
        "\n",
        "    opt.scale = latent_diffusion_guidance_scale\n",
        "    opt.plms = opt_plms\n",
        "    aug = augment_cuts\n",
        "\n",
        "    #Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "    if(len(clamp_index) == 2): \n",
        "      clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "    else:\n",
        "      clamp_index_variation = clamp_index\n",
        "    score_corrector = DotMap()\n",
        "\n",
        "\n",
        "    def modify_score(e_t, e_t_uncond):\n",
        "            if(score_modifier is False):\n",
        "              return e_t\n",
        "            else:\n",
        "              e_t_d = (e_t - e_t_uncond)\n",
        "              s = torch.quantile(\n",
        "                  rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "                  threshold_percentile,\n",
        "                  dim = -1\n",
        "              )\n",
        "\n",
        "            s.clamp_(min = 1.)\n",
        "            s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "            if ths_method == \"softsign\":\n",
        "                e_t_d = F.softsign(e_t_d) / s \n",
        "            elif ths_method == \"clamp\":\n",
        "                e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "            e_t = e_t_uncond + e_t_d\n",
        "            return(e_t)\n",
        "              \n",
        "    score_corrector.modify_score = modify_score\n",
        "\n",
        "    def dynamic_thresholding(pred_x0,t):\n",
        "        return(pred_x0)\n",
        "\n",
        "    opt.n_iter = 1 #Old way for batching, avoid touching\n",
        "    opt.n_samples =  1 #How many implaes in parallel. Breaks upscaling\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    generate_video = False\n",
        "    if generate_video: \n",
        "        fps = 24\n",
        "        p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "    do_run()\n",
        "    if generate_video: \n",
        "        p.stdin.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIyeqAsO12sE"
      },
      "source": [
        "### 𝗗ᴇᴋᴀ-𝗕ᴀᴛᴄʜ 𝗥ᴜɴ 𝗖ᴇʟʟ𝘀"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown  ### Optional settings\n",
        "\n",
        "skip_optional_settings = False #@param{type:'boolean'}\n",
        "if(not skip_optional_settings):\n",
        "\n",
        "  init_image = \"\" #@param{type: 'string'}\n",
        "\n",
        "  if(init_image == '' or init_image == 'None'):\n",
        "    init_image = None\n",
        "\n",
        "  starting_timestep = 0.9 #@param{type: 'number'}\n",
        "\n",
        "  init_mask = None #@param{type: 'string'}\n",
        "\n",
        "  init_scale = 1000 #@param{type: 'integer'}\n",
        "\n",
        "  init_brightness = 0.0 #@param{type: 'number'}\n",
        "\n",
        "  init_noise = 0.0 #@param{type: 'number'}\n",
        "\n",
        "  batch_name = \"test\" #@param{type: 'string'}\n",
        "  outputs_path = \"/content/gdrive/MyDrive/AI/latent_majesty_diffusion/\" + batch_name\n",
        "\n",
        "  print(init_image)\n",
        "  print(outputs_path)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "WvwSAwFo8B1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "SyE0vuAv12sF"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#@markdown ### **Run 1.** Basic settings\n",
        "\n",
        "width = 256 #@param{type: 'integer'}\n",
        "height = 384 #@param{type: 'integer'}\n",
        "\n",
        "clamp_index = [2.4, 2.1] #@param{type: 'raw'}\n",
        "\n",
        "latent_diffusion_guidance_scale = 12 #@param {type:\"number\"}\n",
        "clip_guidance_scale = 12000 #@param{type: 'integer'}\n",
        "\n",
        "how_many_batches = 1 #@param{type: 'integer'}\n",
        "\n",
        "aesthetic_loss_scale = 100 #@param{type: 'integer'}\n",
        "augment_cuts = True #@param{type:'boolean'}\n",
        "\n",
        "\n",
        "init_image = \"\"\n",
        "\n",
        "if(init_image == '' or init_image == 'None'):\n",
        "  init_image = None\n",
        "\n",
        "starting_timestep = 0.9\n",
        "init_mask = None\n",
        "init_scale = 1000\n",
        "init_brightness = 0.0\n",
        "\n",
        "init_noise = 0.57\n",
        "\n",
        "#@markdown ### Custom saved settings\n",
        "#@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "custom_settings = '' #@param{type:'string'}\n",
        "settings_library = 'None (use settings defined above)' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "if(settings_library != 'None (use settings defined above)'):\n",
        "  custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "global_var_scope = globals()\n",
        "if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "  print('Loaded ', custom_settings)\n",
        "  try:\n",
        "    from configparser import ConfigParser\n",
        "  except ImportError:\n",
        "      from ConfigParser import ConfigParser\n",
        "  import configparser\n",
        "  \n",
        "  config = ConfigParser()\n",
        "  config.read(custom_settings)\n",
        "  #custom_settings_stream = fetch(custom_settings)\n",
        "  #Load CLIP models from config\n",
        "  if(config.has_section('clip_list')):\n",
        "    clip_incoming_list = config.items('clip_list')\n",
        "    clip_incoming_models = clip_incoming_list[0]\n",
        "    incoming_perceptors = eval(clip_incoming_models[1])\n",
        "    if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "      clip_load_list = incoming_perceptors\n",
        "      clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "  #Load settings from config and replace variables\n",
        "  if(config.has_section('basic_settings')):\n",
        "    basic_settings = config.items('basic_settings')\n",
        "    for basic_setting in basic_settings:\n",
        "      global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "  \n",
        "  if(config.has_section('advanced_settings')):\n",
        "    advanced_settings = config.items('advanced_settings')\n",
        "    for advanced_setting in advanced_settings:\n",
        "      global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "  custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "prompts = clip_prompts\n",
        "opt.prompt = latent_prompts\n",
        "opt.uc = latent_negatives\n",
        "custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "aes_scale = aesthetic_loss_scale\n",
        "try: \n",
        "  clip_guidance_schedule\n",
        "  clip_guidance_index = clip_guidance_schedule\n",
        "except:\n",
        "  clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "opt.W = (width//64)*64;\n",
        "opt.H = (height//64)*64;\n",
        "if opt.W != width or opt.H != height:\n",
        "    print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "opt.mag_mul = opt_mag_mul \n",
        "opt.ddim_eta = opt_ddim_eta\n",
        "opt.eta_end = opt_eta_end\n",
        "opt.temperature = opt_temperature\n",
        "opt.n_iter = how_many_batches\n",
        "opt.n_samples =  1\n",
        "opt.scale = latent_diffusion_guidance_scale\n",
        "opt.plms = opt_plms\n",
        "aug = augment_cuts\n",
        "\n",
        "#Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "if(len(clamp_index) == 2): \n",
        "  clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "else:\n",
        "  clamp_index_variation = clamp_index\n",
        "score_corrector = DotMap()\n",
        "\n",
        "\n",
        "def modify_score(e_t, e_t_uncond):\n",
        "        if(score_modifier is False):\n",
        "          return e_t\n",
        "        else:\n",
        "          e_t_d = (e_t - e_t_uncond)\n",
        "          s = torch.quantile(\n",
        "              rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "              threshold_percentile,\n",
        "              dim = -1\n",
        "          )\n",
        "\n",
        "        s.clamp_(min = 1.)\n",
        "        s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "        if ths_method == \"softsign\":\n",
        "            e_t_d = F.softsign(e_t_d) / s \n",
        "        elif ths_method == \"clamp\":\n",
        "            e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "        e_t = e_t_uncond + e_t_d\n",
        "        return(e_t)\n",
        "          \n",
        "score_corrector.modify_score = modify_score\n",
        "\n",
        "def dynamic_thresholding(pred_x0,t):\n",
        "    return(pred_x0)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "generate_video = False\n",
        "if generate_video: \n",
        "    fps = 24\n",
        "    p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "do_run()\n",
        "if generate_video: \n",
        "    p.stdin.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Nsb0PCe212sF"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#@markdown ### **Run 2.** Basic settings\n",
        "\n",
        "width = 256 #@param{type: 'integer'}\n",
        "height = 384 #@param{type: 'integer'}\n",
        "\n",
        "clamp_index = [2.1, 2.4] #@param{type: 'raw'}\n",
        "\n",
        "latent_diffusion_guidance_scale = 15 #@param {type:\"number\"}\n",
        "clip_guidance_scale = 50000 #@param{type: 'integer'}\n",
        "\n",
        "how_many_batches = 1 #@param{type: 'integer'}\n",
        "\n",
        "aesthetic_loss_scale = 200 #@param{type: 'integer'}\n",
        "augment_cuts = True #@param{type:'boolean'}\n",
        "\n",
        "\n",
        "#@markdown ### Custom saved settings\n",
        "#@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "custom_settings = '' #@param{type:'string'}\n",
        "settings_library = 'None (use settings defined above)' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "if(settings_library != 'None (use settings defined above)'):\n",
        "  custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "global_var_scope = globals()\n",
        "if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "  print('Loaded ', custom_settings)\n",
        "  try:\n",
        "    from configparser import ConfigParser\n",
        "  except ImportError:\n",
        "      from ConfigParser import ConfigParser\n",
        "  import configparser\n",
        "  \n",
        "  config = ConfigParser()\n",
        "  config.read(custom_settings)\n",
        "  #custom_settings_stream = fetch(custom_settings)\n",
        "  #Load CLIP models from config\n",
        "  if(config.has_section('clip_list')):\n",
        "    clip_incoming_list = config.items('clip_list')\n",
        "    clip_incoming_models = clip_incoming_list[0]\n",
        "    incoming_perceptors = eval(clip_incoming_models[1])\n",
        "    if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "      clip_load_list = incoming_perceptors\n",
        "      clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "  #Load settings from config and replace variables\n",
        "  if(config.has_section('basic_settings')):\n",
        "    basic_settings = config.items('basic_settings')\n",
        "    for basic_setting in basic_settings:\n",
        "      global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "  \n",
        "  if(config.has_section('advanced_settings')):\n",
        "    advanced_settings = config.items('advanced_settings')\n",
        "    for advanced_setting in advanced_settings:\n",
        "      global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "  custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "prompts = clip_prompts\n",
        "opt.prompt = latent_prompts\n",
        "opt.uc = latent_negatives\n",
        "custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "aes_scale = aesthetic_loss_scale\n",
        "try: \n",
        "  clip_guidance_schedule\n",
        "  clip_guidance_index = clip_guidance_schedule\n",
        "except:\n",
        "  clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "opt.W = (width//64)*64;\n",
        "opt.H = (height//64)*64;\n",
        "if opt.W != width or opt.H != height:\n",
        "    print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "opt.mag_mul = opt_mag_mul \n",
        "opt.ddim_eta = opt_ddim_eta\n",
        "opt.eta_end = opt_eta_end\n",
        "opt.temperature = opt_temperature\n",
        "opt.n_iter = how_many_batches\n",
        "opt.n_samples =  1\n",
        "opt.scale = latent_diffusion_guidance_scale\n",
        "opt.plms = opt_plms\n",
        "aug = augment_cuts\n",
        "\n",
        "#Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "if(len(clamp_index) == 2): \n",
        "  clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "else:\n",
        "  clamp_index_variation = clamp_index\n",
        "score_corrector = DotMap()\n",
        "\n",
        "\n",
        "def modify_score(e_t, e_t_uncond):\n",
        "        if(score_modifier is False):\n",
        "          return e_t\n",
        "        else:\n",
        "          e_t_d = (e_t - e_t_uncond)\n",
        "          s = torch.quantile(\n",
        "              rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "              threshold_percentile,\n",
        "              dim = -1\n",
        "          )\n",
        "\n",
        "        s.clamp_(min = 1.)\n",
        "        s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "        if ths_method == \"softsign\":\n",
        "            e_t_d = F.softsign(e_t_d) / s \n",
        "        elif ths_method == \"clamp\":\n",
        "            e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "        e_t = e_t_uncond + e_t_d\n",
        "        return(e_t)\n",
        "          \n",
        "score_corrector.modify_score = modify_score\n",
        "\n",
        "def dynamic_thresholding(pred_x0,t):\n",
        "    return(pred_x0)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "generate_video = False\n",
        "if generate_video: \n",
        "    fps = 24\n",
        "    p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "do_run()\n",
        "if generate_video: \n",
        "    p.stdin.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "YAWnJwyi12sG"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#@markdown ### **Run 3.** Basic settings\n",
        "\n",
        "width = 512 #@param{type: 'integer'}\n",
        "height = 256 #@param{type: 'integer'}\n",
        "\n",
        "clamp_index = [2.1, 2.1] #@param{type: 'raw'}\n",
        "\n",
        "latent_diffusion_guidance_scale = 12 #@param {type:\"number\"}\n",
        "clip_guidance_scale = 50000 #@param{type: 'integer'}\n",
        "\n",
        "how_many_batches = 1 #@param{type: 'integer'}\n",
        "\n",
        "aesthetic_loss_scale = 200 #@param{type: 'integer'}\n",
        "augment_cuts = True #@param{type:'boolean'}\n",
        "\n",
        "\n",
        "#@markdown ### Custom saved settings\n",
        "#@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "custom_settings = '' #@param{type:'string'}\n",
        "settings_library = 'None (use settings defined above)' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "if(settings_library != 'None (use settings defined above)'):\n",
        "  custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "global_var_scope = globals()\n",
        "if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "  print('Loaded ', custom_settings)\n",
        "  try:\n",
        "    from configparser import ConfigParser\n",
        "  except ImportError:\n",
        "      from ConfigParser import ConfigParser\n",
        "  import configparser\n",
        "  \n",
        "  config = ConfigParser()\n",
        "  config.read(custom_settings)\n",
        "  #custom_settings_stream = fetch(custom_settings)\n",
        "  #Load CLIP models from config\n",
        "  if(config.has_section('clip_list')):\n",
        "    clip_incoming_list = config.items('clip_list')\n",
        "    clip_incoming_models = clip_incoming_list[0]\n",
        "    incoming_perceptors = eval(clip_incoming_models[1])\n",
        "    if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "      clip_load_list = incoming_perceptors\n",
        "      clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "  #Load settings from config and replace variables\n",
        "  if(config.has_section('basic_settings')):\n",
        "    basic_settings = config.items('basic_settings')\n",
        "    for basic_setting in basic_settings:\n",
        "      global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "  \n",
        "  if(config.has_section('advanced_settings')):\n",
        "    advanced_settings = config.items('advanced_settings')\n",
        "    for advanced_setting in advanced_settings:\n",
        "      global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "  custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "prompts = clip_prompts\n",
        "opt.prompt = latent_prompts\n",
        "opt.uc = latent_negatives\n",
        "custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "aes_scale = aesthetic_loss_scale\n",
        "try: \n",
        "  clip_guidance_schedule\n",
        "  clip_guidance_index = clip_guidance_schedule\n",
        "except:\n",
        "  clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "opt.W = (width//64)*64;\n",
        "opt.H = (height//64)*64;\n",
        "if opt.W != width or opt.H != height:\n",
        "    print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "opt.mag_mul = opt_mag_mul \n",
        "opt.ddim_eta = opt_ddim_eta\n",
        "opt.eta_end = opt_eta_end\n",
        "opt.temperature = opt_temperature\n",
        "opt.n_iter = how_many_batches\n",
        "opt.n_samples =  1\n",
        "opt.scale = latent_diffusion_guidance_scale\n",
        "opt.plms = opt_plms\n",
        "aug = augment_cuts\n",
        "\n",
        "#Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "if(len(clamp_index) == 2): \n",
        "  clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "else:\n",
        "  clamp_index_variation = clamp_index\n",
        "score_corrector = DotMap()\n",
        "\n",
        "\n",
        "def modify_score(e_t, e_t_uncond):\n",
        "        if(score_modifier is False):\n",
        "          return e_t\n",
        "        else:\n",
        "          e_t_d = (e_t - e_t_uncond)\n",
        "          s = torch.quantile(\n",
        "              rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "              threshold_percentile,\n",
        "              dim = -1\n",
        "          )\n",
        "\n",
        "        s.clamp_(min = 1.)\n",
        "        s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "        if ths_method == \"softsign\":\n",
        "            e_t_d = F.softsign(e_t_d) / s \n",
        "        elif ths_method == \"clamp\":\n",
        "            e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "        e_t = e_t_uncond + e_t_d\n",
        "        return(e_t)\n",
        "          \n",
        "score_corrector.modify_score = modify_score\n",
        "\n",
        "def dynamic_thresholding(pred_x0,t):\n",
        "    return(pred_x0)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "generate_video = False\n",
        "if generate_video: \n",
        "    fps = 24\n",
        "    p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "do_run()\n",
        "if generate_video: \n",
        "    p.stdin.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "hTJqw_qx12sG"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#@markdown ### **Run 4.** Basic settings\n",
        "\n",
        "width = 256 #@param{type: 'integer'}\n",
        "height = 512 #@param{type: 'integer'}\n",
        "\n",
        "clamp_index = [1.5, 2.0] #@param{type: 'raw'}\n",
        "\n",
        "latent_diffusion_guidance_scale = 6 #@param {type:\"number\"}\n",
        "clip_guidance_scale = 36000 #@param{type: 'integer'}\n",
        "\n",
        "how_many_batches = 1 #@param{type: 'integer'}\n",
        "aesthetic_loss_scale = 100 #@param{type: 'integer'}\n",
        "augment_cuts = True #@param{type:'boolean'}\n",
        "\n",
        "\n",
        "#@markdown ### Custom saved settings\n",
        "#@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "custom_settings = '' #@param{type:'string'}\n",
        "settings_library = 'None (use settings defined above)' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "if(settings_library != 'None (use settings defined above)'):\n",
        "  custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "global_var_scope = globals()\n",
        "if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "  print('Loaded ', custom_settings)\n",
        "  try:\n",
        "    from configparser import ConfigParser\n",
        "  except ImportError:\n",
        "      from ConfigParser import ConfigParser\n",
        "  import configparser\n",
        "  \n",
        "  config = ConfigParser()\n",
        "  config.read(custom_settings)\n",
        "  #custom_settings_stream = fetch(custom_settings)\n",
        "  #Load CLIP models from config\n",
        "  if(config.has_section('clip_list')):\n",
        "    clip_incoming_list = config.items('clip_list')\n",
        "    clip_incoming_models = clip_incoming_list[0]\n",
        "    incoming_perceptors = eval(clip_incoming_models[1])\n",
        "    if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "      clip_load_list = incoming_perceptors\n",
        "      clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "  #Load settings from config and replace variables\n",
        "  if(config.has_section('basic_settings')):\n",
        "    basic_settings = config.items('basic_settings')\n",
        "    for basic_setting in basic_settings:\n",
        "      global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "  \n",
        "  if(config.has_section('advanced_settings')):\n",
        "    advanced_settings = config.items('advanced_settings')\n",
        "    for advanced_setting in advanced_settings:\n",
        "      global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "  custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "prompts = clip_prompts\n",
        "opt.prompt = latent_prompts\n",
        "opt.uc = latent_negatives\n",
        "custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "aes_scale = aesthetic_loss_scale\n",
        "try: \n",
        "  clip_guidance_schedule\n",
        "  clip_guidance_index = clip_guidance_schedule\n",
        "except:\n",
        "  clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "opt.W = (width//64)*64;\n",
        "opt.H = (height//64)*64;\n",
        "if opt.W != width or opt.H != height:\n",
        "    print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "opt.mag_mul = opt_mag_mul \n",
        "opt.ddim_eta = opt_ddim_eta\n",
        "opt.eta_end = opt_eta_end\n",
        "opt.temperature = opt_temperature\n",
        "opt.n_iter = how_many_batches\n",
        "opt.n_samples =  1\n",
        "opt.scale = latent_diffusion_guidance_scale\n",
        "opt.plms = opt_plms\n",
        "aug = augment_cuts\n",
        "\n",
        "#Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "if(len(clamp_index) == 2): \n",
        "  clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "else:\n",
        "  clamp_index_variation = clamp_index\n",
        "score_corrector = DotMap()\n",
        "\n",
        "\n",
        "def modify_score(e_t, e_t_uncond):\n",
        "        if(score_modifier is False):\n",
        "          return e_t\n",
        "        else:\n",
        "          e_t_d = (e_t - e_t_uncond)\n",
        "          s = torch.quantile(\n",
        "              rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "              threshold_percentile,\n",
        "              dim = -1\n",
        "          )\n",
        "\n",
        "        s.clamp_(min = 1.)\n",
        "        s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "        if ths_method == \"softsign\":\n",
        "            e_t_d = F.softsign(e_t_d) / s \n",
        "        elif ths_method == \"clamp\":\n",
        "            e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "        e_t = e_t_uncond + e_t_d\n",
        "        return(e_t)\n",
        "          \n",
        "score_corrector.modify_score = modify_score\n",
        "\n",
        "def dynamic_thresholding(pred_x0,t):\n",
        "    return(pred_x0)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "generate_video = False\n",
        "if generate_video: \n",
        "    fps = 24\n",
        "    p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "do_run()\n",
        "if generate_video: \n",
        "    p.stdin.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "yzsCbLeO12sH"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#@markdown ### **Run 5.** Basic settings\n",
        "\n",
        "width = 512 #@param{type: 'integer'}\n",
        "height = 256 #@param{type: 'integer'}\n",
        "\n",
        "clamp_index = [2.1, 2.4] #@param{type: 'raw'}\n",
        "\n",
        "latent_diffusion_guidance_scale = 9 #@param {type:\"number\"}\n",
        "clip_guidance_scale = 16000 #@param{type: 'integer'}\n",
        "\n",
        "how_many_batches = 1#@param{type: 'integer'}\n",
        "aesthetic_loss_scale = 100 #@param{type: 'integer'}\n",
        "augment_cuts = True #@param{type:'boolean'}\n",
        "\n",
        "\n",
        "#@markdown ### Custom saved settings\n",
        "#@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "custom_settings = '' #@param{type:'string'}\n",
        "settings_library = 'default' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "if(settings_library != 'None (use settings defined above)'):\n",
        "  custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "global_var_scope = globals()\n",
        "if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "  print('Loaded ', custom_settings)\n",
        "  try:\n",
        "    from configparser import ConfigParser\n",
        "  except ImportError:\n",
        "      from ConfigParser import ConfigParser\n",
        "  import configparser\n",
        "  \n",
        "  config = ConfigParser()\n",
        "  config.read(custom_settings)\n",
        "  #custom_settings_stream = fetch(custom_settings)\n",
        "  #Load CLIP models from config\n",
        "  if(config.has_section('clip_list')):\n",
        "    clip_incoming_list = config.items('clip_list')\n",
        "    clip_incoming_models = clip_incoming_list[0]\n",
        "    incoming_perceptors = eval(clip_incoming_models[1])\n",
        "    if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "      clip_load_list = incoming_perceptors\n",
        "      clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "  #Load settings from config and replace variables\n",
        "  if(config.has_section('basic_settings')):\n",
        "    basic_settings = config.items('basic_settings')\n",
        "    for basic_setting in basic_settings:\n",
        "      global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "  \n",
        "  if(config.has_section('advanced_settings')):\n",
        "    advanced_settings = config.items('advanced_settings')\n",
        "    for advanced_setting in advanced_settings:\n",
        "      global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "  custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "prompts = clip_prompts\n",
        "opt.prompt = latent_prompts\n",
        "opt.uc = latent_negatives\n",
        "custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "aes_scale = aesthetic_loss_scale\n",
        "try: \n",
        "  clip_guidance_schedule\n",
        "  clip_guidance_index = clip_guidance_schedule\n",
        "except:\n",
        "  clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "opt.W = (width//64)*64;\n",
        "opt.H = (height//64)*64;\n",
        "if opt.W != width or opt.H != height:\n",
        "    print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "opt.mag_mul = opt_mag_mul \n",
        "opt.ddim_eta = opt_ddim_eta\n",
        "opt.eta_end = opt_eta_end\n",
        "opt.temperature = opt_temperature\n",
        "opt.n_iter = how_many_batches\n",
        "opt.n_samples =  1\n",
        "opt.scale = latent_diffusion_guidance_scale\n",
        "opt.plms = opt_plms\n",
        "aug = augment_cuts\n",
        "\n",
        "#Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "if(len(clamp_index) == 2): \n",
        "  clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "else:\n",
        "  clamp_index_variation = clamp_index\n",
        "score_corrector = DotMap()\n",
        "\n",
        "\n",
        "def modify_score(e_t, e_t_uncond):\n",
        "        if(score_modifier is False):\n",
        "          return e_t\n",
        "        else:\n",
        "          e_t_d = (e_t - e_t_uncond)\n",
        "          s = torch.quantile(\n",
        "              rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "              threshold_percentile,\n",
        "              dim = -1\n",
        "          )\n",
        "\n",
        "        s.clamp_(min = 1.)\n",
        "        s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "        if ths_method == \"softsign\":\n",
        "            e_t_d = F.softsign(e_t_d) / s \n",
        "        elif ths_method == \"clamp\":\n",
        "            e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "        e_t = e_t_uncond + e_t_d\n",
        "        return(e_t)\n",
        "          \n",
        "score_corrector.modify_score = modify_score\n",
        "\n",
        "def dynamic_thresholding(pred_x0,t):\n",
        "    return(pred_x0)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "generate_video = False\n",
        "if generate_video: \n",
        "    fps = 24\n",
        "    p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "do_run()\n",
        "if generate_video: \n",
        "    p.stdin.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "UkmyKsoo12sH"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#@markdown ### **Run 6.** Basic Settings\n",
        "\n",
        "width = 256 #@param{type: 'integer'}\n",
        "height = 384 #@param{type: 'integer'}\n",
        "\n",
        "clamp_index = [2.4, 2.1] #@param{type: 'raw'}\n",
        "\n",
        "latent_diffusion_guidance_scale = 15 #@param {type:\"number\"}\n",
        "clip_guidance_scale = 20000 #@param{type: 'integer'}\n",
        "\n",
        "how_many_batches = 1 #@param{type: 'integer'}\n",
        "aesthetic_loss_scale = 100 #@param{type: 'integer'}\n",
        "augment_cuts = True #@param{type:'boolean'}\n",
        "\n",
        "\n",
        "#@markdown ### Custom saved settings\n",
        "#@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "custom_settings = '' #@param{type:'string'}\n",
        "settings_library = 'default' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "if(settings_library != 'None (use settings defined above)'):\n",
        "  custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "global_var_scope = globals()\n",
        "if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "  print('Loaded ', custom_settings)\n",
        "  try:\n",
        "    from configparser import ConfigParser\n",
        "  except ImportError:\n",
        "      from ConfigParser import ConfigParser\n",
        "  import configparser\n",
        "  \n",
        "  config = ConfigParser()\n",
        "  config.read(custom_settings)\n",
        "  #custom_settings_stream = fetch(custom_settings)\n",
        "  #Load CLIP models from config\n",
        "  if(config.has_section('clip_list')):\n",
        "    clip_incoming_list = config.items('clip_list')\n",
        "    clip_incoming_models = clip_incoming_list[0]\n",
        "    incoming_perceptors = eval(clip_incoming_models[1])\n",
        "    if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "      clip_load_list = incoming_perceptors\n",
        "      clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "  #Load settings from config and replace variables\n",
        "  if(config.has_section('basic_settings')):\n",
        "    basic_settings = config.items('basic_settings')\n",
        "    for basic_setting in basic_settings:\n",
        "      global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "  \n",
        "  if(config.has_section('advanced_settings')):\n",
        "    advanced_settings = config.items('advanced_settings')\n",
        "    for advanced_setting in advanced_settings:\n",
        "      global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "  custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "prompts = clip_prompts\n",
        "opt.prompt = latent_prompts\n",
        "opt.uc = latent_negatives\n",
        "custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "aes_scale = aesthetic_loss_scale\n",
        "try: \n",
        "  clip_guidance_schedule\n",
        "  clip_guidance_index = clip_guidance_schedule\n",
        "except:\n",
        "  clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "opt.W = (width//64)*64;\n",
        "opt.H = (height//64)*64;\n",
        "if opt.W != width or opt.H != height:\n",
        "    print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "opt.mag_mul = opt_mag_mul \n",
        "opt.ddim_eta = opt_ddim_eta\n",
        "opt.eta_end = opt_eta_end\n",
        "opt.temperature = opt_temperature\n",
        "opt.n_iter = how_many_batches\n",
        "opt.n_samples =  1\n",
        "opt.scale = latent_diffusion_guidance_scale\n",
        "opt.plms = opt_plms\n",
        "aug = augment_cuts\n",
        "\n",
        "#Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "if(len(clamp_index) == 2): \n",
        "  clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "else:\n",
        "  clamp_index_variation = clamp_index\n",
        "score_corrector = DotMap()\n",
        "\n",
        "\n",
        "def modify_score(e_t, e_t_uncond):\n",
        "        if(score_modifier is False):\n",
        "          return e_t\n",
        "        else:\n",
        "          e_t_d = (e_t - e_t_uncond)\n",
        "          s = torch.quantile(\n",
        "              rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "              threshold_percentile,\n",
        "              dim = -1\n",
        "          )\n",
        "\n",
        "        s.clamp_(min = 1.)\n",
        "        s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "        if ths_method == \"softsign\":\n",
        "            e_t_d = F.softsign(e_t_d) / s \n",
        "        elif ths_method == \"clamp\":\n",
        "            e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "        e_t = e_t_uncond + e_t_d\n",
        "        return(e_t)\n",
        "          \n",
        "score_corrector.modify_score = modify_score\n",
        "\n",
        "def dynamic_thresholding(pred_x0,t):\n",
        "    return(pred_x0)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "generate_video = False\n",
        "if generate_video: \n",
        "    fps = 24\n",
        "    p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "do_run()\n",
        "if generate_video: \n",
        "    p.stdin.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "XSyH8XXS12sH"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#@markdown ### **Run 7.** Basic Settings\n",
        "\n",
        "width = 384 #@param{type: 'integer'}\n",
        "height = 384 #@param{type: 'integer'}\n",
        "\n",
        "clamp_index = [0.6, 0.6] #@param{type: 'raw'}\n",
        "\n",
        "latent_diffusion_guidance_scale = 11 #@param {type:\"number\"}\n",
        "clip_guidance_scale = 39999 #@param{type: 'integer'}\n",
        "\n",
        "how_many_batches = 1 #@param{type: 'integer'}\n",
        "aesthetic_loss_scale = 100 #@param{type: 'integer'}\n",
        "augment_cuts = True #@param{type:'boolean'}\n",
        "\n",
        "\n",
        "#@markdown ### Custom saved settings\n",
        "#@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "custom_settings = '' #@param{type:'string'}\n",
        "settings_library = 'default' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "if(settings_library != 'None (use settings defined above)'):\n",
        "  custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "global_var_scope = globals()\n",
        "if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "  print('Loaded ', custom_settings)\n",
        "  try:\n",
        "    from configparser import ConfigParser\n",
        "  except ImportError:\n",
        "      from ConfigParser import ConfigParser\n",
        "  import configparser\n",
        "  \n",
        "  config = ConfigParser()\n",
        "  config.read(custom_settings)\n",
        "  #custom_settings_stream = fetch(custom_settings)\n",
        "  #Load CLIP models from config\n",
        "  if(config.has_section('clip_list')):\n",
        "    clip_incoming_list = config.items('clip_list')\n",
        "    clip_incoming_models = clip_incoming_list[0]\n",
        "    incoming_perceptors = eval(clip_incoming_models[1])\n",
        "    if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "      clip_load_list = incoming_perceptors\n",
        "      clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "  #Load settings from config and replace variables\n",
        "  if(config.has_section('basic_settings')):\n",
        "    basic_settings = config.items('basic_settings')\n",
        "    for basic_setting in basic_settings:\n",
        "      global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "  \n",
        "  if(config.has_section('advanced_settings')):\n",
        "    advanced_settings = config.items('advanced_settings')\n",
        "    for advanced_setting in advanced_settings:\n",
        "      global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "  custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "prompts = clip_prompts\n",
        "opt.prompt = latent_prompts\n",
        "opt.uc = latent_negatives\n",
        "custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "aes_scale = aesthetic_loss_scale\n",
        "try: \n",
        "  clip_guidance_schedule\n",
        "  clip_guidance_index = clip_guidance_schedule\n",
        "except:\n",
        "  clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "opt.W = (width//64)*64;\n",
        "opt.H = (height//64)*64;\n",
        "if opt.W != width or opt.H != height:\n",
        "    print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "opt.mag_mul = opt_mag_mul \n",
        "opt.ddim_eta = opt_ddim_eta\n",
        "opt.eta_end = opt_eta_end\n",
        "opt.temperature = opt_temperature\n",
        "opt.n_iter = how_many_batches\n",
        "opt.n_samples =  1\n",
        "opt.scale = latent_diffusion_guidance_scale\n",
        "opt.plms = opt_plms\n",
        "aug = augment_cuts\n",
        "\n",
        "#Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "if(len(clamp_index) == 2): \n",
        "  clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "else:\n",
        "  clamp_index_variation = clamp_index\n",
        "score_corrector = DotMap()\n",
        "\n",
        "\n",
        "def modify_score(e_t, e_t_uncond):\n",
        "        if(score_modifier is False):\n",
        "          return e_t\n",
        "        else:\n",
        "          e_t_d = (e_t - e_t_uncond)\n",
        "          s = torch.quantile(\n",
        "              rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "              threshold_percentile,\n",
        "              dim = -1\n",
        "          )\n",
        "\n",
        "        s.clamp_(min = 1.)\n",
        "        s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "        if ths_method == \"softsign\":\n",
        "            e_t_d = F.softsign(e_t_d) / s \n",
        "        elif ths_method == \"clamp\":\n",
        "            e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "        e_t = e_t_uncond + e_t_d\n",
        "        return(e_t)\n",
        "          \n",
        "score_corrector.modify_score = modify_score\n",
        "\n",
        "def dynamic_thresholding(pred_x0,t):\n",
        "    return(pred_x0)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "generate_video = False\n",
        "if generate_video: \n",
        "    fps = 24\n",
        "    p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "do_run()\n",
        "if generate_video: \n",
        "    p.stdin.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "TGdjj_x612sI"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#@markdown ### **Run 8.** Basic Settings\n",
        "\n",
        "width =  256#@param{type: 'integer'}\n",
        "height =  384#@param{type: 'integer'}\n",
        "\n",
        "clamp_index = [1, 1] #@param{type: 'raw'}\n",
        "\n",
        "latent_diffusion_guidance_scale = 10 #@param {type:\"number\"}\n",
        "clip_guidance_scale =  50000#@param{type: 'integer'}\n",
        "\n",
        "how_many_batches =  1#@param{type: 'integer'}\n",
        "\n",
        "aesthetic_loss_scale = 100 #@param{type: 'integer'}\n",
        "augment_cuts=True #@param{type:'boolean'}\n",
        "\n",
        "\n",
        "#@markdown ### Custom saved settings\n",
        "#@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "custom_settings = '' #@param{type:'string'}\n",
        "settings_library = 'coherent_pizzapigeon' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "if(settings_library != 'None (use settings defined above)'):\n",
        "  custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "global_var_scope = globals()\n",
        "if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "  print('Loaded ', custom_settings)\n",
        "  try:\n",
        "    from configparser import ConfigParser\n",
        "  except ImportError:\n",
        "      from ConfigParser import ConfigParser\n",
        "  import configparser\n",
        "  \n",
        "  config = ConfigParser()\n",
        "  config.read(custom_settings)\n",
        "  #custom_settings_stream = fetch(custom_settings)\n",
        "  #Load CLIP models from config\n",
        "  if(config.has_section('clip_list')):\n",
        "    clip_incoming_list = config.items('clip_list')\n",
        "    clip_incoming_models = clip_incoming_list[0]\n",
        "    incoming_perceptors = eval(clip_incoming_models[1])\n",
        "    if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "      clip_load_list = incoming_perceptors\n",
        "      clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "  #Load settings from config and replace variables\n",
        "  if(config.has_section('basic_settings')):\n",
        "    basic_settings = config.items('basic_settings')\n",
        "    for basic_setting in basic_settings:\n",
        "      global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "  \n",
        "  if(config.has_section('advanced_settings')):\n",
        "    advanced_settings = config.items('advanced_settings')\n",
        "    for advanced_setting in advanced_settings:\n",
        "      global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "  custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "prompts = clip_prompts\n",
        "opt.prompt = latent_prompts\n",
        "opt.uc = latent_negatives\n",
        "custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "aes_scale = aesthetic_loss_scale\n",
        "try: \n",
        "  clip_guidance_schedule\n",
        "  clip_guidance_index = clip_guidance_schedule\n",
        "except:\n",
        "  clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "opt.W = (width//64)*64;\n",
        "opt.H = (height//64)*64;\n",
        "if opt.W != width or opt.H != height:\n",
        "    print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "opt.mag_mul = opt_mag_mul \n",
        "opt.ddim_eta = opt_ddim_eta\n",
        "opt.eta_end = opt_eta_end\n",
        "opt.temperature = opt_temperature\n",
        "opt.n_iter = how_many_batches\n",
        "opt.n_samples =  1\n",
        "opt.scale = latent_diffusion_guidance_scale\n",
        "opt.plms = opt_plms\n",
        "aug = augment_cuts\n",
        "\n",
        "#Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "if(len(clamp_index) == 2): \n",
        "  clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "else:\n",
        "  clamp_index_variation = clamp_index\n",
        "score_corrector = DotMap()\n",
        "\n",
        "\n",
        "def modify_score(e_t, e_t_uncond):\n",
        "        if(score_modifier is False):\n",
        "          return e_t\n",
        "        else:\n",
        "          e_t_d = (e_t - e_t_uncond)\n",
        "          s = torch.quantile(\n",
        "              rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "              threshold_percentile,\n",
        "              dim = -1\n",
        "          )\n",
        "\n",
        "        s.clamp_(min = 1.)\n",
        "        s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "        if ths_method == \"softsign\":\n",
        "            e_t_d = F.softsign(e_t_d) / s \n",
        "        elif ths_method == \"clamp\":\n",
        "            e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "        e_t = e_t_uncond + e_t_d\n",
        "        return(e_t)\n",
        "          \n",
        "score_corrector.modify_score = modify_score\n",
        "\n",
        "def dynamic_thresholding(pred_x0,t):\n",
        "    return(pred_x0)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "generate_video = False\n",
        "if generate_video: \n",
        "    fps = 24\n",
        "    p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "do_run()\n",
        "if generate_video: \n",
        "    p.stdin.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ohIEz-i412sI"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#@markdown ### **Run 9.** Basic Settings\n",
        "\n",
        "width = 384 #@param{type: 'integer'}\n",
        "height = 256 #@param{type: 'integer'}\n",
        "\n",
        "clamp_index = [1, 1] #@param{type: 'raw'}\n",
        "\n",
        "latent_diffusion_guidance_scale = 13 #@param {type:\"number\"}\n",
        "clip_guidance_scale = 24000 #@param{type: 'integer'}\n",
        "\n",
        "how_many_batches =  1#@param{type: 'integer'}\n",
        "aesthetic_loss_scale =  1#@param{type: 'integer'}\n",
        "augment_cuts = True #@param{type:'boolean'}\n",
        "\n",
        "\n",
        "#@markdown ### Custom saved settings\n",
        "#@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "custom_settings = '' #@param{type:'string'}\n",
        "settings_library = 'coherent_pizzapigeon' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "if(settings_library != 'None (use settings defined above)'):\n",
        "  custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "global_var_scope = globals()\n",
        "if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "  print('Loaded ', custom_settings)\n",
        "  try:\n",
        "    from configparser import ConfigParser\n",
        "  except ImportError:\n",
        "      from ConfigParser import ConfigParser\n",
        "  import configparser\n",
        "  \n",
        "  config = ConfigParser()\n",
        "  config.read(custom_settings)\n",
        "  #custom_settings_stream = fetch(custom_settings)\n",
        "  #Load CLIP models from config\n",
        "  if(config.has_section('clip_list')):\n",
        "    clip_incoming_list = config.items('clip_list')\n",
        "    clip_incoming_models = clip_incoming_list[0]\n",
        "    incoming_perceptors = eval(clip_incoming_models[1])\n",
        "    if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "      clip_load_list = incoming_perceptors\n",
        "      clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "  #Load settings from config and replace variables\n",
        "  if(config.has_section('basic_settings')):\n",
        "    basic_settings = config.items('basic_settings')\n",
        "    for basic_setting in basic_settings:\n",
        "      global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "  \n",
        "  if(config.has_section('advanced_settings')):\n",
        "    advanced_settings = config.items('advanced_settings')\n",
        "    for advanced_setting in advanced_settings:\n",
        "      global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "  custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "prompts = clip_prompts\n",
        "opt.prompt = latent_prompts\n",
        "opt.uc = latent_negatives\n",
        "custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "aes_scale = aesthetic_loss_scale\n",
        "try: \n",
        "  clip_guidance_schedule\n",
        "  clip_guidance_index = clip_guidance_schedule\n",
        "except:\n",
        "  clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "opt.W = (width//64)*64;\n",
        "opt.H = (height//64)*64;\n",
        "if opt.W != width or opt.H != height:\n",
        "    print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "opt.mag_mul = opt_mag_mul \n",
        "opt.ddim_eta = opt_ddim_eta\n",
        "opt.eta_end = opt_eta_end\n",
        "opt.temperature = opt_temperature\n",
        "opt.n_iter = how_many_batches\n",
        "opt.n_samples =  1\n",
        "opt.scale = latent_diffusion_guidance_scale\n",
        "opt.plms = opt_plms\n",
        "aug = augment_cuts\n",
        "\n",
        "#Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "if(len(clamp_index) == 2): \n",
        "  clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "else:\n",
        "  clamp_index_variation = clamp_index\n",
        "score_corrector = DotMap()\n",
        "\n",
        "\n",
        "def modify_score(e_t, e_t_uncond):\n",
        "        if(score_modifier is False):\n",
        "          return e_t\n",
        "        else:\n",
        "          e_t_d = (e_t - e_t_uncond)\n",
        "          s = torch.quantile(\n",
        "              rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "              threshold_percentile,\n",
        "              dim = -1\n",
        "          )\n",
        "\n",
        "        s.clamp_(min = 1.)\n",
        "        s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "        if ths_method == \"softsign\":\n",
        "            e_t_d = F.softsign(e_t_d) / s \n",
        "        elif ths_method == \"clamp\":\n",
        "            e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "        e_t = e_t_uncond + e_t_d\n",
        "        return(e_t)\n",
        "          \n",
        "score_corrector.modify_score = modify_score\n",
        "\n",
        "def dynamic_thresholding(pred_x0,t):\n",
        "    return(pred_x0)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "generate_video = False\n",
        "if generate_video: \n",
        "    fps = 24\n",
        "    p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "do_run()\n",
        "if generate_video: \n",
        "    p.stdin.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "FhlYCX3q12sI"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#@markdown ### **Run 10.** Basic Settings\n",
        "\n",
        "width = 256 #@param{type: 'integer'}\n",
        "height = 384 #@param{type: 'integer'}\n",
        "\n",
        "clamp_index = [1, 1] #@param{type: 'raw'}\n",
        "\n",
        "latent_diffusion_guidance_scale = 14 #@param {type:\"number\"}\n",
        "clip_guidance_scale = 8000 #@param{type: 'integer'}\n",
        "\n",
        "how_many_batches = 1 #@param{type: 'integer'}\n",
        "aesthetic_loss_scale = 10 #@param{type: 'integer'}\n",
        "augment_cuts = True #@param{type:'boolean'}\n",
        "\n",
        "\n",
        "#@markdown ### Custom saved settings\n",
        "#@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "custom_settings = '' #@param{type:'string'}\n",
        "settings_library = 'makeitrad_defaults' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "if(settings_library != 'None (use settings defined above)'):\n",
        "  custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "global_var_scope = globals()\n",
        "if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "  print('Loaded ', custom_settings)\n",
        "  try:\n",
        "    from configparser import ConfigParser\n",
        "  except ImportError:\n",
        "      from ConfigParser import ConfigParser\n",
        "  import configparser\n",
        "  \n",
        "  config = ConfigParser()\n",
        "  config.read(custom_settings)\n",
        "  #custom_settings_stream = fetch(custom_settings)\n",
        "  #Load CLIP models from config\n",
        "  if(config.has_section('clip_list')):\n",
        "    clip_incoming_list = config.items('clip_list')\n",
        "    clip_incoming_models = clip_incoming_list[0]\n",
        "    incoming_perceptors = eval(clip_incoming_models[1])\n",
        "    if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "      clip_load_list = incoming_perceptors\n",
        "      clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "  #Load settings from config and replace variables\n",
        "  if(config.has_section('basic_settings')):\n",
        "    basic_settings = config.items('basic_settings')\n",
        "    for basic_setting in basic_settings:\n",
        "      global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "  \n",
        "  if(config.has_section('advanced_settings')):\n",
        "    advanced_settings = config.items('advanced_settings')\n",
        "    for advanced_setting in advanced_settings:\n",
        "      global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "  custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "prompts = clip_prompts\n",
        "opt.prompt = latent_prompts\n",
        "opt.uc = latent_negatives\n",
        "custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "aes_scale = aesthetic_loss_scale\n",
        "try: \n",
        "  clip_guidance_schedule\n",
        "  clip_guidance_index = clip_guidance_schedule\n",
        "except:\n",
        "  clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "opt.W = (width//64)*64;\n",
        "opt.H = (height//64)*64;\n",
        "if opt.W != width or opt.H != height:\n",
        "    print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "opt.mag_mul = opt_mag_mul \n",
        "opt.ddim_eta = opt_ddim_eta\n",
        "opt.eta_end = opt_eta_end\n",
        "opt.temperature = opt_temperature\n",
        "opt.n_iter = how_many_batches\n",
        "opt.n_samples =  1\n",
        "opt.scale = latent_diffusion_guidance_scale\n",
        "opt.plms = opt_plms\n",
        "aug = augment_cuts\n",
        "\n",
        "#Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "if(len(clamp_index) == 2): \n",
        "  clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "else:\n",
        "  clamp_index_variation = clamp_index\n",
        "score_corrector = DotMap()\n",
        "\n",
        "\n",
        "def modify_score(e_t, e_t_uncond):\n",
        "        if(score_modifier is False):\n",
        "          return e_t\n",
        "        else:\n",
        "          e_t_d = (e_t - e_t_uncond)\n",
        "          s = torch.quantile(\n",
        "              rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "              threshold_percentile,\n",
        "              dim = -1\n",
        "          )\n",
        "\n",
        "        s.clamp_(min = 1.)\n",
        "        s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "        if ths_method == \"softsign\":\n",
        "            e_t_d = F.softsign(e_t_d) / s \n",
        "        elif ths_method == \"clamp\":\n",
        "            e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "        e_t = e_t_uncond + e_t_d\n",
        "        return(e_t)\n",
        "          \n",
        "score_corrector.modify_score = modify_score\n",
        "\n",
        "def dynamic_thresholding(pred_x0,t):\n",
        "    return(pred_x0)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "generate_video = False\n",
        "if generate_video: \n",
        "    fps = 24\n",
        "    p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "do_run()\n",
        "if generate_video: \n",
        "    p.stdin.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hz-UUtoZLCzG"
      },
      "source": [
        "### 𝗗ᴇᴋᴀ-𝗕ᴀᴛᴄʜ 𝗥ᴜɴ 𝗖ᴇʟʟ𝘀 **X1** - Ecchi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "init_image = \"https://i.imgur.com/q8TWOyJ.png\" #@param{type: 'string'}\n",
        "if(init_image == '' or init_image == 'None'):\n",
        "  init_image = None\n",
        "\n",
        "#default 0.9\n",
        "starting_timestep = 0.0 #@param{type: 'number'}\n",
        "\n",
        "init_mask = None #@param{type: 'string'}\n",
        "\n",
        "init_scale = 1000 #@param{type: 'integer'}\n",
        "\n",
        "#default 0.0\n",
        "init_brightness = 0.0 #@param{type: 'number'}\n",
        "\n",
        "#default 0.57\n",
        "init_noise = 0.0 #@param{type: 'number'}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Ndqc3SBULZOA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Tt-mBnWpLCzL"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#@markdown ### **Run 1.** Basic settings\n",
        "\n",
        "#@markdown We're still figuring out default settings. Experiment and <a href=\"https://huggingface.co/datasets/multimodalart/latent-majesty-diffusion-settings\">share your settings with us</a>.\n",
        "\n",
        "#@markdown ✦✦ TO DO: Add init image cut schedule toggle, init and config skip toggles. ✦✦\n",
        "\n",
        "width = 256 #@param{type: 'integer'}\n",
        "height = 384 #@param{type: 'integer'}\n",
        "\n",
        "clamp_index = [2.4, 2.1] #@param{type: 'raw'}\n",
        "\n",
        "latent_diffusion_guidance_scale = 12 #@param {type:\"number\"}\n",
        "clip_guidance_scale = 12000 #@param{type: 'integer'}\n",
        "\n",
        "how_many_batches = 1 #@param{type: 'integer'}\n",
        "\n",
        "aesthetic_loss_scale = 100 #@param{type: 'integer'}\n",
        "augment_cuts = True #@param{type:'boolean'}\n",
        "\n",
        "\n",
        "#@markdown ### Custom saved settings\n",
        "#@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "custom_settings = '' #@param{type:'string'}\n",
        "settings_library = 'None (use settings defined above)' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "if(settings_library != 'None (use settings defined above)'):\n",
        "  custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "global_var_scope = globals()\n",
        "if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "  print('Loaded ', custom_settings)\n",
        "  try:\n",
        "    from configparser import ConfigParser\n",
        "  except ImportError:\n",
        "      from ConfigParser import ConfigParser\n",
        "  import configparser\n",
        "  \n",
        "  config = ConfigParser()\n",
        "  config.read(custom_settings)\n",
        "  #custom_settings_stream = fetch(custom_settings)\n",
        "  #Load CLIP models from config\n",
        "  if(config.has_section('clip_list')):\n",
        "    clip_incoming_list = config.items('clip_list')\n",
        "    clip_incoming_models = clip_incoming_list[0]\n",
        "    incoming_perceptors = eval(clip_incoming_models[1])\n",
        "    if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "      clip_load_list = incoming_perceptors\n",
        "      clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "  #Load settings from config and replace variables\n",
        "  if(config.has_section('basic_settings')):\n",
        "    basic_settings = config.items('basic_settings')\n",
        "    for basic_setting in basic_settings:\n",
        "      global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "  \n",
        "  if(config.has_section('advanced_settings')):\n",
        "    advanced_settings = config.items('advanced_settings')\n",
        "    for advanced_setting in advanced_settings:\n",
        "      global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "  custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "prompts = clip_prompts\n",
        "opt.prompt = latent_prompts\n",
        "opt.uc = latent_negatives\n",
        "custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "aes_scale = aesthetic_loss_scale\n",
        "try: \n",
        "  clip_guidance_schedule\n",
        "  clip_guidance_index = clip_guidance_schedule\n",
        "except:\n",
        "  clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "opt.W = (width//64)*64;\n",
        "opt.H = (height//64)*64;\n",
        "if opt.W != width or opt.H != height:\n",
        "    print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "opt.mag_mul = opt_mag_mul \n",
        "opt.ddim_eta = opt_ddim_eta\n",
        "opt.eta_end = opt_eta_end\n",
        "opt.temperature = opt_temperature\n",
        "opt.n_iter = how_many_batches\n",
        "opt.n_samples =  1\n",
        "opt.scale = latent_diffusion_guidance_scale\n",
        "opt.plms = opt_plms\n",
        "aug = augment_cuts\n",
        "\n",
        "#Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "if(len(clamp_index) == 2): \n",
        "  clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "else:\n",
        "  clamp_index_variation = clamp_index\n",
        "score_corrector = DotMap()\n",
        "\n",
        "\n",
        "def modify_score(e_t, e_t_uncond):\n",
        "        if(score_modifier is False):\n",
        "          return e_t\n",
        "        else:\n",
        "          e_t_d = (e_t - e_t_uncond)\n",
        "          s = torch.quantile(\n",
        "              rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "              threshold_percentile,\n",
        "              dim = -1\n",
        "          )\n",
        "\n",
        "        s.clamp_(min = 1.)\n",
        "        s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "        if ths_method == \"softsign\":\n",
        "            e_t_d = F.softsign(e_t_d) / s \n",
        "        elif ths_method == \"clamp\":\n",
        "            e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "        e_t = e_t_uncond + e_t_d\n",
        "        return(e_t)\n",
        "          \n",
        "score_corrector.modify_score = modify_score\n",
        "\n",
        "def dynamic_thresholding(pred_x0,t):\n",
        "    return(pred_x0)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "generate_video = False\n",
        "if generate_video: \n",
        "    fps = 24\n",
        "    p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "do_run()\n",
        "if generate_video: \n",
        "    p.stdin.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "MHNsOwnaLCzM"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#@markdown ### **Run 2.** Basic settings\n",
        "\n",
        "width = 256 #@param{type: 'integer'}\n",
        "height = 384 #@param{type: 'integer'}\n",
        "\n",
        "clamp_index = [2.1, 2.4] #@param{type: 'raw'}\n",
        "\n",
        "latent_diffusion_guidance_scale = 15 #@param {type:\"number\"}\n",
        "clip_guidance_scale = 50000 #@param{type: 'integer'}\n",
        "\n",
        "how_many_batches = 1 #@param{type: 'integer'}\n",
        "\n",
        "aesthetic_loss_scale = 200 #@param{type: 'integer'}\n",
        "augment_cuts = True #@param{type:'boolean'}\n",
        "\n",
        "\n",
        "#@markdown ### Custom saved settings\n",
        "#@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "custom_settings = '' #@param{type:'string'}\n",
        "settings_library = 'None (use settings defined above)' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "if(settings_library != 'None (use settings defined above)'):\n",
        "  custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "global_var_scope = globals()\n",
        "if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "  print('Loaded ', custom_settings)\n",
        "  try:\n",
        "    from configparser import ConfigParser\n",
        "  except ImportError:\n",
        "      from ConfigParser import ConfigParser\n",
        "  import configparser\n",
        "  \n",
        "  config = ConfigParser()\n",
        "  config.read(custom_settings)\n",
        "  #custom_settings_stream = fetch(custom_settings)\n",
        "  #Load CLIP models from config\n",
        "  if(config.has_section('clip_list')):\n",
        "    clip_incoming_list = config.items('clip_list')\n",
        "    clip_incoming_models = clip_incoming_list[0]\n",
        "    incoming_perceptors = eval(clip_incoming_models[1])\n",
        "    if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "      clip_load_list = incoming_perceptors\n",
        "      clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "  #Load settings from config and replace variables\n",
        "  if(config.has_section('basic_settings')):\n",
        "    basic_settings = config.items('basic_settings')\n",
        "    for basic_setting in basic_settings:\n",
        "      global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "  \n",
        "  if(config.has_section('advanced_settings')):\n",
        "    advanced_settings = config.items('advanced_settings')\n",
        "    for advanced_setting in advanced_settings:\n",
        "      global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "  custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "prompts = clip_prompts\n",
        "opt.prompt = latent_prompts\n",
        "opt.uc = latent_negatives\n",
        "custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "aes_scale = aesthetic_loss_scale\n",
        "try: \n",
        "  clip_guidance_schedule\n",
        "  clip_guidance_index = clip_guidance_schedule\n",
        "except:\n",
        "  clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "opt.W = (width//64)*64;\n",
        "opt.H = (height//64)*64;\n",
        "if opt.W != width or opt.H != height:\n",
        "    print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "opt.mag_mul = opt_mag_mul \n",
        "opt.ddim_eta = opt_ddim_eta\n",
        "opt.eta_end = opt_eta_end\n",
        "opt.temperature = opt_temperature\n",
        "opt.n_iter = how_many_batches\n",
        "opt.n_samples =  1\n",
        "opt.scale = latent_diffusion_guidance_scale\n",
        "opt.plms = opt_plms\n",
        "aug = augment_cuts\n",
        "\n",
        "#Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "if(len(clamp_index) == 2): \n",
        "  clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "else:\n",
        "  clamp_index_variation = clamp_index\n",
        "score_corrector = DotMap()\n",
        "\n",
        "\n",
        "def modify_score(e_t, e_t_uncond):\n",
        "        if(score_modifier is False):\n",
        "          return e_t\n",
        "        else:\n",
        "          e_t_d = (e_t - e_t_uncond)\n",
        "          s = torch.quantile(\n",
        "              rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "              threshold_percentile,\n",
        "              dim = -1\n",
        "          )\n",
        "\n",
        "        s.clamp_(min = 1.)\n",
        "        s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "        if ths_method == \"softsign\":\n",
        "            e_t_d = F.softsign(e_t_d) / s \n",
        "        elif ths_method == \"clamp\":\n",
        "            e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "        e_t = e_t_uncond + e_t_d\n",
        "        return(e_t)\n",
        "          \n",
        "score_corrector.modify_score = modify_score\n",
        "\n",
        "def dynamic_thresholding(pred_x0,t):\n",
        "    return(pred_x0)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "generate_video = False\n",
        "if generate_video: \n",
        "    fps = 24\n",
        "    p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "do_run()\n",
        "if generate_video: \n",
        "    p.stdin.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "I73sSdV4LCzM"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#@markdown ### **Run 3.** Basic settings\n",
        "\n",
        "width = 512 #@param{type: 'integer'}\n",
        "height = 256 #@param{type: 'integer'}\n",
        "\n",
        "clamp_index = [2.1, 2.1] #@param{type: 'raw'}\n",
        "\n",
        "latent_diffusion_guidance_scale = 12 #@param {type:\"number\"}\n",
        "clip_guidance_scale = 50000 #@param{type: 'integer'}\n",
        "\n",
        "how_many_batches = 1 #@param{type: 'integer'}\n",
        "\n",
        "aesthetic_loss_scale = 200 #@param{type: 'integer'}\n",
        "augment_cuts = True #@param{type:'boolean'}\n",
        "\n",
        "\n",
        "#@markdown ### Custom saved settings\n",
        "#@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "custom_settings = '' #@param{type:'string'}\n",
        "settings_library = 'None (use settings defined above)' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "if(settings_library != 'None (use settings defined above)'):\n",
        "  custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "global_var_scope = globals()\n",
        "if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "  print('Loaded ', custom_settings)\n",
        "  try:\n",
        "    from configparser import ConfigParser\n",
        "  except ImportError:\n",
        "      from ConfigParser import ConfigParser\n",
        "  import configparser\n",
        "  \n",
        "  config = ConfigParser()\n",
        "  config.read(custom_settings)\n",
        "  #custom_settings_stream = fetch(custom_settings)\n",
        "  #Load CLIP models from config\n",
        "  if(config.has_section('clip_list')):\n",
        "    clip_incoming_list = config.items('clip_list')\n",
        "    clip_incoming_models = clip_incoming_list[0]\n",
        "    incoming_perceptors = eval(clip_incoming_models[1])\n",
        "    if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "      clip_load_list = incoming_perceptors\n",
        "      clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "  #Load settings from config and replace variables\n",
        "  if(config.has_section('basic_settings')):\n",
        "    basic_settings = config.items('basic_settings')\n",
        "    for basic_setting in basic_settings:\n",
        "      global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "  \n",
        "  if(config.has_section('advanced_settings')):\n",
        "    advanced_settings = config.items('advanced_settings')\n",
        "    for advanced_setting in advanced_settings:\n",
        "      global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "  custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "prompts = clip_prompts\n",
        "opt.prompt = latent_prompts\n",
        "opt.uc = latent_negatives\n",
        "custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "aes_scale = aesthetic_loss_scale\n",
        "try: \n",
        "  clip_guidance_schedule\n",
        "  clip_guidance_index = clip_guidance_schedule\n",
        "except:\n",
        "  clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "opt.W = (width//64)*64;\n",
        "opt.H = (height//64)*64;\n",
        "if opt.W != width or opt.H != height:\n",
        "    print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "opt.mag_mul = opt_mag_mul \n",
        "opt.ddim_eta = opt_ddim_eta\n",
        "opt.eta_end = opt_eta_end\n",
        "opt.temperature = opt_temperature\n",
        "opt.n_iter = how_many_batches\n",
        "opt.n_samples =  1\n",
        "opt.scale = latent_diffusion_guidance_scale\n",
        "opt.plms = opt_plms\n",
        "aug = augment_cuts\n",
        "\n",
        "#Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "if(len(clamp_index) == 2): \n",
        "  clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "else:\n",
        "  clamp_index_variation = clamp_index\n",
        "score_corrector = DotMap()\n",
        "\n",
        "\n",
        "def modify_score(e_t, e_t_uncond):\n",
        "        if(score_modifier is False):\n",
        "          return e_t\n",
        "        else:\n",
        "          e_t_d = (e_t - e_t_uncond)\n",
        "          s = torch.quantile(\n",
        "              rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "              threshold_percentile,\n",
        "              dim = -1\n",
        "          )\n",
        "\n",
        "        s.clamp_(min = 1.)\n",
        "        s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "        if ths_method == \"softsign\":\n",
        "            e_t_d = F.softsign(e_t_d) / s \n",
        "        elif ths_method == \"clamp\":\n",
        "            e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "        e_t = e_t_uncond + e_t_d\n",
        "        return(e_t)\n",
        "          \n",
        "score_corrector.modify_score = modify_score\n",
        "\n",
        "def dynamic_thresholding(pred_x0,t):\n",
        "    return(pred_x0)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "generate_video = False\n",
        "if generate_video: \n",
        "    fps = 24\n",
        "    p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "do_run()\n",
        "if generate_video: \n",
        "    p.stdin.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "KbZgFhGRLCzM"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#@markdown ### **Run 4.** Basic settings\n",
        "\n",
        "width = 256 #@param{type: 'integer'}\n",
        "height = 512 #@param{type: 'integer'}\n",
        "\n",
        "clamp_index = [1.5, 2.0] #@param{type: 'raw'}\n",
        "\n",
        "latent_diffusion_guidance_scale = 6 #@param {type:\"number\"}\n",
        "clip_guidance_scale = 36000 #@param{type: 'integer'}\n",
        "\n",
        "how_many_batches = 1 #@param{type: 'integer'}\n",
        "aesthetic_loss_scale = 100 #@param{type: 'integer'}\n",
        "augment_cuts = True #@param{type:'boolean'}\n",
        "\n",
        "\n",
        "#@markdown\n",
        "\n",
        "#@markdown ### Custom saved settings\n",
        "#@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "custom_settings = '' #@param{type:'string'}\n",
        "settings_library = 'None (use settings defined above)' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "if(settings_library != 'None (use settings defined above)'):\n",
        "  custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "global_var_scope = globals()\n",
        "if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "  print('Loaded ', custom_settings)\n",
        "  try:\n",
        "    from configparser import ConfigParser\n",
        "  except ImportError:\n",
        "      from ConfigParser import ConfigParser\n",
        "  import configparser\n",
        "  \n",
        "  config = ConfigParser()\n",
        "  config.read(custom_settings)\n",
        "  #custom_settings_stream = fetch(custom_settings)\n",
        "  #Load CLIP models from config\n",
        "  if(config.has_section('clip_list')):\n",
        "    clip_incoming_list = config.items('clip_list')\n",
        "    clip_incoming_models = clip_incoming_list[0]\n",
        "    incoming_perceptors = eval(clip_incoming_models[1])\n",
        "    if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "      clip_load_list = incoming_perceptors\n",
        "      clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "  #Load settings from config and replace variables\n",
        "  if(config.has_section('basic_settings')):\n",
        "    basic_settings = config.items('basic_settings')\n",
        "    for basic_setting in basic_settings:\n",
        "      global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "  \n",
        "  if(config.has_section('advanced_settings')):\n",
        "    advanced_settings = config.items('advanced_settings')\n",
        "    for advanced_setting in advanced_settings:\n",
        "      global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "  custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "prompts = clip_prompts\n",
        "opt.prompt = latent_prompts\n",
        "opt.uc = latent_negatives\n",
        "custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "aes_scale = aesthetic_loss_scale\n",
        "try: \n",
        "  clip_guidance_schedule\n",
        "  clip_guidance_index = clip_guidance_schedule\n",
        "except:\n",
        "  clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "opt.W = (width//64)*64;\n",
        "opt.H = (height//64)*64;\n",
        "if opt.W != width or opt.H != height:\n",
        "    print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "opt.mag_mul = opt_mag_mul \n",
        "opt.ddim_eta = opt_ddim_eta\n",
        "opt.eta_end = opt_eta_end\n",
        "opt.temperature = opt_temperature\n",
        "opt.n_iter = how_many_batches\n",
        "opt.n_samples =  1\n",
        "opt.scale = latent_diffusion_guidance_scale\n",
        "opt.plms = opt_plms\n",
        "aug = augment_cuts\n",
        "\n",
        "#Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "if(len(clamp_index) == 2): \n",
        "  clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "else:\n",
        "  clamp_index_variation = clamp_index\n",
        "score_corrector = DotMap()\n",
        "\n",
        "\n",
        "def modify_score(e_t, e_t_uncond):\n",
        "        if(score_modifier is False):\n",
        "          return e_t\n",
        "        else:\n",
        "          e_t_d = (e_t - e_t_uncond)\n",
        "          s = torch.quantile(\n",
        "              rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "              threshold_percentile,\n",
        "              dim = -1\n",
        "          )\n",
        "\n",
        "        s.clamp_(min = 1.)\n",
        "        s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "        if ths_method == \"softsign\":\n",
        "            e_t_d = F.softsign(e_t_d) / s \n",
        "        elif ths_method == \"clamp\":\n",
        "            e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "        e_t = e_t_uncond + e_t_d\n",
        "        return(e_t)\n",
        "          \n",
        "score_corrector.modify_score = modify_score\n",
        "\n",
        "def dynamic_thresholding(pred_x0,t):\n",
        "    return(pred_x0)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "generate_video = False\n",
        "if generate_video: \n",
        "    fps = 24\n",
        "    p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "do_run()\n",
        "if generate_video: \n",
        "    p.stdin.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "WRscs1eRLCzM"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#@markdown ### **Run 5.** Basic settings\n",
        "\n",
        "#@markdown We're still figuring out default settings. Experiment and <a href=\"https://huggingface.co/datasets/multimodalart/latent-majesty-diffusion-settings\">share your settings with us</a>.\n",
        "\n",
        "width = 512 #@param{type: 'integer'}\n",
        "height = 256 #@param{type: 'integer'}\n",
        "\n",
        "clamp_index = [2.1, 2.4] #@param{type: 'raw'}\n",
        "\n",
        "latent_diffusion_guidance_scale = 9 #@param {type:\"number\"}\n",
        "clip_guidance_scale = 16000 #@param{type: 'integer'}\n",
        "\n",
        "how_many_batches = 1#@param{type: 'integer'}\n",
        "aesthetic_loss_scale = 100 #@param{type: 'integer'}\n",
        "augment_cuts = True #@param{type:'boolean'}\n",
        "\n",
        "\n",
        "#@markdown\n",
        "\n",
        "#@markdown ### Custom saved settings\n",
        "#@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "custom_settings = '' #@param{type:'string'}\n",
        "settings_library = 'default' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "if(settings_library != 'None (use settings defined above)'):\n",
        "  custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "global_var_scope = globals()\n",
        "if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "  print('Loaded ', custom_settings)\n",
        "  try:\n",
        "    from configparser import ConfigParser\n",
        "  except ImportError:\n",
        "      from ConfigParser import ConfigParser\n",
        "  import configparser\n",
        "  \n",
        "  config = ConfigParser()\n",
        "  config.read(custom_settings)\n",
        "  #custom_settings_stream = fetch(custom_settings)\n",
        "  #Load CLIP models from config\n",
        "  if(config.has_section('clip_list')):\n",
        "    clip_incoming_list = config.items('clip_list')\n",
        "    clip_incoming_models = clip_incoming_list[0]\n",
        "    incoming_perceptors = eval(clip_incoming_models[1])\n",
        "    if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "      clip_load_list = incoming_perceptors\n",
        "      clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "  #Load settings from config and replace variables\n",
        "  if(config.has_section('basic_settings')):\n",
        "    basic_settings = config.items('basic_settings')\n",
        "    for basic_setting in basic_settings:\n",
        "      global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "  \n",
        "  if(config.has_section('advanced_settings')):\n",
        "    advanced_settings = config.items('advanced_settings')\n",
        "    for advanced_setting in advanced_settings:\n",
        "      global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "  custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "prompts = clip_prompts\n",
        "opt.prompt = latent_prompts\n",
        "opt.uc = latent_negatives\n",
        "custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "aes_scale = aesthetic_loss_scale\n",
        "try: \n",
        "  clip_guidance_schedule\n",
        "  clip_guidance_index = clip_guidance_schedule\n",
        "except:\n",
        "  clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "opt.W = (width//64)*64;\n",
        "opt.H = (height//64)*64;\n",
        "if opt.W != width or opt.H != height:\n",
        "    print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "opt.mag_mul = opt_mag_mul \n",
        "opt.ddim_eta = opt_ddim_eta\n",
        "opt.eta_end = opt_eta_end\n",
        "opt.temperature = opt_temperature\n",
        "opt.n_iter = how_many_batches\n",
        "opt.n_samples =  1\n",
        "opt.scale = latent_diffusion_guidance_scale\n",
        "opt.plms = opt_plms\n",
        "aug = augment_cuts\n",
        "\n",
        "#Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "if(len(clamp_index) == 2): \n",
        "  clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "else:\n",
        "  clamp_index_variation = clamp_index\n",
        "score_corrector = DotMap()\n",
        "\n",
        "\n",
        "def modify_score(e_t, e_t_uncond):\n",
        "        if(score_modifier is False):\n",
        "          return e_t\n",
        "        else:\n",
        "          e_t_d = (e_t - e_t_uncond)\n",
        "          s = torch.quantile(\n",
        "              rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "              threshold_percentile,\n",
        "              dim = -1\n",
        "          )\n",
        "\n",
        "        s.clamp_(min = 1.)\n",
        "        s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "        if ths_method == \"softsign\":\n",
        "            e_t_d = F.softsign(e_t_d) / s \n",
        "        elif ths_method == \"clamp\":\n",
        "            e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "        e_t = e_t_uncond + e_t_d\n",
        "        return(e_t)\n",
        "          \n",
        "score_corrector.modify_score = modify_score\n",
        "\n",
        "def dynamic_thresholding(pred_x0,t):\n",
        "    return(pred_x0)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "generate_video = False\n",
        "if generate_video: \n",
        "    fps = 24\n",
        "    p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "do_run()\n",
        "if generate_video: \n",
        "    p.stdin.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "61eQY_EOLCzN"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#@markdown ### **Run 6.** Basic Settings\n",
        "\n",
        "width = 256 #@param{type: 'integer'}\n",
        "height = 384 #@param{type: 'integer'}\n",
        "\n",
        "clamp_index = [2.4, 2.1] #@param{type: 'raw'}\n",
        "\n",
        "latent_diffusion_guidance_scale = 15 #@param {type:\"number\"}\n",
        "clip_guidance_scale = 20000 #@param{type: 'integer'}\n",
        "\n",
        "how_many_batches = 1 #@param{type: 'integer'}\n",
        "aesthetic_loss_scale = 100 #@param{type: 'integer'}\n",
        "augment_cuts = True #@param{type:'boolean'}\n",
        "\n",
        "\n",
        "#@markdown\n",
        "\n",
        "#@markdown ### Custom saved settings\n",
        "#@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "custom_settings = '' #@param{type:'string'}\n",
        "settings_library = 'default' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "if(settings_library != 'None (use settings defined above)'):\n",
        "  custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "global_var_scope = globals()\n",
        "if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "  print('Loaded ', custom_settings)\n",
        "  try:\n",
        "    from configparser import ConfigParser\n",
        "  except ImportError:\n",
        "      from ConfigParser import ConfigParser\n",
        "  import configparser\n",
        "  \n",
        "  config = ConfigParser()\n",
        "  config.read(custom_settings)\n",
        "  #custom_settings_stream = fetch(custom_settings)\n",
        "  #Load CLIP models from config\n",
        "  if(config.has_section('clip_list')):\n",
        "    clip_incoming_list = config.items('clip_list')\n",
        "    clip_incoming_models = clip_incoming_list[0]\n",
        "    incoming_perceptors = eval(clip_incoming_models[1])\n",
        "    if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "      clip_load_list = incoming_perceptors\n",
        "      clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "  #Load settings from config and replace variables\n",
        "  if(config.has_section('basic_settings')):\n",
        "    basic_settings = config.items('basic_settings')\n",
        "    for basic_setting in basic_settings:\n",
        "      global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "  \n",
        "  if(config.has_section('advanced_settings')):\n",
        "    advanced_settings = config.items('advanced_settings')\n",
        "    for advanced_setting in advanced_settings:\n",
        "      global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "  custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "prompts = clip_prompts\n",
        "opt.prompt = latent_prompts\n",
        "opt.uc = latent_negatives\n",
        "custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "aes_scale = aesthetic_loss_scale\n",
        "try: \n",
        "  clip_guidance_schedule\n",
        "  clip_guidance_index = clip_guidance_schedule\n",
        "except:\n",
        "  clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "opt.W = (width//64)*64;\n",
        "opt.H = (height//64)*64;\n",
        "if opt.W != width or opt.H != height:\n",
        "    print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "opt.mag_mul = opt_mag_mul \n",
        "opt.ddim_eta = opt_ddim_eta\n",
        "opt.eta_end = opt_eta_end\n",
        "opt.temperature = opt_temperature\n",
        "opt.n_iter = how_many_batches\n",
        "opt.n_samples =  1\n",
        "opt.scale = latent_diffusion_guidance_scale\n",
        "opt.plms = opt_plms\n",
        "aug = augment_cuts\n",
        "\n",
        "#Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "if(len(clamp_index) == 2): \n",
        "  clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "else:\n",
        "  clamp_index_variation = clamp_index\n",
        "score_corrector = DotMap()\n",
        "\n",
        "\n",
        "def modify_score(e_t, e_t_uncond):\n",
        "        if(score_modifier is False):\n",
        "          return e_t\n",
        "        else:\n",
        "          e_t_d = (e_t - e_t_uncond)\n",
        "          s = torch.quantile(\n",
        "              rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "              threshold_percentile,\n",
        "              dim = -1\n",
        "          )\n",
        "\n",
        "        s.clamp_(min = 1.)\n",
        "        s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "        if ths_method == \"softsign\":\n",
        "            e_t_d = F.softsign(e_t_d) / s \n",
        "        elif ths_method == \"clamp\":\n",
        "            e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "        e_t = e_t_uncond + e_t_d\n",
        "        return(e_t)\n",
        "          \n",
        "score_corrector.modify_score = modify_score\n",
        "\n",
        "def dynamic_thresholding(pred_x0,t):\n",
        "    return(pred_x0)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "generate_video = False\n",
        "if generate_video: \n",
        "    fps = 24\n",
        "    p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "do_run()\n",
        "if generate_video: \n",
        "    p.stdin.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "CPqliSWDLCzN"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#@markdown ### **Run 7.** Basic Settings\n",
        "\n",
        "width = 384 #@param{type: 'integer'}\n",
        "height = 384 #@param{type: 'integer'}\n",
        "\n",
        "clamp_index = [0.6, 0.6] #@param{type: 'raw'}\n",
        "\n",
        "latent_diffusion_guidance_scale = 11 #@param {type:\"number\"}\n",
        "clip_guidance_scale = 39999 #@param{type: 'integer'}\n",
        "\n",
        "how_many_batches = 1 #@param{type: 'integer'}\n",
        "aesthetic_loss_scale = 100 #@param{type: 'integer'}\n",
        "augment_cuts = True #@param{type:'boolean'}\n",
        "\n",
        "\n",
        "#@markdown ### Custom saved settings\n",
        "#@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "custom_settings = '' #@param{type:'string'}\n",
        "settings_library = 'coherent_pizzapigeon' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "if(settings_library != 'None (use settings defined above)'):\n",
        "  custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "global_var_scope = globals()\n",
        "if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "  print('Loaded ', custom_settings)\n",
        "  try:\n",
        "    from configparser import ConfigParser\n",
        "  except ImportError:\n",
        "      from ConfigParser import ConfigParser\n",
        "  import configparser\n",
        "  \n",
        "  config = ConfigParser()\n",
        "  config.read(custom_settings)\n",
        "  #custom_settings_stream = fetch(custom_settings)\n",
        "  #Load CLIP models from config\n",
        "  if(config.has_section('clip_list')):\n",
        "    clip_incoming_list = config.items('clip_list')\n",
        "    clip_incoming_models = clip_incoming_list[0]\n",
        "    incoming_perceptors = eval(clip_incoming_models[1])\n",
        "    if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "      clip_load_list = incoming_perceptors\n",
        "      clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "  #Load settings from config and replace variables\n",
        "  if(config.has_section('basic_settings')):\n",
        "    basic_settings = config.items('basic_settings')\n",
        "    for basic_setting in basic_settings:\n",
        "      global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "  \n",
        "  if(config.has_section('advanced_settings')):\n",
        "    advanced_settings = config.items('advanced_settings')\n",
        "    for advanced_setting in advanced_settings:\n",
        "      global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "  custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "prompts = clip_prompts\n",
        "opt.prompt = latent_prompts\n",
        "opt.uc = latent_negatives\n",
        "custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "aes_scale = aesthetic_loss_scale\n",
        "try: \n",
        "  clip_guidance_schedule\n",
        "  clip_guidance_index = clip_guidance_schedule\n",
        "except:\n",
        "  clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "opt.W = (width//64)*64;\n",
        "opt.H = (height//64)*64;\n",
        "if opt.W != width or opt.H != height:\n",
        "    print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "opt.mag_mul = opt_mag_mul \n",
        "opt.ddim_eta = opt_ddim_eta\n",
        "opt.eta_end = opt_eta_end\n",
        "opt.temperature = opt_temperature\n",
        "opt.n_iter = how_many_batches\n",
        "opt.n_samples =  1\n",
        "opt.scale = latent_diffusion_guidance_scale\n",
        "opt.plms = opt_plms\n",
        "aug = augment_cuts\n",
        "\n",
        "#Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "if(len(clamp_index) == 2): \n",
        "  clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "else:\n",
        "  clamp_index_variation = clamp_index\n",
        "score_corrector = DotMap()\n",
        "\n",
        "\n",
        "def modify_score(e_t, e_t_uncond):\n",
        "        if(score_modifier is False):\n",
        "          return e_t\n",
        "        else:\n",
        "          e_t_d = (e_t - e_t_uncond)\n",
        "          s = torch.quantile(\n",
        "              rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "              threshold_percentile,\n",
        "              dim = -1\n",
        "          )\n",
        "\n",
        "        s.clamp_(min = 1.)\n",
        "        s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "        if ths_method == \"softsign\":\n",
        "            e_t_d = F.softsign(e_t_d) / s \n",
        "        elif ths_method == \"clamp\":\n",
        "            e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "        e_t = e_t_uncond + e_t_d\n",
        "        return(e_t)\n",
        "          \n",
        "score_corrector.modify_score = modify_score\n",
        "\n",
        "def dynamic_thresholding(pred_x0,t):\n",
        "    return(pred_x0)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "generate_video = False\n",
        "if generate_video: \n",
        "    fps = 24\n",
        "    p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "do_run()\n",
        "if generate_video: \n",
        "    p.stdin.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "nVoPtpdELCzO"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#@markdown ### **Run 8.** Basic Settings\n",
        "\n",
        "width =  256#@param{type: 'integer'}\n",
        "height =  384#@param{type: 'integer'}\n",
        "\n",
        "clamp_index = [1, 1] #@param{type: 'raw'}\n",
        "\n",
        "latent_diffusion_guidance_scale = 10 #@param {type:\"number\"}\n",
        "clip_guidance_scale =  50000#@param{type: 'integer'}\n",
        "\n",
        "how_many_batches =  1#@param{type: 'integer'}\n",
        "\n",
        "aesthetic_loss_scale = 100 #@param{type: 'integer'}\n",
        "augment_cuts=True #@param{type:'boolean'}\n",
        "\n",
        "\n",
        "#@markdown ### Custom saved settings\n",
        "#@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "custom_settings = '' #@param{type:'string'}\n",
        "settings_library = 'coherent_pizzapigeon' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "if(settings_library != 'None (use settings defined above)'):\n",
        "  custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "global_var_scope = globals()\n",
        "if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "  print('Loaded ', custom_settings)\n",
        "  try:\n",
        "    from configparser import ConfigParser\n",
        "  except ImportError:\n",
        "      from ConfigParser import ConfigParser\n",
        "  import configparser\n",
        "  \n",
        "  config = ConfigParser()\n",
        "  config.read(custom_settings)\n",
        "  #custom_settings_stream = fetch(custom_settings)\n",
        "  #Load CLIP models from config\n",
        "  if(config.has_section('clip_list')):\n",
        "    clip_incoming_list = config.items('clip_list')\n",
        "    clip_incoming_models = clip_incoming_list[0]\n",
        "    incoming_perceptors = eval(clip_incoming_models[1])\n",
        "    if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "      clip_load_list = incoming_perceptors\n",
        "      clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "  #Load settings from config and replace variables\n",
        "  if(config.has_section('basic_settings')):\n",
        "    basic_settings = config.items('basic_settings')\n",
        "    for basic_setting in basic_settings:\n",
        "      global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "  \n",
        "  if(config.has_section('advanced_settings')):\n",
        "    advanced_settings = config.items('advanced_settings')\n",
        "    for advanced_setting in advanced_settings:\n",
        "      global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "  custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "prompts = clip_prompts\n",
        "opt.prompt = latent_prompts\n",
        "opt.uc = latent_negatives\n",
        "custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "aes_scale = aesthetic_loss_scale\n",
        "try: \n",
        "  clip_guidance_schedule\n",
        "  clip_guidance_index = clip_guidance_schedule\n",
        "except:\n",
        "  clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "opt.W = (width//64)*64;\n",
        "opt.H = (height//64)*64;\n",
        "if opt.W != width or opt.H != height:\n",
        "    print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "opt.mag_mul = opt_mag_mul \n",
        "opt.ddim_eta = opt_ddim_eta\n",
        "opt.eta_end = opt_eta_end\n",
        "opt.temperature = opt_temperature\n",
        "opt.n_iter = how_many_batches\n",
        "opt.n_samples =  1\n",
        "opt.scale = latent_diffusion_guidance_scale\n",
        "opt.plms = opt_plms\n",
        "aug = augment_cuts\n",
        "\n",
        "#Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "if(len(clamp_index) == 2): \n",
        "  clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "else:\n",
        "  clamp_index_variation = clamp_index\n",
        "score_corrector = DotMap()\n",
        "\n",
        "\n",
        "def modify_score(e_t, e_t_uncond):\n",
        "        if(score_modifier is False):\n",
        "          return e_t\n",
        "        else:\n",
        "          e_t_d = (e_t - e_t_uncond)\n",
        "          s = torch.quantile(\n",
        "              rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "              threshold_percentile,\n",
        "              dim = -1\n",
        "          )\n",
        "\n",
        "        s.clamp_(min = 1.)\n",
        "        s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "        if ths_method == \"softsign\":\n",
        "            e_t_d = F.softsign(e_t_d) / s \n",
        "        elif ths_method == \"clamp\":\n",
        "            e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "        e_t = e_t_uncond + e_t_d\n",
        "        return(e_t)\n",
        "          \n",
        "score_corrector.modify_score = modify_score\n",
        "\n",
        "def dynamic_thresholding(pred_x0,t):\n",
        "    return(pred_x0)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "generate_video = False\n",
        "if generate_video: \n",
        "    fps = 24\n",
        "    p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "do_run()\n",
        "if generate_video: \n",
        "    p.stdin.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ChmH1mSRLCzO"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#@markdown ### **Run 9.** Basic Settings\n",
        "\n",
        "width = 384 #@param{type: 'integer'}\n",
        "height = 256 #@param{type: 'integer'}\n",
        "\n",
        "clamp_index = [1, 1] #@param{type: 'raw'}\n",
        "\n",
        "latent_diffusion_guidance_scale = 13 #@param {type:\"number\"}\n",
        "clip_guidance_scale = 24000 #@param{type: 'integer'}\n",
        "\n",
        "how_many_batches =  1#@param{type: 'integer'}\n",
        "aesthetic_loss_scale =  1#@param{type: 'integer'}\n",
        "augment_cuts = True #@param{type:'boolean'}\n",
        "\n",
        "\n",
        "#@markdown ### Custom saved settings\n",
        "#@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "custom_settings = '' #@param{type:'string'}\n",
        "settings_library = 'makeitrad_defaults' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "if(settings_library != 'None (use settings defined above)'):\n",
        "  custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "global_var_scope = globals()\n",
        "if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "  print('Loaded ', custom_settings)\n",
        "  try:\n",
        "    from configparser import ConfigParser\n",
        "  except ImportError:\n",
        "      from ConfigParser import ConfigParser\n",
        "  import configparser\n",
        "  \n",
        "  config = ConfigParser()\n",
        "  config.read(custom_settings)\n",
        "  #custom_settings_stream = fetch(custom_settings)\n",
        "  #Load CLIP models from config\n",
        "  if(config.has_section('clip_list')):\n",
        "    clip_incoming_list = config.items('clip_list')\n",
        "    clip_incoming_models = clip_incoming_list[0]\n",
        "    incoming_perceptors = eval(clip_incoming_models[1])\n",
        "    if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "      clip_load_list = incoming_perceptors\n",
        "      clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "  #Load settings from config and replace variables\n",
        "  if(config.has_section('basic_settings')):\n",
        "    basic_settings = config.items('basic_settings')\n",
        "    for basic_setting in basic_settings:\n",
        "      global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "  \n",
        "  if(config.has_section('advanced_settings')):\n",
        "    advanced_settings = config.items('advanced_settings')\n",
        "    for advanced_setting in advanced_settings:\n",
        "      global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "  custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "prompts = clip_prompts\n",
        "opt.prompt = latent_prompts\n",
        "opt.uc = latent_negatives\n",
        "custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "aes_scale = aesthetic_loss_scale\n",
        "try: \n",
        "  clip_guidance_schedule\n",
        "  clip_guidance_index = clip_guidance_schedule\n",
        "except:\n",
        "  clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "opt.W = (width//64)*64;\n",
        "opt.H = (height//64)*64;\n",
        "if opt.W != width or opt.H != height:\n",
        "    print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "opt.mag_mul = opt_mag_mul \n",
        "opt.ddim_eta = opt_ddim_eta\n",
        "opt.eta_end = opt_eta_end\n",
        "opt.temperature = opt_temperature\n",
        "opt.n_iter = how_many_batches\n",
        "opt.n_samples =  1\n",
        "opt.scale = latent_diffusion_guidance_scale\n",
        "opt.plms = opt_plms\n",
        "aug = augment_cuts\n",
        "\n",
        "#Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "if(len(clamp_index) == 2): \n",
        "  clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "else:\n",
        "  clamp_index_variation = clamp_index\n",
        "score_corrector = DotMap()\n",
        "\n",
        "\n",
        "def modify_score(e_t, e_t_uncond):\n",
        "        if(score_modifier is False):\n",
        "          return e_t\n",
        "        else:\n",
        "          e_t_d = (e_t - e_t_uncond)\n",
        "          s = torch.quantile(\n",
        "              rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "              threshold_percentile,\n",
        "              dim = -1\n",
        "          )\n",
        "\n",
        "        s.clamp_(min = 1.)\n",
        "        s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "        if ths_method == \"softsign\":\n",
        "            e_t_d = F.softsign(e_t_d) / s \n",
        "        elif ths_method == \"clamp\":\n",
        "            e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "        e_t = e_t_uncond + e_t_d\n",
        "        return(e_t)\n",
        "          \n",
        "score_corrector.modify_score = modify_score\n",
        "\n",
        "def dynamic_thresholding(pred_x0,t):\n",
        "    return(pred_x0)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "generate_video = False\n",
        "if generate_video: \n",
        "    fps = 24\n",
        "    p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "do_run()\n",
        "if generate_video: \n",
        "    p.stdin.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "TWNjsFKrLCzP"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#@markdown ### **Run 10.** Basic Settings\n",
        "\n",
        "width = 256 #@param{type: 'integer'}\n",
        "height = 384 #@param{type: 'integer'}\n",
        "\n",
        "clamp_index = [1, 1] #@param{type: 'raw'}\n",
        "\n",
        "latent_diffusion_guidance_scale = 14 #@param {type:\"number\"}\n",
        "clip_guidance_scale = 8000 #@param{type: 'integer'}\n",
        "\n",
        "how_many_batches = 1 #@param{type: 'integer'}\n",
        "aesthetic_loss_scale = 10 #@param{type: 'integer'}\n",
        "augment_cuts = True #@param{type:'boolean'}\n",
        "\n",
        "\n",
        "#@markdown ### Custom saved settings\n",
        "#@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "custom_settings = '' #@param{type:'string'}\n",
        "settings_library = 'makeitrad_defaults' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "if(settings_library != 'None (use settings defined above)'):\n",
        "  custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "global_var_scope = globals()\n",
        "if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "  print('Loaded ', custom_settings)\n",
        "  try:\n",
        "    from configparser import ConfigParser\n",
        "  except ImportError:\n",
        "      from ConfigParser import ConfigParser\n",
        "  import configparser\n",
        "  \n",
        "  config = ConfigParser()\n",
        "  config.read(custom_settings)\n",
        "  #custom_settings_stream = fetch(custom_settings)\n",
        "  #Load CLIP models from config\n",
        "  if(config.has_section('clip_list')):\n",
        "    clip_incoming_list = config.items('clip_list')\n",
        "    clip_incoming_models = clip_incoming_list[0]\n",
        "    incoming_perceptors = eval(clip_incoming_models[1])\n",
        "    if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "      clip_load_list = incoming_perceptors\n",
        "      clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "  #Load settings from config and replace variables\n",
        "  if(config.has_section('basic_settings')):\n",
        "    basic_settings = config.items('basic_settings')\n",
        "    for basic_setting in basic_settings:\n",
        "      global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "  \n",
        "  if(config.has_section('advanced_settings')):\n",
        "    advanced_settings = config.items('advanced_settings')\n",
        "    for advanced_setting in advanced_settings:\n",
        "      global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "  custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "prompts = clip_prompts\n",
        "opt.prompt = latent_prompts\n",
        "opt.uc = latent_negatives\n",
        "custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "aes_scale = aesthetic_loss_scale\n",
        "try: \n",
        "  clip_guidance_schedule\n",
        "  clip_guidance_index = clip_guidance_schedule\n",
        "except:\n",
        "  clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "opt.W = (width//64)*64;\n",
        "opt.H = (height//64)*64;\n",
        "if opt.W != width or opt.H != height:\n",
        "    print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "opt.mag_mul = opt_mag_mul \n",
        "opt.ddim_eta = opt_ddim_eta\n",
        "opt.eta_end = opt_eta_end\n",
        "opt.temperature = opt_temperature\n",
        "opt.n_iter = how_many_batches\n",
        "opt.n_samples =  1\n",
        "opt.scale = latent_diffusion_guidance_scale\n",
        "opt.plms = opt_plms\n",
        "aug = augment_cuts\n",
        "\n",
        "#Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "if(len(clamp_index) == 2): \n",
        "  clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "else:\n",
        "  clamp_index_variation = clamp_index\n",
        "score_corrector = DotMap()\n",
        "\n",
        "\n",
        "def modify_score(e_t, e_t_uncond):\n",
        "        if(score_modifier is False):\n",
        "          return e_t\n",
        "        else:\n",
        "          e_t_d = (e_t - e_t_uncond)\n",
        "          s = torch.quantile(\n",
        "              rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "              threshold_percentile,\n",
        "              dim = -1\n",
        "          )\n",
        "\n",
        "        s.clamp_(min = 1.)\n",
        "        s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "        if ths_method == \"softsign\":\n",
        "            e_t_d = F.softsign(e_t_d) / s \n",
        "        elif ths_method == \"clamp\":\n",
        "            e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "        e_t = e_t_uncond + e_t_d\n",
        "        return(e_t)\n",
        "          \n",
        "score_corrector.modify_score = modify_score\n",
        "\n",
        "def dynamic_thresholding(pred_x0,t):\n",
        "    return(pred_x0)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "generate_video = False\n",
        "if generate_video: \n",
        "    fps = 24\n",
        "    p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "do_run()\n",
        "if generate_video: \n",
        "    p.stdin.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0w6W3qub2sP"
      },
      "source": [
        "### 𝗗ᴇᴋᴀ-𝗕ᴀᴛᴄʜ 𝗥ᴜɴ 𝗖ᴇʟʟ𝘀 **X2** - Vampire"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "init_image = \"https://i.imgur.com/ofaRzmO.png\" #@param{type: 'string'}\n",
        "if(init_image == '' or init_image == 'None'):\n",
        "  init_image = None\n",
        "\n",
        "#default 0.9\n",
        "starting_timestep = 0.5 #@param{type: 'number'}\n",
        "\n",
        "init_mask = None #@param{type: 'string'}\n",
        "\n",
        "init_scale = 1000 #@param{type: 'integer'}\n",
        "\n",
        "#default 0.0\n",
        "init_brightness = 0.0 #@param{type: 'number'}\n",
        "\n",
        "#default 0.57\n",
        "init_noise = 0.5 #@param{type: 'number'}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "zr4uMi0eb2sQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "OQxBFMLPb2sQ"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#@markdown ### **Run 1.** Basic settings\n",
        "\n",
        "#@markdown We're still figuring out default settings. Experiment and <a href=\"https://huggingface.co/datasets/multimodalart/latent-majesty-diffusion-settings\">share your settings with us</a>.\n",
        "\n",
        "#@markdown ✦✦ TO DO: Add init image cut schedule toggle, init and config skip toggles. ✦✦\n",
        "\n",
        "width = 256 #@param{type: 'integer'}\n",
        "height = 384 #@param{type: 'integer'}\n",
        "\n",
        "clamp_index = [2.4, 2.1] #@param{type: 'raw'}\n",
        "\n",
        "latent_diffusion_guidance_scale = 12 #@param {type:\"number\"}\n",
        "clip_guidance_scale = 12000 #@param{type: 'integer'}\n",
        "\n",
        "how_many_batches = 1 #@param{type: 'integer'}\n",
        "\n",
        "aesthetic_loss_scale = 100 #@param{type: 'integer'}\n",
        "augment_cuts = True #@param{type:'boolean'}\n",
        "\n",
        "\n",
        "#@markdown ### Custom saved settings\n",
        "#@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "custom_settings = '' #@param{type:'string'}\n",
        "settings_library = 'None (use settings defined above)' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "if(settings_library != 'None (use settings defined above)'):\n",
        "  custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "global_var_scope = globals()\n",
        "if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "  print('Loaded ', custom_settings)\n",
        "  try:\n",
        "    from configparser import ConfigParser\n",
        "  except ImportError:\n",
        "      from ConfigParser import ConfigParser\n",
        "  import configparser\n",
        "  \n",
        "  config = ConfigParser()\n",
        "  config.read(custom_settings)\n",
        "  #custom_settings_stream = fetch(custom_settings)\n",
        "  #Load CLIP models from config\n",
        "  if(config.has_section('clip_list')):\n",
        "    clip_incoming_list = config.items('clip_list')\n",
        "    clip_incoming_models = clip_incoming_list[0]\n",
        "    incoming_perceptors = eval(clip_incoming_models[1])\n",
        "    if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "      clip_load_list = incoming_perceptors\n",
        "      clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "  #Load settings from config and replace variables\n",
        "  if(config.has_section('basic_settings')):\n",
        "    basic_settings = config.items('basic_settings')\n",
        "    for basic_setting in basic_settings:\n",
        "      global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "  \n",
        "  if(config.has_section('advanced_settings')):\n",
        "    advanced_settings = config.items('advanced_settings')\n",
        "    for advanced_setting in advanced_settings:\n",
        "      global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "  custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "prompts = clip_prompts\n",
        "opt.prompt = latent_prompts\n",
        "opt.uc = latent_negatives\n",
        "custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "aes_scale = aesthetic_loss_scale\n",
        "try: \n",
        "  clip_guidance_schedule\n",
        "  clip_guidance_index = clip_guidance_schedule\n",
        "except:\n",
        "  clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "opt.W = (width//64)*64;\n",
        "opt.H = (height//64)*64;\n",
        "if opt.W != width or opt.H != height:\n",
        "    print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "opt.mag_mul = opt_mag_mul \n",
        "opt.ddim_eta = opt_ddim_eta\n",
        "opt.eta_end = opt_eta_end\n",
        "opt.temperature = opt_temperature\n",
        "opt.n_iter = how_many_batches\n",
        "opt.n_samples =  1\n",
        "opt.scale = latent_diffusion_guidance_scale\n",
        "opt.plms = opt_plms\n",
        "aug = augment_cuts\n",
        "\n",
        "#Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "if(len(clamp_index) == 2): \n",
        "  clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "else:\n",
        "  clamp_index_variation = clamp_index\n",
        "score_corrector = DotMap()\n",
        "\n",
        "\n",
        "def modify_score(e_t, e_t_uncond):\n",
        "        if(score_modifier is False):\n",
        "          return e_t\n",
        "        else:\n",
        "          e_t_d = (e_t - e_t_uncond)\n",
        "          s = torch.quantile(\n",
        "              rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "              threshold_percentile,\n",
        "              dim = -1\n",
        "          )\n",
        "\n",
        "        s.clamp_(min = 1.)\n",
        "        s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "        if ths_method == \"softsign\":\n",
        "            e_t_d = F.softsign(e_t_d) / s \n",
        "        elif ths_method == \"clamp\":\n",
        "            e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "        e_t = e_t_uncond + e_t_d\n",
        "        return(e_t)\n",
        "          \n",
        "score_corrector.modify_score = modify_score\n",
        "\n",
        "def dynamic_thresholding(pred_x0,t):\n",
        "    return(pred_x0)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "generate_video = False\n",
        "if generate_video: \n",
        "    fps = 24\n",
        "    p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "do_run()\n",
        "if generate_video: \n",
        "    p.stdin.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "6dnPTfE0b2sQ"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#@markdown ### **Run 2.** Basic settings\n",
        "\n",
        "width = 256 #@param{type: 'integer'}\n",
        "height = 384 #@param{type: 'integer'}\n",
        "\n",
        "clamp_index = [2.1, 2.4] #@param{type: 'raw'}\n",
        "\n",
        "latent_diffusion_guidance_scale = 15 #@param {type:\"number\"}\n",
        "clip_guidance_scale = 50000 #@param{type: 'integer'}\n",
        "\n",
        "how_many_batches = 1 #@param{type: 'integer'}\n",
        "\n",
        "aesthetic_loss_scale = 200 #@param{type: 'integer'}\n",
        "augment_cuts = True #@param{type:'boolean'}\n",
        "\n",
        "\n",
        "#@markdown ### Custom saved settings\n",
        "#@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "custom_settings = '' #@param{type:'string'}\n",
        "settings_library = 'None (use settings defined above)' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "if(settings_library != 'None (use settings defined above)'):\n",
        "  custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "global_var_scope = globals()\n",
        "if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "  print('Loaded ', custom_settings)\n",
        "  try:\n",
        "    from configparser import ConfigParser\n",
        "  except ImportError:\n",
        "      from ConfigParser import ConfigParser\n",
        "  import configparser\n",
        "  \n",
        "  config = ConfigParser()\n",
        "  config.read(custom_settings)\n",
        "  #custom_settings_stream = fetch(custom_settings)\n",
        "  #Load CLIP models from config\n",
        "  if(config.has_section('clip_list')):\n",
        "    clip_incoming_list = config.items('clip_list')\n",
        "    clip_incoming_models = clip_incoming_list[0]\n",
        "    incoming_perceptors = eval(clip_incoming_models[1])\n",
        "    if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "      clip_load_list = incoming_perceptors\n",
        "      clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "  #Load settings from config and replace variables\n",
        "  if(config.has_section('basic_settings')):\n",
        "    basic_settings = config.items('basic_settings')\n",
        "    for basic_setting in basic_settings:\n",
        "      global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "  \n",
        "  if(config.has_section('advanced_settings')):\n",
        "    advanced_settings = config.items('advanced_settings')\n",
        "    for advanced_setting in advanced_settings:\n",
        "      global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "  custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "prompts = clip_prompts\n",
        "opt.prompt = latent_prompts\n",
        "opt.uc = latent_negatives\n",
        "custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "aes_scale = aesthetic_loss_scale\n",
        "try: \n",
        "  clip_guidance_schedule\n",
        "  clip_guidance_index = clip_guidance_schedule\n",
        "except:\n",
        "  clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "opt.W = (width//64)*64;\n",
        "opt.H = (height//64)*64;\n",
        "if opt.W != width or opt.H != height:\n",
        "    print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "opt.mag_mul = opt_mag_mul \n",
        "opt.ddim_eta = opt_ddim_eta\n",
        "opt.eta_end = opt_eta_end\n",
        "opt.temperature = opt_temperature\n",
        "opt.n_iter = how_many_batches\n",
        "opt.n_samples =  1\n",
        "opt.scale = latent_diffusion_guidance_scale\n",
        "opt.plms = opt_plms\n",
        "aug = augment_cuts\n",
        "\n",
        "#Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "if(len(clamp_index) == 2): \n",
        "  clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "else:\n",
        "  clamp_index_variation = clamp_index\n",
        "score_corrector = DotMap()\n",
        "\n",
        "\n",
        "def modify_score(e_t, e_t_uncond):\n",
        "        if(score_modifier is False):\n",
        "          return e_t\n",
        "        else:\n",
        "          e_t_d = (e_t - e_t_uncond)\n",
        "          s = torch.quantile(\n",
        "              rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "              threshold_percentile,\n",
        "              dim = -1\n",
        "          )\n",
        "\n",
        "        s.clamp_(min = 1.)\n",
        "        s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "        if ths_method == \"softsign\":\n",
        "            e_t_d = F.softsign(e_t_d) / s \n",
        "        elif ths_method == \"clamp\":\n",
        "            e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "        e_t = e_t_uncond + e_t_d\n",
        "        return(e_t)\n",
        "          \n",
        "score_corrector.modify_score = modify_score\n",
        "\n",
        "def dynamic_thresholding(pred_x0,t):\n",
        "    return(pred_x0)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "generate_video = False\n",
        "if generate_video: \n",
        "    fps = 24\n",
        "    p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "do_run()\n",
        "if generate_video: \n",
        "    p.stdin.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "0ser66QNb2sR"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#@markdown ### **Run 3.** Basic settings\n",
        "\n",
        "width = 512 #@param{type: 'integer'}\n",
        "height = 256 #@param{type: 'integer'}\n",
        "\n",
        "clamp_index = [2.1, 2.1] #@param{type: 'raw'}\n",
        "\n",
        "latent_diffusion_guidance_scale = 12 #@param {type:\"number\"}\n",
        "clip_guidance_scale = 50000 #@param{type: 'integer'}\n",
        "\n",
        "how_many_batches = 1 #@param{type: 'integer'}\n",
        "\n",
        "aesthetic_loss_scale = 200 #@param{type: 'integer'}\n",
        "augment_cuts = True #@param{type:'boolean'}\n",
        "\n",
        "\n",
        "#@markdown ### Custom saved settings\n",
        "#@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "custom_settings = '' #@param{type:'string'}\n",
        "settings_library = 'None (use settings defined above)' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "if(settings_library != 'None (use settings defined above)'):\n",
        "  custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "global_var_scope = globals()\n",
        "if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "  print('Loaded ', custom_settings)\n",
        "  try:\n",
        "    from configparser import ConfigParser\n",
        "  except ImportError:\n",
        "      from ConfigParser import ConfigParser\n",
        "  import configparser\n",
        "  \n",
        "  config = ConfigParser()\n",
        "  config.read(custom_settings)\n",
        "  #custom_settings_stream = fetch(custom_settings)\n",
        "  #Load CLIP models from config\n",
        "  if(config.has_section('clip_list')):\n",
        "    clip_incoming_list = config.items('clip_list')\n",
        "    clip_incoming_models = clip_incoming_list[0]\n",
        "    incoming_perceptors = eval(clip_incoming_models[1])\n",
        "    if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "      clip_load_list = incoming_perceptors\n",
        "      clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "  #Load settings from config and replace variables\n",
        "  if(config.has_section('basic_settings')):\n",
        "    basic_settings = config.items('basic_settings')\n",
        "    for basic_setting in basic_settings:\n",
        "      global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "  \n",
        "  if(config.has_section('advanced_settings')):\n",
        "    advanced_settings = config.items('advanced_settings')\n",
        "    for advanced_setting in advanced_settings:\n",
        "      global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "  custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "prompts = clip_prompts\n",
        "opt.prompt = latent_prompts\n",
        "opt.uc = latent_negatives\n",
        "custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "aes_scale = aesthetic_loss_scale\n",
        "try: \n",
        "  clip_guidance_schedule\n",
        "  clip_guidance_index = clip_guidance_schedule\n",
        "except:\n",
        "  clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "opt.W = (width//64)*64;\n",
        "opt.H = (height//64)*64;\n",
        "if opt.W != width or opt.H != height:\n",
        "    print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "opt.mag_mul = opt_mag_mul \n",
        "opt.ddim_eta = opt_ddim_eta\n",
        "opt.eta_end = opt_eta_end\n",
        "opt.temperature = opt_temperature\n",
        "opt.n_iter = how_many_batches\n",
        "opt.n_samples =  1\n",
        "opt.scale = latent_diffusion_guidance_scale\n",
        "opt.plms = opt_plms\n",
        "aug = augment_cuts\n",
        "\n",
        "#Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "if(len(clamp_index) == 2): \n",
        "  clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "else:\n",
        "  clamp_index_variation = clamp_index\n",
        "score_corrector = DotMap()\n",
        "\n",
        "\n",
        "def modify_score(e_t, e_t_uncond):\n",
        "        if(score_modifier is False):\n",
        "          return e_t\n",
        "        else:\n",
        "          e_t_d = (e_t - e_t_uncond)\n",
        "          s = torch.quantile(\n",
        "              rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "              threshold_percentile,\n",
        "              dim = -1\n",
        "          )\n",
        "\n",
        "        s.clamp_(min = 1.)\n",
        "        s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "        if ths_method == \"softsign\":\n",
        "            e_t_d = F.softsign(e_t_d) / s \n",
        "        elif ths_method == \"clamp\":\n",
        "            e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "        e_t = e_t_uncond + e_t_d\n",
        "        return(e_t)\n",
        "          \n",
        "score_corrector.modify_score = modify_score\n",
        "\n",
        "def dynamic_thresholding(pred_x0,t):\n",
        "    return(pred_x0)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "generate_video = False\n",
        "if generate_video: \n",
        "    fps = 24\n",
        "    p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "do_run()\n",
        "if generate_video: \n",
        "    p.stdin.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "-wUNPG8Db2sR"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#@markdown ### **Run 4.** Basic settings\n",
        "\n",
        "width = 256 #@param{type: 'integer'}\n",
        "height = 512 #@param{type: 'integer'}\n",
        "\n",
        "clamp_index = [1.5, 2.0] #@param{type: 'raw'}\n",
        "\n",
        "latent_diffusion_guidance_scale = 6 #@param {type:\"number\"}\n",
        "clip_guidance_scale = 36000 #@param{type: 'integer'}\n",
        "\n",
        "how_many_batches = 1 #@param{type: 'integer'}\n",
        "aesthetic_loss_scale = 100 #@param{type: 'integer'}\n",
        "augment_cuts = True #@param{type:'boolean'}\n",
        "\n",
        "\n",
        "#@markdown\n",
        "\n",
        "#@markdown ### Custom saved settings\n",
        "#@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "custom_settings = '' #@param{type:'string'}\n",
        "settings_library = 'None (use settings defined above)' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "if(settings_library != 'None (use settings defined above)'):\n",
        "  custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "global_var_scope = globals()\n",
        "if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "  print('Loaded ', custom_settings)\n",
        "  try:\n",
        "    from configparser import ConfigParser\n",
        "  except ImportError:\n",
        "      from ConfigParser import ConfigParser\n",
        "  import configparser\n",
        "  \n",
        "  config = ConfigParser()\n",
        "  config.read(custom_settings)\n",
        "  #custom_settings_stream = fetch(custom_settings)\n",
        "  #Load CLIP models from config\n",
        "  if(config.has_section('clip_list')):\n",
        "    clip_incoming_list = config.items('clip_list')\n",
        "    clip_incoming_models = clip_incoming_list[0]\n",
        "    incoming_perceptors = eval(clip_incoming_models[1])\n",
        "    if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "      clip_load_list = incoming_perceptors\n",
        "      clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "  #Load settings from config and replace variables\n",
        "  if(config.has_section('basic_settings')):\n",
        "    basic_settings = config.items('basic_settings')\n",
        "    for basic_setting in basic_settings:\n",
        "      global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "  \n",
        "  if(config.has_section('advanced_settings')):\n",
        "    advanced_settings = config.items('advanced_settings')\n",
        "    for advanced_setting in advanced_settings:\n",
        "      global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "  custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "prompts = clip_prompts\n",
        "opt.prompt = latent_prompts\n",
        "opt.uc = latent_negatives\n",
        "custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "aes_scale = aesthetic_loss_scale\n",
        "try: \n",
        "  clip_guidance_schedule\n",
        "  clip_guidance_index = clip_guidance_schedule\n",
        "except:\n",
        "  clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "opt.W = (width//64)*64;\n",
        "opt.H = (height//64)*64;\n",
        "if opt.W != width or opt.H != height:\n",
        "    print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "opt.mag_mul = opt_mag_mul \n",
        "opt.ddim_eta = opt_ddim_eta\n",
        "opt.eta_end = opt_eta_end\n",
        "opt.temperature = opt_temperature\n",
        "opt.n_iter = how_many_batches\n",
        "opt.n_samples =  1\n",
        "opt.scale = latent_diffusion_guidance_scale\n",
        "opt.plms = opt_plms\n",
        "aug = augment_cuts\n",
        "\n",
        "#Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "if(len(clamp_index) == 2): \n",
        "  clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "else:\n",
        "  clamp_index_variation = clamp_index\n",
        "score_corrector = DotMap()\n",
        "\n",
        "\n",
        "def modify_score(e_t, e_t_uncond):\n",
        "        if(score_modifier is False):\n",
        "          return e_t\n",
        "        else:\n",
        "          e_t_d = (e_t - e_t_uncond)\n",
        "          s = torch.quantile(\n",
        "              rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "              threshold_percentile,\n",
        "              dim = -1\n",
        "          )\n",
        "\n",
        "        s.clamp_(min = 1.)\n",
        "        s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "        if ths_method == \"softsign\":\n",
        "            e_t_d = F.softsign(e_t_d) / s \n",
        "        elif ths_method == \"clamp\":\n",
        "            e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "        e_t = e_t_uncond + e_t_d\n",
        "        return(e_t)\n",
        "          \n",
        "score_corrector.modify_score = modify_score\n",
        "\n",
        "def dynamic_thresholding(pred_x0,t):\n",
        "    return(pred_x0)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "generate_video = False\n",
        "if generate_video: \n",
        "    fps = 24\n",
        "    p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "do_run()\n",
        "if generate_video: \n",
        "    p.stdin.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "JfLd09uYb2sS"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#@markdown ### **Run 5.** Basic settings\n",
        "\n",
        "#@markdown We're still figuring out default settings. Experiment and <a href=\"https://huggingface.co/datasets/multimodalart/latent-majesty-diffusion-settings\">share your settings with us</a>.\n",
        "\n",
        "width = 512 #@param{type: 'integer'}\n",
        "height = 256 #@param{type: 'integer'}\n",
        "\n",
        "clamp_index = [2.1, 2.4] #@param{type: 'raw'}\n",
        "\n",
        "latent_diffusion_guidance_scale = 9 #@param {type:\"number\"}\n",
        "clip_guidance_scale = 16000 #@param{type: 'integer'}\n",
        "\n",
        "how_many_batches = 1#@param{type: 'integer'}\n",
        "aesthetic_loss_scale = 100 #@param{type: 'integer'}\n",
        "augment_cuts = True #@param{type:'boolean'}\n",
        "\n",
        "\n",
        "#@markdown\n",
        "\n",
        "#@markdown ### Custom saved settings\n",
        "#@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "custom_settings = '' #@param{type:'string'}\n",
        "settings_library = 'default' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "if(settings_library != 'None (use settings defined above)'):\n",
        "  custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "global_var_scope = globals()\n",
        "if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "  print('Loaded ', custom_settings)\n",
        "  try:\n",
        "    from configparser import ConfigParser\n",
        "  except ImportError:\n",
        "      from ConfigParser import ConfigParser\n",
        "  import configparser\n",
        "  \n",
        "  config = ConfigParser()\n",
        "  config.read(custom_settings)\n",
        "  #custom_settings_stream = fetch(custom_settings)\n",
        "  #Load CLIP models from config\n",
        "  if(config.has_section('clip_list')):\n",
        "    clip_incoming_list = config.items('clip_list')\n",
        "    clip_incoming_models = clip_incoming_list[0]\n",
        "    incoming_perceptors = eval(clip_incoming_models[1])\n",
        "    if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "      clip_load_list = incoming_perceptors\n",
        "      clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "  #Load settings from config and replace variables\n",
        "  if(config.has_section('basic_settings')):\n",
        "    basic_settings = config.items('basic_settings')\n",
        "    for basic_setting in basic_settings:\n",
        "      global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "  \n",
        "  if(config.has_section('advanced_settings')):\n",
        "    advanced_settings = config.items('advanced_settings')\n",
        "    for advanced_setting in advanced_settings:\n",
        "      global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "  custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "prompts = clip_prompts\n",
        "opt.prompt = latent_prompts\n",
        "opt.uc = latent_negatives\n",
        "custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "aes_scale = aesthetic_loss_scale\n",
        "try: \n",
        "  clip_guidance_schedule\n",
        "  clip_guidance_index = clip_guidance_schedule\n",
        "except:\n",
        "  clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "opt.W = (width//64)*64;\n",
        "opt.H = (height//64)*64;\n",
        "if opt.W != width or opt.H != height:\n",
        "    print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "opt.mag_mul = opt_mag_mul \n",
        "opt.ddim_eta = opt_ddim_eta\n",
        "opt.eta_end = opt_eta_end\n",
        "opt.temperature = opt_temperature\n",
        "opt.n_iter = how_many_batches\n",
        "opt.n_samples =  1\n",
        "opt.scale = latent_diffusion_guidance_scale\n",
        "opt.plms = opt_plms\n",
        "aug = augment_cuts\n",
        "\n",
        "#Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "if(len(clamp_index) == 2): \n",
        "  clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "else:\n",
        "  clamp_index_variation = clamp_index\n",
        "score_corrector = DotMap()\n",
        "\n",
        "\n",
        "def modify_score(e_t, e_t_uncond):\n",
        "        if(score_modifier is False):\n",
        "          return e_t\n",
        "        else:\n",
        "          e_t_d = (e_t - e_t_uncond)\n",
        "          s = torch.quantile(\n",
        "              rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "              threshold_percentile,\n",
        "              dim = -1\n",
        "          )\n",
        "\n",
        "        s.clamp_(min = 1.)\n",
        "        s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "        if ths_method == \"softsign\":\n",
        "            e_t_d = F.softsign(e_t_d) / s \n",
        "        elif ths_method == \"clamp\":\n",
        "            e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "        e_t = e_t_uncond + e_t_d\n",
        "        return(e_t)\n",
        "          \n",
        "score_corrector.modify_score = modify_score\n",
        "\n",
        "def dynamic_thresholding(pred_x0,t):\n",
        "    return(pred_x0)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "generate_video = False\n",
        "if generate_video: \n",
        "    fps = 24\n",
        "    p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "do_run()\n",
        "if generate_video: \n",
        "    p.stdin.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "6uq3-MuOb2sS"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#@markdown ### **Run 6.** Basic Settings\n",
        "\n",
        "width = 256 #@param{type: 'integer'}\n",
        "height = 384 #@param{type: 'integer'}\n",
        "\n",
        "clamp_index = [2.4, 2.1] #@param{type: 'raw'}\n",
        "\n",
        "latent_diffusion_guidance_scale = 15 #@param {type:\"number\"}\n",
        "clip_guidance_scale = 20000 #@param{type: 'integer'}\n",
        "\n",
        "how_many_batches = 1 #@param{type: 'integer'}\n",
        "aesthetic_loss_scale = 100 #@param{type: 'integer'}\n",
        "augment_cuts = True #@param{type:'boolean'}\n",
        "\n",
        "\n",
        "#@markdown\n",
        "\n",
        "#@markdown ### Custom saved settings\n",
        "#@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "custom_settings = '' #@param{type:'string'}\n",
        "settings_library = 'default' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "if(settings_library != 'None (use settings defined above)'):\n",
        "  custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "global_var_scope = globals()\n",
        "if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "  print('Loaded ', custom_settings)\n",
        "  try:\n",
        "    from configparser import ConfigParser\n",
        "  except ImportError:\n",
        "      from ConfigParser import ConfigParser\n",
        "  import configparser\n",
        "  \n",
        "  config = ConfigParser()\n",
        "  config.read(custom_settings)\n",
        "  #custom_settings_stream = fetch(custom_settings)\n",
        "  #Load CLIP models from config\n",
        "  if(config.has_section('clip_list')):\n",
        "    clip_incoming_list = config.items('clip_list')\n",
        "    clip_incoming_models = clip_incoming_list[0]\n",
        "    incoming_perceptors = eval(clip_incoming_models[1])\n",
        "    if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "      clip_load_list = incoming_perceptors\n",
        "      clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "  #Load settings from config and replace variables\n",
        "  if(config.has_section('basic_settings')):\n",
        "    basic_settings = config.items('basic_settings')\n",
        "    for basic_setting in basic_settings:\n",
        "      global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "  \n",
        "  if(config.has_section('advanced_settings')):\n",
        "    advanced_settings = config.items('advanced_settings')\n",
        "    for advanced_setting in advanced_settings:\n",
        "      global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "  custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "prompts = clip_prompts\n",
        "opt.prompt = latent_prompts\n",
        "opt.uc = latent_negatives\n",
        "custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "aes_scale = aesthetic_loss_scale\n",
        "try: \n",
        "  clip_guidance_schedule\n",
        "  clip_guidance_index = clip_guidance_schedule\n",
        "except:\n",
        "  clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "opt.W = (width//64)*64;\n",
        "opt.H = (height//64)*64;\n",
        "if opt.W != width or opt.H != height:\n",
        "    print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "opt.mag_mul = opt_mag_mul \n",
        "opt.ddim_eta = opt_ddim_eta\n",
        "opt.eta_end = opt_eta_end\n",
        "opt.temperature = opt_temperature\n",
        "opt.n_iter = how_many_batches\n",
        "opt.n_samples =  1\n",
        "opt.scale = latent_diffusion_guidance_scale\n",
        "opt.plms = opt_plms\n",
        "aug = augment_cuts\n",
        "\n",
        "#Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "if(len(clamp_index) == 2): \n",
        "  clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "else:\n",
        "  clamp_index_variation = clamp_index\n",
        "score_corrector = DotMap()\n",
        "\n",
        "\n",
        "def modify_score(e_t, e_t_uncond):\n",
        "        if(score_modifier is False):\n",
        "          return e_t\n",
        "        else:\n",
        "          e_t_d = (e_t - e_t_uncond)\n",
        "          s = torch.quantile(\n",
        "              rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "              threshold_percentile,\n",
        "              dim = -1\n",
        "          )\n",
        "\n",
        "        s.clamp_(min = 1.)\n",
        "        s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "        if ths_method == \"softsign\":\n",
        "            e_t_d = F.softsign(e_t_d) / s \n",
        "        elif ths_method == \"clamp\":\n",
        "            e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "        e_t = e_t_uncond + e_t_d\n",
        "        return(e_t)\n",
        "          \n",
        "score_corrector.modify_score = modify_score\n",
        "\n",
        "def dynamic_thresholding(pred_x0,t):\n",
        "    return(pred_x0)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "generate_video = False\n",
        "if generate_video: \n",
        "    fps = 24\n",
        "    p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "do_run()\n",
        "if generate_video: \n",
        "    p.stdin.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "OjxCmMPdb2sS"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#@markdown ### **Run 7.** Basic Settings\n",
        "\n",
        "width = 384 #@param{type: 'integer'}\n",
        "height = 384 #@param{type: 'integer'}\n",
        "\n",
        "clamp_index = [0.6, 0.6] #@param{type: 'raw'}\n",
        "\n",
        "latent_diffusion_guidance_scale = 11 #@param {type:\"number\"}\n",
        "clip_guidance_scale = 39999 #@param{type: 'integer'}\n",
        "\n",
        "how_many_batches = 1 #@param{type: 'integer'}\n",
        "aesthetic_loss_scale = 100 #@param{type: 'integer'}\n",
        "augment_cuts = True #@param{type:'boolean'}\n",
        "\n",
        "\n",
        "#@markdown ### Custom saved settings\n",
        "#@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "custom_settings = '' #@param{type:'string'}\n",
        "settings_library = 'coherent_pizzapigeon' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "if(settings_library != 'None (use settings defined above)'):\n",
        "  custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "global_var_scope = globals()\n",
        "if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "  print('Loaded ', custom_settings)\n",
        "  try:\n",
        "    from configparser import ConfigParser\n",
        "  except ImportError:\n",
        "      from ConfigParser import ConfigParser\n",
        "  import configparser\n",
        "  \n",
        "  config = ConfigParser()\n",
        "  config.read(custom_settings)\n",
        "  #custom_settings_stream = fetch(custom_settings)\n",
        "  #Load CLIP models from config\n",
        "  if(config.has_section('clip_list')):\n",
        "    clip_incoming_list = config.items('clip_list')\n",
        "    clip_incoming_models = clip_incoming_list[0]\n",
        "    incoming_perceptors = eval(clip_incoming_models[1])\n",
        "    if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "      clip_load_list = incoming_perceptors\n",
        "      clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "  #Load settings from config and replace variables\n",
        "  if(config.has_section('basic_settings')):\n",
        "    basic_settings = config.items('basic_settings')\n",
        "    for basic_setting in basic_settings:\n",
        "      global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "  \n",
        "  if(config.has_section('advanced_settings')):\n",
        "    advanced_settings = config.items('advanced_settings')\n",
        "    for advanced_setting in advanced_settings:\n",
        "      global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "  custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "prompts = clip_prompts\n",
        "opt.prompt = latent_prompts\n",
        "opt.uc = latent_negatives\n",
        "custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "aes_scale = aesthetic_loss_scale\n",
        "try: \n",
        "  clip_guidance_schedule\n",
        "  clip_guidance_index = clip_guidance_schedule\n",
        "except:\n",
        "  clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "opt.W = (width//64)*64;\n",
        "opt.H = (height//64)*64;\n",
        "if opt.W != width or opt.H != height:\n",
        "    print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "opt.mag_mul = opt_mag_mul \n",
        "opt.ddim_eta = opt_ddim_eta\n",
        "opt.eta_end = opt_eta_end\n",
        "opt.temperature = opt_temperature\n",
        "opt.n_iter = how_many_batches\n",
        "opt.n_samples =  1\n",
        "opt.scale = latent_diffusion_guidance_scale\n",
        "opt.plms = opt_plms\n",
        "aug = augment_cuts\n",
        "\n",
        "#Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "if(len(clamp_index) == 2): \n",
        "  clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "else:\n",
        "  clamp_index_variation = clamp_index\n",
        "score_corrector = DotMap()\n",
        "\n",
        "\n",
        "def modify_score(e_t, e_t_uncond):\n",
        "        if(score_modifier is False):\n",
        "          return e_t\n",
        "        else:\n",
        "          e_t_d = (e_t - e_t_uncond)\n",
        "          s = torch.quantile(\n",
        "              rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "              threshold_percentile,\n",
        "              dim = -1\n",
        "          )\n",
        "\n",
        "        s.clamp_(min = 1.)\n",
        "        s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "        if ths_method == \"softsign\":\n",
        "            e_t_d = F.softsign(e_t_d) / s \n",
        "        elif ths_method == \"clamp\":\n",
        "            e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "        e_t = e_t_uncond + e_t_d\n",
        "        return(e_t)\n",
        "          \n",
        "score_corrector.modify_score = modify_score\n",
        "\n",
        "def dynamic_thresholding(pred_x0,t):\n",
        "    return(pred_x0)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "generate_video = False\n",
        "if generate_video: \n",
        "    fps = 24\n",
        "    p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "do_run()\n",
        "if generate_video: \n",
        "    p.stdin.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "qBsEzGaJb2sT"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#@markdown ### **Run 8.** Basic Settings\n",
        "\n",
        "width =  256#@param{type: 'integer'}\n",
        "height =  384#@param{type: 'integer'}\n",
        "\n",
        "clamp_index = [1, 1] #@param{type: 'raw'}\n",
        "\n",
        "latent_diffusion_guidance_scale = 10 #@param {type:\"number\"}\n",
        "clip_guidance_scale =  50000#@param{type: 'integer'}\n",
        "\n",
        "how_many_batches =  1#@param{type: 'integer'}\n",
        "\n",
        "aesthetic_loss_scale = 100 #@param{type: 'integer'}\n",
        "augment_cuts=True #@param{type:'boolean'}\n",
        "\n",
        "\n",
        "#@markdown ### Custom saved settings\n",
        "#@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "custom_settings = '' #@param{type:'string'}\n",
        "settings_library = 'coherent_pizzapigeon' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "if(settings_library != 'None (use settings defined above)'):\n",
        "  custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "global_var_scope = globals()\n",
        "if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "  print('Loaded ', custom_settings)\n",
        "  try:\n",
        "    from configparser import ConfigParser\n",
        "  except ImportError:\n",
        "      from ConfigParser import ConfigParser\n",
        "  import configparser\n",
        "  \n",
        "  config = ConfigParser()\n",
        "  config.read(custom_settings)\n",
        "  #custom_settings_stream = fetch(custom_settings)\n",
        "  #Load CLIP models from config\n",
        "  if(config.has_section('clip_list')):\n",
        "    clip_incoming_list = config.items('clip_list')\n",
        "    clip_incoming_models = clip_incoming_list[0]\n",
        "    incoming_perceptors = eval(clip_incoming_models[1])\n",
        "    if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "      clip_load_list = incoming_perceptors\n",
        "      clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "  #Load settings from config and replace variables\n",
        "  if(config.has_section('basic_settings')):\n",
        "    basic_settings = config.items('basic_settings')\n",
        "    for basic_setting in basic_settings:\n",
        "      global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "  \n",
        "  if(config.has_section('advanced_settings')):\n",
        "    advanced_settings = config.items('advanced_settings')\n",
        "    for advanced_setting in advanced_settings:\n",
        "      global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "  custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "prompts = clip_prompts\n",
        "opt.prompt = latent_prompts\n",
        "opt.uc = latent_negatives\n",
        "custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "aes_scale = aesthetic_loss_scale\n",
        "try: \n",
        "  clip_guidance_schedule\n",
        "  clip_guidance_index = clip_guidance_schedule\n",
        "except:\n",
        "  clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "opt.W = (width//64)*64;\n",
        "opt.H = (height//64)*64;\n",
        "if opt.W != width or opt.H != height:\n",
        "    print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "opt.mag_mul = opt_mag_mul \n",
        "opt.ddim_eta = opt_ddim_eta\n",
        "opt.eta_end = opt_eta_end\n",
        "opt.temperature = opt_temperature\n",
        "opt.n_iter = how_many_batches\n",
        "opt.n_samples =  1\n",
        "opt.scale = latent_diffusion_guidance_scale\n",
        "opt.plms = opt_plms\n",
        "aug = augment_cuts\n",
        "\n",
        "#Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "if(len(clamp_index) == 2): \n",
        "  clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "else:\n",
        "  clamp_index_variation = clamp_index\n",
        "score_corrector = DotMap()\n",
        "\n",
        "\n",
        "def modify_score(e_t, e_t_uncond):\n",
        "        if(score_modifier is False):\n",
        "          return e_t\n",
        "        else:\n",
        "          e_t_d = (e_t - e_t_uncond)\n",
        "          s = torch.quantile(\n",
        "              rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "              threshold_percentile,\n",
        "              dim = -1\n",
        "          )\n",
        "\n",
        "        s.clamp_(min = 1.)\n",
        "        s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "        if ths_method == \"softsign\":\n",
        "            e_t_d = F.softsign(e_t_d) / s \n",
        "        elif ths_method == \"clamp\":\n",
        "            e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "        e_t = e_t_uncond + e_t_d\n",
        "        return(e_t)\n",
        "          \n",
        "score_corrector.modify_score = modify_score\n",
        "\n",
        "def dynamic_thresholding(pred_x0,t):\n",
        "    return(pred_x0)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "generate_video = False\n",
        "if generate_video: \n",
        "    fps = 24\n",
        "    p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "do_run()\n",
        "if generate_video: \n",
        "    p.stdin.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "sCwZtrkOb2sT"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#@markdown ### **Run 9.** Basic Settings\n",
        "\n",
        "width = 384 #@param{type: 'integer'}\n",
        "height = 256 #@param{type: 'integer'}\n",
        "\n",
        "clamp_index = [1, 1] #@param{type: 'raw'}\n",
        "\n",
        "latent_diffusion_guidance_scale = 13 #@param {type:\"number\"}\n",
        "clip_guidance_scale = 24000 #@param{type: 'integer'}\n",
        "\n",
        "how_many_batches =  1#@param{type: 'integer'}\n",
        "aesthetic_loss_scale =  1#@param{type: 'integer'}\n",
        "augment_cuts = True #@param{type:'boolean'}\n",
        "\n",
        "\n",
        "#@markdown ### Custom saved settings\n",
        "#@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "custom_settings = '' #@param{type:'string'}\n",
        "settings_library = 'makeitrad_defaults' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "if(settings_library != 'None (use settings defined above)'):\n",
        "  custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "global_var_scope = globals()\n",
        "if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "  print('Loaded ', custom_settings)\n",
        "  try:\n",
        "    from configparser import ConfigParser\n",
        "  except ImportError:\n",
        "      from ConfigParser import ConfigParser\n",
        "  import configparser\n",
        "  \n",
        "  config = ConfigParser()\n",
        "  config.read(custom_settings)\n",
        "  #custom_settings_stream = fetch(custom_settings)\n",
        "  #Load CLIP models from config\n",
        "  if(config.has_section('clip_list')):\n",
        "    clip_incoming_list = config.items('clip_list')\n",
        "    clip_incoming_models = clip_incoming_list[0]\n",
        "    incoming_perceptors = eval(clip_incoming_models[1])\n",
        "    if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "      clip_load_list = incoming_perceptors\n",
        "      clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "  #Load settings from config and replace variables\n",
        "  if(config.has_section('basic_settings')):\n",
        "    basic_settings = config.items('basic_settings')\n",
        "    for basic_setting in basic_settings:\n",
        "      global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "  \n",
        "  if(config.has_section('advanced_settings')):\n",
        "    advanced_settings = config.items('advanced_settings')\n",
        "    for advanced_setting in advanced_settings:\n",
        "      global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "  custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "prompts = clip_prompts\n",
        "opt.prompt = latent_prompts\n",
        "opt.uc = latent_negatives\n",
        "custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "aes_scale = aesthetic_loss_scale\n",
        "try: \n",
        "  clip_guidance_schedule\n",
        "  clip_guidance_index = clip_guidance_schedule\n",
        "except:\n",
        "  clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "opt.W = (width//64)*64;\n",
        "opt.H = (height//64)*64;\n",
        "if opt.W != width or opt.H != height:\n",
        "    print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "opt.mag_mul = opt_mag_mul \n",
        "opt.ddim_eta = opt_ddim_eta\n",
        "opt.eta_end = opt_eta_end\n",
        "opt.temperature = opt_temperature\n",
        "opt.n_iter = how_many_batches\n",
        "opt.n_samples =  1\n",
        "opt.scale = latent_diffusion_guidance_scale\n",
        "opt.plms = opt_plms\n",
        "aug = augment_cuts\n",
        "\n",
        "#Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "if(len(clamp_index) == 2): \n",
        "  clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "else:\n",
        "  clamp_index_variation = clamp_index\n",
        "score_corrector = DotMap()\n",
        "\n",
        "\n",
        "def modify_score(e_t, e_t_uncond):\n",
        "        if(score_modifier is False):\n",
        "          return e_t\n",
        "        else:\n",
        "          e_t_d = (e_t - e_t_uncond)\n",
        "          s = torch.quantile(\n",
        "              rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "              threshold_percentile,\n",
        "              dim = -1\n",
        "          )\n",
        "\n",
        "        s.clamp_(min = 1.)\n",
        "        s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "        if ths_method == \"softsign\":\n",
        "            e_t_d = F.softsign(e_t_d) / s \n",
        "        elif ths_method == \"clamp\":\n",
        "            e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "        e_t = e_t_uncond + e_t_d\n",
        "        return(e_t)\n",
        "          \n",
        "score_corrector.modify_score = modify_score\n",
        "\n",
        "def dynamic_thresholding(pred_x0,t):\n",
        "    return(pred_x0)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "generate_video = False\n",
        "if generate_video: \n",
        "    fps = 24\n",
        "    p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "do_run()\n",
        "if generate_video: \n",
        "    p.stdin.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "bijX-zAQb2sU"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#@markdown ### **Run 10.** Basic Settings\n",
        "\n",
        "width = 256 #@param{type: 'integer'}\n",
        "height = 384 #@param{type: 'integer'}\n",
        "\n",
        "clamp_index = [1, 1] #@param{type: 'raw'}\n",
        "\n",
        "latent_diffusion_guidance_scale = 14 #@param {type:\"number\"}\n",
        "clip_guidance_scale = 8000 #@param{type: 'integer'}\n",
        "\n",
        "how_many_batches = 1 #@param{type: 'integer'}\n",
        "aesthetic_loss_scale = 10 #@param{type: 'integer'}\n",
        "augment_cuts = True #@param{type:'boolean'}\n",
        "\n",
        "\n",
        "#@markdown ### Custom saved settings\n",
        "#@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "custom_settings = '' #@param{type:'string'}\n",
        "settings_library = 'makeitrad_defaults' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "if(settings_library != 'None (use settings defined above)'):\n",
        "  custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "global_var_scope = globals()\n",
        "if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "  print('Loaded ', custom_settings)\n",
        "  try:\n",
        "    from configparser import ConfigParser\n",
        "  except ImportError:\n",
        "      from ConfigParser import ConfigParser\n",
        "  import configparser\n",
        "  \n",
        "  config = ConfigParser()\n",
        "  config.read(custom_settings)\n",
        "  #custom_settings_stream = fetch(custom_settings)\n",
        "  #Load CLIP models from config\n",
        "  if(config.has_section('clip_list')):\n",
        "    clip_incoming_list = config.items('clip_list')\n",
        "    clip_incoming_models = clip_incoming_list[0]\n",
        "    incoming_perceptors = eval(clip_incoming_models[1])\n",
        "    if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "      clip_load_list = incoming_perceptors\n",
        "      clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "  #Load settings from config and replace variables\n",
        "  if(config.has_section('basic_settings')):\n",
        "    basic_settings = config.items('basic_settings')\n",
        "    for basic_setting in basic_settings:\n",
        "      global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "  \n",
        "  if(config.has_section('advanced_settings')):\n",
        "    advanced_settings = config.items('advanced_settings')\n",
        "    for advanced_setting in advanced_settings:\n",
        "      global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "  custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "prompts = clip_prompts\n",
        "opt.prompt = latent_prompts\n",
        "opt.uc = latent_negatives\n",
        "custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "aes_scale = aesthetic_loss_scale\n",
        "try: \n",
        "  clip_guidance_schedule\n",
        "  clip_guidance_index = clip_guidance_schedule\n",
        "except:\n",
        "  clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "opt.W = (width//64)*64;\n",
        "opt.H = (height//64)*64;\n",
        "if opt.W != width or opt.H != height:\n",
        "    print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "opt.mag_mul = opt_mag_mul \n",
        "opt.ddim_eta = opt_ddim_eta\n",
        "opt.eta_end = opt_eta_end\n",
        "opt.temperature = opt_temperature\n",
        "opt.n_iter = how_many_batches\n",
        "opt.n_samples =  1\n",
        "opt.scale = latent_diffusion_guidance_scale\n",
        "opt.plms = opt_plms\n",
        "aug = augment_cuts\n",
        "\n",
        "#Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "if(len(clamp_index) == 2): \n",
        "  clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "else:\n",
        "  clamp_index_variation = clamp_index\n",
        "score_corrector = DotMap()\n",
        "\n",
        "\n",
        "def modify_score(e_t, e_t_uncond):\n",
        "        if(score_modifier is False):\n",
        "          return e_t\n",
        "        else:\n",
        "          e_t_d = (e_t - e_t_uncond)\n",
        "          s = torch.quantile(\n",
        "              rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "              threshold_percentile,\n",
        "              dim = -1\n",
        "          )\n",
        "\n",
        "        s.clamp_(min = 1.)\n",
        "        s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "        if ths_method == \"softsign\":\n",
        "            e_t_d = F.softsign(e_t_d) / s \n",
        "        elif ths_method == \"clamp\":\n",
        "            e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "        e_t = e_t_uncond + e_t_d\n",
        "        return(e_t)\n",
        "          \n",
        "score_corrector.modify_score = modify_score\n",
        "\n",
        "def dynamic_thresholding(pred_x0,t):\n",
        "    return(pred_x0)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "generate_video = False\n",
        "if generate_video: \n",
        "    fps = 24\n",
        "    p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "do_run()\n",
        "if generate_video: \n",
        "    p.stdin.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwaBYdaVb3A2"
      },
      "source": [
        "### 𝗗ᴇᴋᴀ-𝗕ᴀᴛᴄʜ 𝗥ᴜɴ 𝗖ᴇʟʟ𝘀 **X3** - Steam"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "init_image = \"https://i.imgur.com/KSnK8Mk.png\" #@param{type: 'string'}\n",
        "if(init_image == '' or init_image == 'None'):\n",
        "  init_image = None\n",
        "\n",
        "#default 0.9\n",
        "starting_timestep = 0.0 #@param{type: 'number'}\n",
        "\n",
        "init_mask = None #@param{type: 'string'}\n",
        "\n",
        "init_scale = 1000 #@param{type: 'integer'}\n",
        "\n",
        "#default 0.0\n",
        "init_brightness = 0.0 #@param{type: 'number'}\n",
        "\n",
        "#default 0.57\n",
        "init_noise = 0.0 #@param{type: 'number'}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ceV2gYeMb3A3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "sseB1Jytb3A3"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#@markdown ### **Run 1.** Basic settings\n",
        "\n",
        "#@markdown We're still figuring out default settings. Experiment and <a href=\"https://huggingface.co/datasets/multimodalart/latent-majesty-diffusion-settings\">share your settings with us</a>.\n",
        "\n",
        "#@markdown ✦✦ TO DO: Add init image cut schedule toggle, init and config skip toggles. ✦✦\n",
        "\n",
        "width = 256 #@param{type: 'integer'}\n",
        "height = 384 #@param{type: 'integer'}\n",
        "\n",
        "clamp_index = [2.4, 2.1] #@param{type: 'raw'}\n",
        "\n",
        "latent_diffusion_guidance_scale = 12 #@param {type:\"number\"}\n",
        "clip_guidance_scale = 12000 #@param{type: 'integer'}\n",
        "\n",
        "how_many_batches = 1 #@param{type: 'integer'}\n",
        "\n",
        "aesthetic_loss_scale = 100 #@param{type: 'integer'}\n",
        "augment_cuts = True #@param{type:'boolean'}\n",
        "\n",
        "\n",
        "#@markdown ### Custom saved settings\n",
        "#@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "custom_settings = '' #@param{type:'string'}\n",
        "settings_library = 'None (use settings defined above)' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "if(settings_library != 'None (use settings defined above)'):\n",
        "  custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "global_var_scope = globals()\n",
        "if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "  print('Loaded ', custom_settings)\n",
        "  try:\n",
        "    from configparser import ConfigParser\n",
        "  except ImportError:\n",
        "      from ConfigParser import ConfigParser\n",
        "  import configparser\n",
        "  \n",
        "  config = ConfigParser()\n",
        "  config.read(custom_settings)\n",
        "  #custom_settings_stream = fetch(custom_settings)\n",
        "  #Load CLIP models from config\n",
        "  if(config.has_section('clip_list')):\n",
        "    clip_incoming_list = config.items('clip_list')\n",
        "    clip_incoming_models = clip_incoming_list[0]\n",
        "    incoming_perceptors = eval(clip_incoming_models[1])\n",
        "    if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "      clip_load_list = incoming_perceptors\n",
        "      clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "  #Load settings from config and replace variables\n",
        "  if(config.has_section('basic_settings')):\n",
        "    basic_settings = config.items('basic_settings')\n",
        "    for basic_setting in basic_settings:\n",
        "      global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "  \n",
        "  if(config.has_section('advanced_settings')):\n",
        "    advanced_settings = config.items('advanced_settings')\n",
        "    for advanced_setting in advanced_settings:\n",
        "      global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "  custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "prompts = clip_prompts\n",
        "opt.prompt = latent_prompts\n",
        "opt.uc = latent_negatives\n",
        "custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "aes_scale = aesthetic_loss_scale\n",
        "try: \n",
        "  clip_guidance_schedule\n",
        "  clip_guidance_index = clip_guidance_schedule\n",
        "except:\n",
        "  clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "opt.W = (width//64)*64;\n",
        "opt.H = (height//64)*64;\n",
        "if opt.W != width or opt.H != height:\n",
        "    print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "opt.mag_mul = opt_mag_mul \n",
        "opt.ddim_eta = opt_ddim_eta\n",
        "opt.eta_end = opt_eta_end\n",
        "opt.temperature = opt_temperature\n",
        "opt.n_iter = how_many_batches\n",
        "opt.n_samples =  1\n",
        "opt.scale = latent_diffusion_guidance_scale\n",
        "opt.plms = opt_plms\n",
        "aug = augment_cuts\n",
        "\n",
        "#Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "if(len(clamp_index) == 2): \n",
        "  clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "else:\n",
        "  clamp_index_variation = clamp_index\n",
        "score_corrector = DotMap()\n",
        "\n",
        "\n",
        "def modify_score(e_t, e_t_uncond):\n",
        "        if(score_modifier is False):\n",
        "          return e_t\n",
        "        else:\n",
        "          e_t_d = (e_t - e_t_uncond)\n",
        "          s = torch.quantile(\n",
        "              rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "              threshold_percentile,\n",
        "              dim = -1\n",
        "          )\n",
        "\n",
        "        s.clamp_(min = 1.)\n",
        "        s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "        if ths_method == \"softsign\":\n",
        "            e_t_d = F.softsign(e_t_d) / s \n",
        "        elif ths_method == \"clamp\":\n",
        "            e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "        e_t = e_t_uncond + e_t_d\n",
        "        return(e_t)\n",
        "          \n",
        "score_corrector.modify_score = modify_score\n",
        "\n",
        "def dynamic_thresholding(pred_x0,t):\n",
        "    return(pred_x0)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "generate_video = False\n",
        "if generate_video: \n",
        "    fps = 24\n",
        "    p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "do_run()\n",
        "if generate_video: \n",
        "    p.stdin.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "PJDZL72fb3A3"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#@markdown ### **Run 2.** Basic settings\n",
        "\n",
        "width = 256 #@param{type: 'integer'}\n",
        "height = 384 #@param{type: 'integer'}\n",
        "\n",
        "clamp_index = [2.1, 2.4] #@param{type: 'raw'}\n",
        "\n",
        "latent_diffusion_guidance_scale = 15 #@param {type:\"number\"}\n",
        "clip_guidance_scale = 50000 #@param{type: 'integer'}\n",
        "\n",
        "how_many_batches = 1 #@param{type: 'integer'}\n",
        "\n",
        "aesthetic_loss_scale = 200 #@param{type: 'integer'}\n",
        "augment_cuts = True #@param{type:'boolean'}\n",
        "\n",
        "\n",
        "#@markdown ### Custom saved settings\n",
        "#@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "custom_settings = '' #@param{type:'string'}\n",
        "settings_library = 'None (use settings defined above)' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "if(settings_library != 'None (use settings defined above)'):\n",
        "  custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "global_var_scope = globals()\n",
        "if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "  print('Loaded ', custom_settings)\n",
        "  try:\n",
        "    from configparser import ConfigParser\n",
        "  except ImportError:\n",
        "      from ConfigParser import ConfigParser\n",
        "  import configparser\n",
        "  \n",
        "  config = ConfigParser()\n",
        "  config.read(custom_settings)\n",
        "  #custom_settings_stream = fetch(custom_settings)\n",
        "  #Load CLIP models from config\n",
        "  if(config.has_section('clip_list')):\n",
        "    clip_incoming_list = config.items('clip_list')\n",
        "    clip_incoming_models = clip_incoming_list[0]\n",
        "    incoming_perceptors = eval(clip_incoming_models[1])\n",
        "    if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "      clip_load_list = incoming_perceptors\n",
        "      clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "  #Load settings from config and replace variables\n",
        "  if(config.has_section('basic_settings')):\n",
        "    basic_settings = config.items('basic_settings')\n",
        "    for basic_setting in basic_settings:\n",
        "      global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "  \n",
        "  if(config.has_section('advanced_settings')):\n",
        "    advanced_settings = config.items('advanced_settings')\n",
        "    for advanced_setting in advanced_settings:\n",
        "      global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "  custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "prompts = clip_prompts\n",
        "opt.prompt = latent_prompts\n",
        "opt.uc = latent_negatives\n",
        "custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "aes_scale = aesthetic_loss_scale\n",
        "try: \n",
        "  clip_guidance_schedule\n",
        "  clip_guidance_index = clip_guidance_schedule\n",
        "except:\n",
        "  clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "opt.W = (width//64)*64;\n",
        "opt.H = (height//64)*64;\n",
        "if opt.W != width or opt.H != height:\n",
        "    print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "opt.mag_mul = opt_mag_mul \n",
        "opt.ddim_eta = opt_ddim_eta\n",
        "opt.eta_end = opt_eta_end\n",
        "opt.temperature = opt_temperature\n",
        "opt.n_iter = how_many_batches\n",
        "opt.n_samples =  1\n",
        "opt.scale = latent_diffusion_guidance_scale\n",
        "opt.plms = opt_plms\n",
        "aug = augment_cuts\n",
        "\n",
        "#Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "if(len(clamp_index) == 2): \n",
        "  clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "else:\n",
        "  clamp_index_variation = clamp_index\n",
        "score_corrector = DotMap()\n",
        "\n",
        "\n",
        "def modify_score(e_t, e_t_uncond):\n",
        "        if(score_modifier is False):\n",
        "          return e_t\n",
        "        else:\n",
        "          e_t_d = (e_t - e_t_uncond)\n",
        "          s = torch.quantile(\n",
        "              rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "              threshold_percentile,\n",
        "              dim = -1\n",
        "          )\n",
        "\n",
        "        s.clamp_(min = 1.)\n",
        "        s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "        if ths_method == \"softsign\":\n",
        "            e_t_d = F.softsign(e_t_d) / s \n",
        "        elif ths_method == \"clamp\":\n",
        "            e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "        e_t = e_t_uncond + e_t_d\n",
        "        return(e_t)\n",
        "          \n",
        "score_corrector.modify_score = modify_score\n",
        "\n",
        "def dynamic_thresholding(pred_x0,t):\n",
        "    return(pred_x0)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "generate_video = False\n",
        "if generate_video: \n",
        "    fps = 24\n",
        "    p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "do_run()\n",
        "if generate_video: \n",
        "    p.stdin.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "vMf7Za3Fb3A4"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#@markdown ### **Run 3.** Basic settings\n",
        "\n",
        "width = 512 #@param{type: 'integer'}\n",
        "height = 256 #@param{type: 'integer'}\n",
        "\n",
        "clamp_index = [2.1, 2.1] #@param{type: 'raw'}\n",
        "\n",
        "latent_diffusion_guidance_scale = 12 #@param {type:\"number\"}\n",
        "clip_guidance_scale = 50000 #@param{type: 'integer'}\n",
        "\n",
        "how_many_batches = 1 #@param{type: 'integer'}\n",
        "\n",
        "aesthetic_loss_scale = 200 #@param{type: 'integer'}\n",
        "augment_cuts = True #@param{type:'boolean'}\n",
        "\n",
        "\n",
        "#@markdown ### Custom saved settings\n",
        "#@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "custom_settings = '' #@param{type:'string'}\n",
        "settings_library = 'None (use settings defined above)' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "if(settings_library != 'None (use settings defined above)'):\n",
        "  custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "global_var_scope = globals()\n",
        "if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "  print('Loaded ', custom_settings)\n",
        "  try:\n",
        "    from configparser import ConfigParser\n",
        "  except ImportError:\n",
        "      from ConfigParser import ConfigParser\n",
        "  import configparser\n",
        "  \n",
        "  config = ConfigParser()\n",
        "  config.read(custom_settings)\n",
        "  #custom_settings_stream = fetch(custom_settings)\n",
        "  #Load CLIP models from config\n",
        "  if(config.has_section('clip_list')):\n",
        "    clip_incoming_list = config.items('clip_list')\n",
        "    clip_incoming_models = clip_incoming_list[0]\n",
        "    incoming_perceptors = eval(clip_incoming_models[1])\n",
        "    if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "      clip_load_list = incoming_perceptors\n",
        "      clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "  #Load settings from config and replace variables\n",
        "  if(config.has_section('basic_settings')):\n",
        "    basic_settings = config.items('basic_settings')\n",
        "    for basic_setting in basic_settings:\n",
        "      global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "  \n",
        "  if(config.has_section('advanced_settings')):\n",
        "    advanced_settings = config.items('advanced_settings')\n",
        "    for advanced_setting in advanced_settings:\n",
        "      global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "  custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "prompts = clip_prompts\n",
        "opt.prompt = latent_prompts\n",
        "opt.uc = latent_negatives\n",
        "custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "aes_scale = aesthetic_loss_scale\n",
        "try: \n",
        "  clip_guidance_schedule\n",
        "  clip_guidance_index = clip_guidance_schedule\n",
        "except:\n",
        "  clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "opt.W = (width//64)*64;\n",
        "opt.H = (height//64)*64;\n",
        "if opt.W != width or opt.H != height:\n",
        "    print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "opt.mag_mul = opt_mag_mul \n",
        "opt.ddim_eta = opt_ddim_eta\n",
        "opt.eta_end = opt_eta_end\n",
        "opt.temperature = opt_temperature\n",
        "opt.n_iter = how_many_batches\n",
        "opt.n_samples =  1\n",
        "opt.scale = latent_diffusion_guidance_scale\n",
        "opt.plms = opt_plms\n",
        "aug = augment_cuts\n",
        "\n",
        "#Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "if(len(clamp_index) == 2): \n",
        "  clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "else:\n",
        "  clamp_index_variation = clamp_index\n",
        "score_corrector = DotMap()\n",
        "\n",
        "\n",
        "def modify_score(e_t, e_t_uncond):\n",
        "        if(score_modifier is False):\n",
        "          return e_t\n",
        "        else:\n",
        "          e_t_d = (e_t - e_t_uncond)\n",
        "          s = torch.quantile(\n",
        "              rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "              threshold_percentile,\n",
        "              dim = -1\n",
        "          )\n",
        "\n",
        "        s.clamp_(min = 1.)\n",
        "        s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "        if ths_method == \"softsign\":\n",
        "            e_t_d = F.softsign(e_t_d) / s \n",
        "        elif ths_method == \"clamp\":\n",
        "            e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "        e_t = e_t_uncond + e_t_d\n",
        "        return(e_t)\n",
        "          \n",
        "score_corrector.modify_score = modify_score\n",
        "\n",
        "def dynamic_thresholding(pred_x0,t):\n",
        "    return(pred_x0)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "generate_video = False\n",
        "if generate_video: \n",
        "    fps = 24\n",
        "    p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "do_run()\n",
        "if generate_video: \n",
        "    p.stdin.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "oFqCF5gEb3A4"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#@markdown ### **Run 4.** Basic settings\n",
        "\n",
        "width = 256 #@param{type: 'integer'}\n",
        "height = 512 #@param{type: 'integer'}\n",
        "\n",
        "clamp_index = [1.5, 2.0] #@param{type: 'raw'}\n",
        "\n",
        "latent_diffusion_guidance_scale = 6 #@param {type:\"number\"}\n",
        "clip_guidance_scale = 36000 #@param{type: 'integer'}\n",
        "\n",
        "how_many_batches = 1 #@param{type: 'integer'}\n",
        "aesthetic_loss_scale = 100 #@param{type: 'integer'}\n",
        "augment_cuts = True #@param{type:'boolean'}\n",
        "\n",
        "\n",
        "#@markdown\n",
        "\n",
        "#@markdown ### Custom saved settings\n",
        "#@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "custom_settings = '' #@param{type:'string'}\n",
        "settings_library = 'None (use settings defined above)' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "if(settings_library != 'None (use settings defined above)'):\n",
        "  custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "global_var_scope = globals()\n",
        "if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "  print('Loaded ', custom_settings)\n",
        "  try:\n",
        "    from configparser import ConfigParser\n",
        "  except ImportError:\n",
        "      from ConfigParser import ConfigParser\n",
        "  import configparser\n",
        "  \n",
        "  config = ConfigParser()\n",
        "  config.read(custom_settings)\n",
        "  #custom_settings_stream = fetch(custom_settings)\n",
        "  #Load CLIP models from config\n",
        "  if(config.has_section('clip_list')):\n",
        "    clip_incoming_list = config.items('clip_list')\n",
        "    clip_incoming_models = clip_incoming_list[0]\n",
        "    incoming_perceptors = eval(clip_incoming_models[1])\n",
        "    if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "      clip_load_list = incoming_perceptors\n",
        "      clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "  #Load settings from config and replace variables\n",
        "  if(config.has_section('basic_settings')):\n",
        "    basic_settings = config.items('basic_settings')\n",
        "    for basic_setting in basic_settings:\n",
        "      global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "  \n",
        "  if(config.has_section('advanced_settings')):\n",
        "    advanced_settings = config.items('advanced_settings')\n",
        "    for advanced_setting in advanced_settings:\n",
        "      global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "  custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "prompts = clip_prompts\n",
        "opt.prompt = latent_prompts\n",
        "opt.uc = latent_negatives\n",
        "custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "aes_scale = aesthetic_loss_scale\n",
        "try: \n",
        "  clip_guidance_schedule\n",
        "  clip_guidance_index = clip_guidance_schedule\n",
        "except:\n",
        "  clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "opt.W = (width//64)*64;\n",
        "opt.H = (height//64)*64;\n",
        "if opt.W != width or opt.H != height:\n",
        "    print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "opt.mag_mul = opt_mag_mul \n",
        "opt.ddim_eta = opt_ddim_eta\n",
        "opt.eta_end = opt_eta_end\n",
        "opt.temperature = opt_temperature\n",
        "opt.n_iter = how_many_batches\n",
        "opt.n_samples =  1\n",
        "opt.scale = latent_diffusion_guidance_scale\n",
        "opt.plms = opt_plms\n",
        "aug = augment_cuts\n",
        "\n",
        "#Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "if(len(clamp_index) == 2): \n",
        "  clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "else:\n",
        "  clamp_index_variation = clamp_index\n",
        "score_corrector = DotMap()\n",
        "\n",
        "\n",
        "def modify_score(e_t, e_t_uncond):\n",
        "        if(score_modifier is False):\n",
        "          return e_t\n",
        "        else:\n",
        "          e_t_d = (e_t - e_t_uncond)\n",
        "          s = torch.quantile(\n",
        "              rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "              threshold_percentile,\n",
        "              dim = -1\n",
        "          )\n",
        "\n",
        "        s.clamp_(min = 1.)\n",
        "        s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "        if ths_method == \"softsign\":\n",
        "            e_t_d = F.softsign(e_t_d) / s \n",
        "        elif ths_method == \"clamp\":\n",
        "            e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "        e_t = e_t_uncond + e_t_d\n",
        "        return(e_t)\n",
        "          \n",
        "score_corrector.modify_score = modify_score\n",
        "\n",
        "def dynamic_thresholding(pred_x0,t):\n",
        "    return(pred_x0)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "generate_video = False\n",
        "if generate_video: \n",
        "    fps = 24\n",
        "    p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "do_run()\n",
        "if generate_video: \n",
        "    p.stdin.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "jN_nQt6sb3A5"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#@markdown ### **Run 5.** Basic settings\n",
        "\n",
        "#@markdown We're still figuring out default settings. Experiment and <a href=\"https://huggingface.co/datasets/multimodalart/latent-majesty-diffusion-settings\">share your settings with us</a>.\n",
        "\n",
        "width = 512 #@param{type: 'integer'}\n",
        "height = 256 #@param{type: 'integer'}\n",
        "\n",
        "clamp_index = [2.1, 2.4] #@param{type: 'raw'}\n",
        "\n",
        "latent_diffusion_guidance_scale = 9 #@param {type:\"number\"}\n",
        "clip_guidance_scale = 16000 #@param{type: 'integer'}\n",
        "\n",
        "how_many_batches = 1#@param{type: 'integer'}\n",
        "aesthetic_loss_scale = 100 #@param{type: 'integer'}\n",
        "augment_cuts = True #@param{type:'boolean'}\n",
        "\n",
        "\n",
        "#@markdown\n",
        "\n",
        "#@markdown ### Custom saved settings\n",
        "#@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "custom_settings = '' #@param{type:'string'}\n",
        "settings_library = 'default' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "if(settings_library != 'None (use settings defined above)'):\n",
        "  custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "global_var_scope = globals()\n",
        "if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "  print('Loaded ', custom_settings)\n",
        "  try:\n",
        "    from configparser import ConfigParser\n",
        "  except ImportError:\n",
        "      from ConfigParser import ConfigParser\n",
        "  import configparser\n",
        "  \n",
        "  config = ConfigParser()\n",
        "  config.read(custom_settings)\n",
        "  #custom_settings_stream = fetch(custom_settings)\n",
        "  #Load CLIP models from config\n",
        "  if(config.has_section('clip_list')):\n",
        "    clip_incoming_list = config.items('clip_list')\n",
        "    clip_incoming_models = clip_incoming_list[0]\n",
        "    incoming_perceptors = eval(clip_incoming_models[1])\n",
        "    if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "      clip_load_list = incoming_perceptors\n",
        "      clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "  #Load settings from config and replace variables\n",
        "  if(config.has_section('basic_settings')):\n",
        "    basic_settings = config.items('basic_settings')\n",
        "    for basic_setting in basic_settings:\n",
        "      global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "  \n",
        "  if(config.has_section('advanced_settings')):\n",
        "    advanced_settings = config.items('advanced_settings')\n",
        "    for advanced_setting in advanced_settings:\n",
        "      global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "  custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "prompts = clip_prompts\n",
        "opt.prompt = latent_prompts\n",
        "opt.uc = latent_negatives\n",
        "custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "aes_scale = aesthetic_loss_scale\n",
        "try: \n",
        "  clip_guidance_schedule\n",
        "  clip_guidance_index = clip_guidance_schedule\n",
        "except:\n",
        "  clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "opt.W = (width//64)*64;\n",
        "opt.H = (height//64)*64;\n",
        "if opt.W != width or opt.H != height:\n",
        "    print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "opt.mag_mul = opt_mag_mul \n",
        "opt.ddim_eta = opt_ddim_eta\n",
        "opt.eta_end = opt_eta_end\n",
        "opt.temperature = opt_temperature\n",
        "opt.n_iter = how_many_batches\n",
        "opt.n_samples =  1\n",
        "opt.scale = latent_diffusion_guidance_scale\n",
        "opt.plms = opt_plms\n",
        "aug = augment_cuts\n",
        "\n",
        "#Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "if(len(clamp_index) == 2): \n",
        "  clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "else:\n",
        "  clamp_index_variation = clamp_index\n",
        "score_corrector = DotMap()\n",
        "\n",
        "\n",
        "def modify_score(e_t, e_t_uncond):\n",
        "        if(score_modifier is False):\n",
        "          return e_t\n",
        "        else:\n",
        "          e_t_d = (e_t - e_t_uncond)\n",
        "          s = torch.quantile(\n",
        "              rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "              threshold_percentile,\n",
        "              dim = -1\n",
        "          )\n",
        "\n",
        "        s.clamp_(min = 1.)\n",
        "        s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "        if ths_method == \"softsign\":\n",
        "            e_t_d = F.softsign(e_t_d) / s \n",
        "        elif ths_method == \"clamp\":\n",
        "            e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "        e_t = e_t_uncond + e_t_d\n",
        "        return(e_t)\n",
        "          \n",
        "score_corrector.modify_score = modify_score\n",
        "\n",
        "def dynamic_thresholding(pred_x0,t):\n",
        "    return(pred_x0)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "generate_video = False\n",
        "if generate_video: \n",
        "    fps = 24\n",
        "    p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "do_run()\n",
        "if generate_video: \n",
        "    p.stdin.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "l3frSBihb3A5"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#@markdown ### **Run 6.** Basic Settings\n",
        "\n",
        "width = 256 #@param{type: 'integer'}\n",
        "height = 384 #@param{type: 'integer'}\n",
        "\n",
        "clamp_index = [2.4, 2.1] #@param{type: 'raw'}\n",
        "\n",
        "latent_diffusion_guidance_scale = 15 #@param {type:\"number\"}\n",
        "clip_guidance_scale = 20000 #@param{type: 'integer'}\n",
        "\n",
        "how_many_batches = 1 #@param{type: 'integer'}\n",
        "aesthetic_loss_scale = 100 #@param{type: 'integer'}\n",
        "augment_cuts = True #@param{type:'boolean'}\n",
        "\n",
        "\n",
        "#@markdown\n",
        "\n",
        "#@markdown ### Custom saved settings\n",
        "#@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "custom_settings = '' #@param{type:'string'}\n",
        "settings_library = 'default' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "if(settings_library != 'None (use settings defined above)'):\n",
        "  custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "global_var_scope = globals()\n",
        "if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "  print('Loaded ', custom_settings)\n",
        "  try:\n",
        "    from configparser import ConfigParser\n",
        "  except ImportError:\n",
        "      from ConfigParser import ConfigParser\n",
        "  import configparser\n",
        "  \n",
        "  config = ConfigParser()\n",
        "  config.read(custom_settings)\n",
        "  #custom_settings_stream = fetch(custom_settings)\n",
        "  #Load CLIP models from config\n",
        "  if(config.has_section('clip_list')):\n",
        "    clip_incoming_list = config.items('clip_list')\n",
        "    clip_incoming_models = clip_incoming_list[0]\n",
        "    incoming_perceptors = eval(clip_incoming_models[1])\n",
        "    if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "      clip_load_list = incoming_perceptors\n",
        "      clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "  #Load settings from config and replace variables\n",
        "  if(config.has_section('basic_settings')):\n",
        "    basic_settings = config.items('basic_settings')\n",
        "    for basic_setting in basic_settings:\n",
        "      global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "  \n",
        "  if(config.has_section('advanced_settings')):\n",
        "    advanced_settings = config.items('advanced_settings')\n",
        "    for advanced_setting in advanced_settings:\n",
        "      global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "  custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "prompts = clip_prompts\n",
        "opt.prompt = latent_prompts\n",
        "opt.uc = latent_negatives\n",
        "custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "aes_scale = aesthetic_loss_scale\n",
        "try: \n",
        "  clip_guidance_schedule\n",
        "  clip_guidance_index = clip_guidance_schedule\n",
        "except:\n",
        "  clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "opt.W = (width//64)*64;\n",
        "opt.H = (height//64)*64;\n",
        "if opt.W != width or opt.H != height:\n",
        "    print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "opt.mag_mul = opt_mag_mul \n",
        "opt.ddim_eta = opt_ddim_eta\n",
        "opt.eta_end = opt_eta_end\n",
        "opt.temperature = opt_temperature\n",
        "opt.n_iter = how_many_batches\n",
        "opt.n_samples =  1\n",
        "opt.scale = latent_diffusion_guidance_scale\n",
        "opt.plms = opt_plms\n",
        "aug = augment_cuts\n",
        "\n",
        "#Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "if(len(clamp_index) == 2): \n",
        "  clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "else:\n",
        "  clamp_index_variation = clamp_index\n",
        "score_corrector = DotMap()\n",
        "\n",
        "\n",
        "def modify_score(e_t, e_t_uncond):\n",
        "        if(score_modifier is False):\n",
        "          return e_t\n",
        "        else:\n",
        "          e_t_d = (e_t - e_t_uncond)\n",
        "          s = torch.quantile(\n",
        "              rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "              threshold_percentile,\n",
        "              dim = -1\n",
        "          )\n",
        "\n",
        "        s.clamp_(min = 1.)\n",
        "        s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "        if ths_method == \"softsign\":\n",
        "            e_t_d = F.softsign(e_t_d) / s \n",
        "        elif ths_method == \"clamp\":\n",
        "            e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "        e_t = e_t_uncond + e_t_d\n",
        "        return(e_t)\n",
        "          \n",
        "score_corrector.modify_score = modify_score\n",
        "\n",
        "def dynamic_thresholding(pred_x0,t):\n",
        "    return(pred_x0)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "generate_video = False\n",
        "if generate_video: \n",
        "    fps = 24\n",
        "    p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "do_run()\n",
        "if generate_video: \n",
        "    p.stdin.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "NUkg-Qplb3A5"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#@markdown ### **Run 7.** Basic Settings\n",
        "\n",
        "width = 384 #@param{type: 'integer'}\n",
        "height = 384 #@param{type: 'integer'}\n",
        "\n",
        "clamp_index = [0.6, 0.6] #@param{type: 'raw'}\n",
        "\n",
        "latent_diffusion_guidance_scale = 11 #@param {type:\"number\"}\n",
        "clip_guidance_scale = 39999 #@param{type: 'integer'}\n",
        "\n",
        "how_many_batches = 1 #@param{type: 'integer'}\n",
        "aesthetic_loss_scale = 100 #@param{type: 'integer'}\n",
        "augment_cuts = True #@param{type:'boolean'}\n",
        "\n",
        "\n",
        "#@markdown ### Custom saved settings\n",
        "#@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "custom_settings = '' #@param{type:'string'}\n",
        "settings_library = 'coherent_pizzapigeon' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "if(settings_library != 'None (use settings defined above)'):\n",
        "  custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "global_var_scope = globals()\n",
        "if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "  print('Loaded ', custom_settings)\n",
        "  try:\n",
        "    from configparser import ConfigParser\n",
        "  except ImportError:\n",
        "      from ConfigParser import ConfigParser\n",
        "  import configparser\n",
        "  \n",
        "  config = ConfigParser()\n",
        "  config.read(custom_settings)\n",
        "  #custom_settings_stream = fetch(custom_settings)\n",
        "  #Load CLIP models from config\n",
        "  if(config.has_section('clip_list')):\n",
        "    clip_incoming_list = config.items('clip_list')\n",
        "    clip_incoming_models = clip_incoming_list[0]\n",
        "    incoming_perceptors = eval(clip_incoming_models[1])\n",
        "    if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "      clip_load_list = incoming_perceptors\n",
        "      clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "  #Load settings from config and replace variables\n",
        "  if(config.has_section('basic_settings')):\n",
        "    basic_settings = config.items('basic_settings')\n",
        "    for basic_setting in basic_settings:\n",
        "      global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "  \n",
        "  if(config.has_section('advanced_settings')):\n",
        "    advanced_settings = config.items('advanced_settings')\n",
        "    for advanced_setting in advanced_settings:\n",
        "      global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "  custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "prompts = clip_prompts\n",
        "opt.prompt = latent_prompts\n",
        "opt.uc = latent_negatives\n",
        "custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "aes_scale = aesthetic_loss_scale\n",
        "try: \n",
        "  clip_guidance_schedule\n",
        "  clip_guidance_index = clip_guidance_schedule\n",
        "except:\n",
        "  clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "opt.W = (width//64)*64;\n",
        "opt.H = (height//64)*64;\n",
        "if opt.W != width or opt.H != height:\n",
        "    print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "opt.mag_mul = opt_mag_mul \n",
        "opt.ddim_eta = opt_ddim_eta\n",
        "opt.eta_end = opt_eta_end\n",
        "opt.temperature = opt_temperature\n",
        "opt.n_iter = how_many_batches\n",
        "opt.n_samples =  1\n",
        "opt.scale = latent_diffusion_guidance_scale\n",
        "opt.plms = opt_plms\n",
        "aug = augment_cuts\n",
        "\n",
        "#Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "if(len(clamp_index) == 2): \n",
        "  clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "else:\n",
        "  clamp_index_variation = clamp_index\n",
        "score_corrector = DotMap()\n",
        "\n",
        "\n",
        "def modify_score(e_t, e_t_uncond):\n",
        "        if(score_modifier is False):\n",
        "          return e_t\n",
        "        else:\n",
        "          e_t_d = (e_t - e_t_uncond)\n",
        "          s = torch.quantile(\n",
        "              rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "              threshold_percentile,\n",
        "              dim = -1\n",
        "          )\n",
        "\n",
        "        s.clamp_(min = 1.)\n",
        "        s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "        if ths_method == \"softsign\":\n",
        "            e_t_d = F.softsign(e_t_d) / s \n",
        "        elif ths_method == \"clamp\":\n",
        "            e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "        e_t = e_t_uncond + e_t_d\n",
        "        return(e_t)\n",
        "          \n",
        "score_corrector.modify_score = modify_score\n",
        "\n",
        "def dynamic_thresholding(pred_x0,t):\n",
        "    return(pred_x0)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "generate_video = False\n",
        "if generate_video: \n",
        "    fps = 24\n",
        "    p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "do_run()\n",
        "if generate_video: \n",
        "    p.stdin.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "RSmQjc_Mb3A6"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#@markdown ### **Run 8.** Basic Settings\n",
        "\n",
        "width =  256#@param{type: 'integer'}\n",
        "height =  384#@param{type: 'integer'}\n",
        "\n",
        "clamp_index = [1, 1] #@param{type: 'raw'}\n",
        "\n",
        "latent_diffusion_guidance_scale = 10 #@param {type:\"number\"}\n",
        "clip_guidance_scale =  50000#@param{type: 'integer'}\n",
        "\n",
        "how_many_batches =  1#@param{type: 'integer'}\n",
        "\n",
        "aesthetic_loss_scale = 100 #@param{type: 'integer'}\n",
        "augment_cuts=True #@param{type:'boolean'}\n",
        "\n",
        "\n",
        "#@markdown ### Custom saved settings\n",
        "#@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "custom_settings = '' #@param{type:'string'}\n",
        "settings_library = 'coherent_pizzapigeon' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "if(settings_library != 'None (use settings defined above)'):\n",
        "  custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "global_var_scope = globals()\n",
        "if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "  print('Loaded ', custom_settings)\n",
        "  try:\n",
        "    from configparser import ConfigParser\n",
        "  except ImportError:\n",
        "      from ConfigParser import ConfigParser\n",
        "  import configparser\n",
        "  \n",
        "  config = ConfigParser()\n",
        "  config.read(custom_settings)\n",
        "  #custom_settings_stream = fetch(custom_settings)\n",
        "  #Load CLIP models from config\n",
        "  if(config.has_section('clip_list')):\n",
        "    clip_incoming_list = config.items('clip_list')\n",
        "    clip_incoming_models = clip_incoming_list[0]\n",
        "    incoming_perceptors = eval(clip_incoming_models[1])\n",
        "    if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "      clip_load_list = incoming_perceptors\n",
        "      clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "  #Load settings from config and replace variables\n",
        "  if(config.has_section('basic_settings')):\n",
        "    basic_settings = config.items('basic_settings')\n",
        "    for basic_setting in basic_settings:\n",
        "      global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "  \n",
        "  if(config.has_section('advanced_settings')):\n",
        "    advanced_settings = config.items('advanced_settings')\n",
        "    for advanced_setting in advanced_settings:\n",
        "      global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "  custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "prompts = clip_prompts\n",
        "opt.prompt = latent_prompts\n",
        "opt.uc = latent_negatives\n",
        "custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "aes_scale = aesthetic_loss_scale\n",
        "try: \n",
        "  clip_guidance_schedule\n",
        "  clip_guidance_index = clip_guidance_schedule\n",
        "except:\n",
        "  clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "opt.W = (width//64)*64;\n",
        "opt.H = (height//64)*64;\n",
        "if opt.W != width or opt.H != height:\n",
        "    print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "opt.mag_mul = opt_mag_mul \n",
        "opt.ddim_eta = opt_ddim_eta\n",
        "opt.eta_end = opt_eta_end\n",
        "opt.temperature = opt_temperature\n",
        "opt.n_iter = how_many_batches\n",
        "opt.n_samples =  1\n",
        "opt.scale = latent_diffusion_guidance_scale\n",
        "opt.plms = opt_plms\n",
        "aug = augment_cuts\n",
        "\n",
        "#Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "if(len(clamp_index) == 2): \n",
        "  clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "else:\n",
        "  clamp_index_variation = clamp_index\n",
        "score_corrector = DotMap()\n",
        "\n",
        "\n",
        "def modify_score(e_t, e_t_uncond):\n",
        "        if(score_modifier is False):\n",
        "          return e_t\n",
        "        else:\n",
        "          e_t_d = (e_t - e_t_uncond)\n",
        "          s = torch.quantile(\n",
        "              rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "              threshold_percentile,\n",
        "              dim = -1\n",
        "          )\n",
        "\n",
        "        s.clamp_(min = 1.)\n",
        "        s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "        if ths_method == \"softsign\":\n",
        "            e_t_d = F.softsign(e_t_d) / s \n",
        "        elif ths_method == \"clamp\":\n",
        "            e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "        e_t = e_t_uncond + e_t_d\n",
        "        return(e_t)\n",
        "          \n",
        "score_corrector.modify_score = modify_score\n",
        "\n",
        "def dynamic_thresholding(pred_x0,t):\n",
        "    return(pred_x0)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "generate_video = False\n",
        "if generate_video: \n",
        "    fps = 24\n",
        "    p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "do_run()\n",
        "if generate_video: \n",
        "    p.stdin.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "DBJJzbSqb3A6"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#@markdown ### **Run 9.** Basic Settings\n",
        "\n",
        "width = 384 #@param{type: 'integer'}\n",
        "height = 256 #@param{type: 'integer'}\n",
        "\n",
        "clamp_index = [1, 1] #@param{type: 'raw'}\n",
        "\n",
        "latent_diffusion_guidance_scale = 13 #@param {type:\"number\"}\n",
        "clip_guidance_scale = 24000 #@param{type: 'integer'}\n",
        "\n",
        "how_many_batches =  1#@param{type: 'integer'}\n",
        "aesthetic_loss_scale =  1#@param{type: 'integer'}\n",
        "augment_cuts = True #@param{type:'boolean'}\n",
        "\n",
        "\n",
        "#@markdown ### Custom saved settings\n",
        "#@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "custom_settings = '' #@param{type:'string'}\n",
        "settings_library = 'makeitrad_defaults' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "if(settings_library != 'None (use settings defined above)'):\n",
        "  custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "global_var_scope = globals()\n",
        "if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "  print('Loaded ', custom_settings)\n",
        "  try:\n",
        "    from configparser import ConfigParser\n",
        "  except ImportError:\n",
        "      from ConfigParser import ConfigParser\n",
        "  import configparser\n",
        "  \n",
        "  config = ConfigParser()\n",
        "  config.read(custom_settings)\n",
        "  #custom_settings_stream = fetch(custom_settings)\n",
        "  #Load CLIP models from config\n",
        "  if(config.has_section('clip_list')):\n",
        "    clip_incoming_list = config.items('clip_list')\n",
        "    clip_incoming_models = clip_incoming_list[0]\n",
        "    incoming_perceptors = eval(clip_incoming_models[1])\n",
        "    if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "      clip_load_list = incoming_perceptors\n",
        "      clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "  #Load settings from config and replace variables\n",
        "  if(config.has_section('basic_settings')):\n",
        "    basic_settings = config.items('basic_settings')\n",
        "    for basic_setting in basic_settings:\n",
        "      global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "  \n",
        "  if(config.has_section('advanced_settings')):\n",
        "    advanced_settings = config.items('advanced_settings')\n",
        "    for advanced_setting in advanced_settings:\n",
        "      global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "  custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "prompts = clip_prompts\n",
        "opt.prompt = latent_prompts\n",
        "opt.uc = latent_negatives\n",
        "custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "aes_scale = aesthetic_loss_scale\n",
        "try: \n",
        "  clip_guidance_schedule\n",
        "  clip_guidance_index = clip_guidance_schedule\n",
        "except:\n",
        "  clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "opt.W = (width//64)*64;\n",
        "opt.H = (height//64)*64;\n",
        "if opt.W != width or opt.H != height:\n",
        "    print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "opt.mag_mul = opt_mag_mul \n",
        "opt.ddim_eta = opt_ddim_eta\n",
        "opt.eta_end = opt_eta_end\n",
        "opt.temperature = opt_temperature\n",
        "opt.n_iter = how_many_batches\n",
        "opt.n_samples =  1\n",
        "opt.scale = latent_diffusion_guidance_scale\n",
        "opt.plms = opt_plms\n",
        "aug = augment_cuts\n",
        "\n",
        "#Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "if(len(clamp_index) == 2): \n",
        "  clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "else:\n",
        "  clamp_index_variation = clamp_index\n",
        "score_corrector = DotMap()\n",
        "\n",
        "\n",
        "def modify_score(e_t, e_t_uncond):\n",
        "        if(score_modifier is False):\n",
        "          return e_t\n",
        "        else:\n",
        "          e_t_d = (e_t - e_t_uncond)\n",
        "          s = torch.quantile(\n",
        "              rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "              threshold_percentile,\n",
        "              dim = -1\n",
        "          )\n",
        "\n",
        "        s.clamp_(min = 1.)\n",
        "        s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "        if ths_method == \"softsign\":\n",
        "            e_t_d = F.softsign(e_t_d) / s \n",
        "        elif ths_method == \"clamp\":\n",
        "            e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "        e_t = e_t_uncond + e_t_d\n",
        "        return(e_t)\n",
        "          \n",
        "score_corrector.modify_score = modify_score\n",
        "\n",
        "def dynamic_thresholding(pred_x0,t):\n",
        "    return(pred_x0)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "generate_video = False\n",
        "if generate_video: \n",
        "    fps = 24\n",
        "    p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "do_run()\n",
        "if generate_video: \n",
        "    p.stdin.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "UidhbVrYb3A7"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#@markdown ### **Run 10.** Basic Settings\n",
        "\n",
        "width = 256 #@param{type: 'integer'}\n",
        "height = 384 #@param{type: 'integer'}\n",
        "\n",
        "clamp_index = [1, 1] #@param{type: 'raw'}\n",
        "\n",
        "latent_diffusion_guidance_scale = 14 #@param {type:\"number\"}\n",
        "clip_guidance_scale = 8000 #@param{type: 'integer'}\n",
        "\n",
        "how_many_batches = 1 #@param{type: 'integer'}\n",
        "aesthetic_loss_scale = 10 #@param{type: 'integer'}\n",
        "augment_cuts = True #@param{type:'boolean'}\n",
        "\n",
        "\n",
        "#@markdown ### Custom saved settings\n",
        "#@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "custom_settings = '' #@param{type:'string'}\n",
        "settings_library = 'makeitrad_defaults' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "if(settings_library != 'None (use settings defined above)'):\n",
        "  custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "global_var_scope = globals()\n",
        "if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "  print('Loaded ', custom_settings)\n",
        "  try:\n",
        "    from configparser import ConfigParser\n",
        "  except ImportError:\n",
        "      from ConfigParser import ConfigParser\n",
        "  import configparser\n",
        "  \n",
        "  config = ConfigParser()\n",
        "  config.read(custom_settings)\n",
        "  #custom_settings_stream = fetch(custom_settings)\n",
        "  #Load CLIP models from config\n",
        "  if(config.has_section('clip_list')):\n",
        "    clip_incoming_list = config.items('clip_list')\n",
        "    clip_incoming_models = clip_incoming_list[0]\n",
        "    incoming_perceptors = eval(clip_incoming_models[1])\n",
        "    if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "      clip_load_list = incoming_perceptors\n",
        "      clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "  #Load settings from config and replace variables\n",
        "  if(config.has_section('basic_settings')):\n",
        "    basic_settings = config.items('basic_settings')\n",
        "    for basic_setting in basic_settings:\n",
        "      global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "  \n",
        "  if(config.has_section('advanced_settings')):\n",
        "    advanced_settings = config.items('advanced_settings')\n",
        "    for advanced_setting in advanced_settings:\n",
        "      global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "  custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "prompts = clip_prompts\n",
        "opt.prompt = latent_prompts\n",
        "opt.uc = latent_negatives\n",
        "custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "aes_scale = aesthetic_loss_scale\n",
        "try: \n",
        "  clip_guidance_schedule\n",
        "  clip_guidance_index = clip_guidance_schedule\n",
        "except:\n",
        "  clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "opt.W = (width//64)*64;\n",
        "opt.H = (height//64)*64;\n",
        "if opt.W != width or opt.H != height:\n",
        "    print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "opt.mag_mul = opt_mag_mul \n",
        "opt.ddim_eta = opt_ddim_eta\n",
        "opt.eta_end = opt_eta_end\n",
        "opt.temperature = opt_temperature\n",
        "opt.n_iter = how_many_batches\n",
        "opt.n_samples =  1\n",
        "opt.scale = latent_diffusion_guidance_scale\n",
        "opt.plms = opt_plms\n",
        "aug = augment_cuts\n",
        "\n",
        "#Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "if(len(clamp_index) == 2): \n",
        "  clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "else:\n",
        "  clamp_index_variation = clamp_index\n",
        "score_corrector = DotMap()\n",
        "\n",
        "\n",
        "def modify_score(e_t, e_t_uncond):\n",
        "        if(score_modifier is False):\n",
        "          return e_t\n",
        "        else:\n",
        "          e_t_d = (e_t - e_t_uncond)\n",
        "          s = torch.quantile(\n",
        "              rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "              threshold_percentile,\n",
        "              dim = -1\n",
        "          )\n",
        "\n",
        "        s.clamp_(min = 1.)\n",
        "        s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "        if ths_method == \"softsign\":\n",
        "            e_t_d = F.softsign(e_t_d) / s \n",
        "        elif ths_method == \"clamp\":\n",
        "            e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "        e_t = e_t_uncond + e_t_d\n",
        "        return(e_t)\n",
        "          \n",
        "score_corrector.modify_score = modify_score\n",
        "\n",
        "def dynamic_thresholding(pred_x0,t):\n",
        "    return(pred_x0)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "generate_video = False\n",
        "if generate_video: \n",
        "    fps = 24\n",
        "    p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "do_run()\n",
        "if generate_video: \n",
        "    p.stdin.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzhuRi7zb3P7"
      },
      "source": [
        "### 𝗗ᴇᴋᴀ-𝗕ᴀᴛᴄʜ 𝗥ᴜɴ 𝗖ᴇʟʟ𝘀 **X4** - Genie"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "init_image = \"https://i.imgur.com/CaDFnF4.png\" #@param{type: 'string'}\n",
        "if(init_image == '' or init_image == 'None'):\n",
        "  init_image = None\n",
        "\n",
        "#default 0.9\n",
        "starting_timestep = 0.0 #@param{type: 'number'}\n",
        "\n",
        "init_mask = None #@param{type: 'string'}\n",
        "\n",
        "init_scale = 1000 #@param{type: 'integer'}\n",
        "\n",
        "#default 0.0\n",
        "init_brightness = 0.0 #@param{type: 'number'}\n",
        "\n",
        "#default 0.57\n",
        "init_noise = 0.0 #@param{type: 'number'}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "P1x_HpLpb3P7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "m8JonFsib3P7"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#@markdown ### **Run 1.** Basic settings\n",
        "\n",
        "#@markdown We're still figuring out default settings. Experiment and <a href=\"https://huggingface.co/datasets/multimodalart/latent-majesty-diffusion-settings\">share your settings with us</a>.\n",
        "\n",
        "#@markdown ✦✦ TO DO: Add init image cut schedule toggle, init and config skip toggles. ✦✦\n",
        "\n",
        "width = 256 #@param{type: 'integer'}\n",
        "height = 384 #@param{type: 'integer'}\n",
        "\n",
        "clamp_index = [2.4, 2.1] #@param{type: 'raw'}\n",
        "\n",
        "latent_diffusion_guidance_scale = 12 #@param {type:\"number\"}\n",
        "clip_guidance_scale = 12000 #@param{type: 'integer'}\n",
        "\n",
        "how_many_batches = 1 #@param{type: 'integer'}\n",
        "\n",
        "aesthetic_loss_scale = 100 #@param{type: 'integer'}\n",
        "augment_cuts = True #@param{type:'boolean'}\n",
        "\n",
        "\n",
        "#@markdown ### Custom saved settings\n",
        "#@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "custom_settings = '' #@param{type:'string'}\n",
        "settings_library = 'None (use settings defined above)' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "if(settings_library != 'None (use settings defined above)'):\n",
        "  custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "global_var_scope = globals()\n",
        "if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "  print('Loaded ', custom_settings)\n",
        "  try:\n",
        "    from configparser import ConfigParser\n",
        "  except ImportError:\n",
        "      from ConfigParser import ConfigParser\n",
        "  import configparser\n",
        "  \n",
        "  config = ConfigParser()\n",
        "  config.read(custom_settings)\n",
        "  #custom_settings_stream = fetch(custom_settings)\n",
        "  #Load CLIP models from config\n",
        "  if(config.has_section('clip_list')):\n",
        "    clip_incoming_list = config.items('clip_list')\n",
        "    clip_incoming_models = clip_incoming_list[0]\n",
        "    incoming_perceptors = eval(clip_incoming_models[1])\n",
        "    if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "      clip_load_list = incoming_perceptors\n",
        "      clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "  #Load settings from config and replace variables\n",
        "  if(config.has_section('basic_settings')):\n",
        "    basic_settings = config.items('basic_settings')\n",
        "    for basic_setting in basic_settings:\n",
        "      global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "  \n",
        "  if(config.has_section('advanced_settings')):\n",
        "    advanced_settings = config.items('advanced_settings')\n",
        "    for advanced_setting in advanced_settings:\n",
        "      global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "  custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "prompts = clip_prompts\n",
        "opt.prompt = latent_prompts\n",
        "opt.uc = latent_negatives\n",
        "custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "aes_scale = aesthetic_loss_scale\n",
        "try: \n",
        "  clip_guidance_schedule\n",
        "  clip_guidance_index = clip_guidance_schedule\n",
        "except:\n",
        "  clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "opt.W = (width//64)*64;\n",
        "opt.H = (height//64)*64;\n",
        "if opt.W != width or opt.H != height:\n",
        "    print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "opt.mag_mul = opt_mag_mul \n",
        "opt.ddim_eta = opt_ddim_eta\n",
        "opt.eta_end = opt_eta_end\n",
        "opt.temperature = opt_temperature\n",
        "opt.n_iter = how_many_batches\n",
        "opt.n_samples =  1\n",
        "opt.scale = latent_diffusion_guidance_scale\n",
        "opt.plms = opt_plms\n",
        "aug = augment_cuts\n",
        "\n",
        "#Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "if(len(clamp_index) == 2): \n",
        "  clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "else:\n",
        "  clamp_index_variation = clamp_index\n",
        "score_corrector = DotMap()\n",
        "\n",
        "\n",
        "def modify_score(e_t, e_t_uncond):\n",
        "        if(score_modifier is False):\n",
        "          return e_t\n",
        "        else:\n",
        "          e_t_d = (e_t - e_t_uncond)\n",
        "          s = torch.quantile(\n",
        "              rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "              threshold_percentile,\n",
        "              dim = -1\n",
        "          )\n",
        "\n",
        "        s.clamp_(min = 1.)\n",
        "        s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "        if ths_method == \"softsign\":\n",
        "            e_t_d = F.softsign(e_t_d) / s \n",
        "        elif ths_method == \"clamp\":\n",
        "            e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "        e_t = e_t_uncond + e_t_d\n",
        "        return(e_t)\n",
        "          \n",
        "score_corrector.modify_score = modify_score\n",
        "\n",
        "def dynamic_thresholding(pred_x0,t):\n",
        "    return(pred_x0)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "generate_video = False\n",
        "if generate_video: \n",
        "    fps = 24\n",
        "    p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "do_run()\n",
        "if generate_video: \n",
        "    p.stdin.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Z0xCnx72b3P7"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#@markdown ### **Run 2.** Basic settings\n",
        "\n",
        "width = 256 #@param{type: 'integer'}\n",
        "height = 384 #@param{type: 'integer'}\n",
        "\n",
        "clamp_index = [2.1, 2.4] #@param{type: 'raw'}\n",
        "\n",
        "latent_diffusion_guidance_scale = 15 #@param {type:\"number\"}\n",
        "clip_guidance_scale = 50000 #@param{type: 'integer'}\n",
        "\n",
        "how_many_batches = 1 #@param{type: 'integer'}\n",
        "\n",
        "aesthetic_loss_scale = 200 #@param{type: 'integer'}\n",
        "augment_cuts = True #@param{type:'boolean'}\n",
        "\n",
        "\n",
        "#@markdown ### Custom saved settings\n",
        "#@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "custom_settings = '' #@param{type:'string'}\n",
        "settings_library = 'None (use settings defined above)' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "if(settings_library != 'None (use settings defined above)'):\n",
        "  custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "global_var_scope = globals()\n",
        "if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "  print('Loaded ', custom_settings)\n",
        "  try:\n",
        "    from configparser import ConfigParser\n",
        "  except ImportError:\n",
        "      from ConfigParser import ConfigParser\n",
        "  import configparser\n",
        "  \n",
        "  config = ConfigParser()\n",
        "  config.read(custom_settings)\n",
        "  #custom_settings_stream = fetch(custom_settings)\n",
        "  #Load CLIP models from config\n",
        "  if(config.has_section('clip_list')):\n",
        "    clip_incoming_list = config.items('clip_list')\n",
        "    clip_incoming_models = clip_incoming_list[0]\n",
        "    incoming_perceptors = eval(clip_incoming_models[1])\n",
        "    if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "      clip_load_list = incoming_perceptors\n",
        "      clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "  #Load settings from config and replace variables\n",
        "  if(config.has_section('basic_settings')):\n",
        "    basic_settings = config.items('basic_settings')\n",
        "    for basic_setting in basic_settings:\n",
        "      global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "  \n",
        "  if(config.has_section('advanced_settings')):\n",
        "    advanced_settings = config.items('advanced_settings')\n",
        "    for advanced_setting in advanced_settings:\n",
        "      global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "  custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "prompts = clip_prompts\n",
        "opt.prompt = latent_prompts\n",
        "opt.uc = latent_negatives\n",
        "custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "aes_scale = aesthetic_loss_scale\n",
        "try: \n",
        "  clip_guidance_schedule\n",
        "  clip_guidance_index = clip_guidance_schedule\n",
        "except:\n",
        "  clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "opt.W = (width//64)*64;\n",
        "opt.H = (height//64)*64;\n",
        "if opt.W != width or opt.H != height:\n",
        "    print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "opt.mag_mul = opt_mag_mul \n",
        "opt.ddim_eta = opt_ddim_eta\n",
        "opt.eta_end = opt_eta_end\n",
        "opt.temperature = opt_temperature\n",
        "opt.n_iter = how_many_batches\n",
        "opt.n_samples =  1\n",
        "opt.scale = latent_diffusion_guidance_scale\n",
        "opt.plms = opt_plms\n",
        "aug = augment_cuts\n",
        "\n",
        "#Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "if(len(clamp_index) == 2): \n",
        "  clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "else:\n",
        "  clamp_index_variation = clamp_index\n",
        "score_corrector = DotMap()\n",
        "\n",
        "\n",
        "def modify_score(e_t, e_t_uncond):\n",
        "        if(score_modifier is False):\n",
        "          return e_t\n",
        "        else:\n",
        "          e_t_d = (e_t - e_t_uncond)\n",
        "          s = torch.quantile(\n",
        "              rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "              threshold_percentile,\n",
        "              dim = -1\n",
        "          )\n",
        "\n",
        "        s.clamp_(min = 1.)\n",
        "        s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "        if ths_method == \"softsign\":\n",
        "            e_t_d = F.softsign(e_t_d) / s \n",
        "        elif ths_method == \"clamp\":\n",
        "            e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "        e_t = e_t_uncond + e_t_d\n",
        "        return(e_t)\n",
        "          \n",
        "score_corrector.modify_score = modify_score\n",
        "\n",
        "def dynamic_thresholding(pred_x0,t):\n",
        "    return(pred_x0)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "generate_video = False\n",
        "if generate_video: \n",
        "    fps = 24\n",
        "    p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "do_run()\n",
        "if generate_video: \n",
        "    p.stdin.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "RlVaWE34b3P8"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#@markdown ### **Run 3.** Basic settings\n",
        "\n",
        "width = 512 #@param{type: 'integer'}\n",
        "height = 256 #@param{type: 'integer'}\n",
        "\n",
        "clamp_index = [2.1, 2.1] #@param{type: 'raw'}\n",
        "\n",
        "latent_diffusion_guidance_scale = 12 #@param {type:\"number\"}\n",
        "clip_guidance_scale = 50000 #@param{type: 'integer'}\n",
        "\n",
        "how_many_batches = 1 #@param{type: 'integer'}\n",
        "\n",
        "aesthetic_loss_scale = 200 #@param{type: 'integer'}\n",
        "augment_cuts = True #@param{type:'boolean'}\n",
        "\n",
        "\n",
        "#@markdown ### Custom saved settings\n",
        "#@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "custom_settings = '' #@param{type:'string'}\n",
        "settings_library = 'None (use settings defined above)' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "if(settings_library != 'None (use settings defined above)'):\n",
        "  custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "global_var_scope = globals()\n",
        "if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "  print('Loaded ', custom_settings)\n",
        "  try:\n",
        "    from configparser import ConfigParser\n",
        "  except ImportError:\n",
        "      from ConfigParser import ConfigParser\n",
        "  import configparser\n",
        "  \n",
        "  config = ConfigParser()\n",
        "  config.read(custom_settings)\n",
        "  #custom_settings_stream = fetch(custom_settings)\n",
        "  #Load CLIP models from config\n",
        "  if(config.has_section('clip_list')):\n",
        "    clip_incoming_list = config.items('clip_list')\n",
        "    clip_incoming_models = clip_incoming_list[0]\n",
        "    incoming_perceptors = eval(clip_incoming_models[1])\n",
        "    if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "      clip_load_list = incoming_perceptors\n",
        "      clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "  #Load settings from config and replace variables\n",
        "  if(config.has_section('basic_settings')):\n",
        "    basic_settings = config.items('basic_settings')\n",
        "    for basic_setting in basic_settings:\n",
        "      global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "  \n",
        "  if(config.has_section('advanced_settings')):\n",
        "    advanced_settings = config.items('advanced_settings')\n",
        "    for advanced_setting in advanced_settings:\n",
        "      global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "  custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "prompts = clip_prompts\n",
        "opt.prompt = latent_prompts\n",
        "opt.uc = latent_negatives\n",
        "custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "aes_scale = aesthetic_loss_scale\n",
        "try: \n",
        "  clip_guidance_schedule\n",
        "  clip_guidance_index = clip_guidance_schedule\n",
        "except:\n",
        "  clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "opt.W = (width//64)*64;\n",
        "opt.H = (height//64)*64;\n",
        "if opt.W != width or opt.H != height:\n",
        "    print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "opt.mag_mul = opt_mag_mul \n",
        "opt.ddim_eta = opt_ddim_eta\n",
        "opt.eta_end = opt_eta_end\n",
        "opt.temperature = opt_temperature\n",
        "opt.n_iter = how_many_batches\n",
        "opt.n_samples =  1\n",
        "opt.scale = latent_diffusion_guidance_scale\n",
        "opt.plms = opt_plms\n",
        "aug = augment_cuts\n",
        "\n",
        "#Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "if(len(clamp_index) == 2): \n",
        "  clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "else:\n",
        "  clamp_index_variation = clamp_index\n",
        "score_corrector = DotMap()\n",
        "\n",
        "\n",
        "def modify_score(e_t, e_t_uncond):\n",
        "        if(score_modifier is False):\n",
        "          return e_t\n",
        "        else:\n",
        "          e_t_d = (e_t - e_t_uncond)\n",
        "          s = torch.quantile(\n",
        "              rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "              threshold_percentile,\n",
        "              dim = -1\n",
        "          )\n",
        "\n",
        "        s.clamp_(min = 1.)\n",
        "        s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "        if ths_method == \"softsign\":\n",
        "            e_t_d = F.softsign(e_t_d) / s \n",
        "        elif ths_method == \"clamp\":\n",
        "            e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "        e_t = e_t_uncond + e_t_d\n",
        "        return(e_t)\n",
        "          \n",
        "score_corrector.modify_score = modify_score\n",
        "\n",
        "def dynamic_thresholding(pred_x0,t):\n",
        "    return(pred_x0)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "generate_video = False\n",
        "if generate_video: \n",
        "    fps = 24\n",
        "    p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "do_run()\n",
        "if generate_video: \n",
        "    p.stdin.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "DH5r3NzJb3P8"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#@markdown ### **Run 4.** Basic settings\n",
        "\n",
        "width = 256 #@param{type: 'integer'}\n",
        "height = 512 #@param{type: 'integer'}\n",
        "\n",
        "clamp_index = [1.5, 2.0] #@param{type: 'raw'}\n",
        "\n",
        "latent_diffusion_guidance_scale = 6 #@param {type:\"number\"}\n",
        "clip_guidance_scale = 36000 #@param{type: 'integer'}\n",
        "\n",
        "how_many_batches = 1 #@param{type: 'integer'}\n",
        "aesthetic_loss_scale = 100 #@param{type: 'integer'}\n",
        "augment_cuts = True #@param{type:'boolean'}\n",
        "\n",
        "\n",
        "#@markdown\n",
        "\n",
        "#@markdown ### Custom saved settings\n",
        "#@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "custom_settings = '' #@param{type:'string'}\n",
        "settings_library = 'None (use settings defined above)' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "if(settings_library != 'None (use settings defined above)'):\n",
        "  custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "global_var_scope = globals()\n",
        "if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "  print('Loaded ', custom_settings)\n",
        "  try:\n",
        "    from configparser import ConfigParser\n",
        "  except ImportError:\n",
        "      from ConfigParser import ConfigParser\n",
        "  import configparser\n",
        "  \n",
        "  config = ConfigParser()\n",
        "  config.read(custom_settings)\n",
        "  #custom_settings_stream = fetch(custom_settings)\n",
        "  #Load CLIP models from config\n",
        "  if(config.has_section('clip_list')):\n",
        "    clip_incoming_list = config.items('clip_list')\n",
        "    clip_incoming_models = clip_incoming_list[0]\n",
        "    incoming_perceptors = eval(clip_incoming_models[1])\n",
        "    if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "      clip_load_list = incoming_perceptors\n",
        "      clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "  #Load settings from config and replace variables\n",
        "  if(config.has_section('basic_settings')):\n",
        "    basic_settings = config.items('basic_settings')\n",
        "    for basic_setting in basic_settings:\n",
        "      global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "  \n",
        "  if(config.has_section('advanced_settings')):\n",
        "    advanced_settings = config.items('advanced_settings')\n",
        "    for advanced_setting in advanced_settings:\n",
        "      global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "  custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "prompts = clip_prompts\n",
        "opt.prompt = latent_prompts\n",
        "opt.uc = latent_negatives\n",
        "custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "aes_scale = aesthetic_loss_scale\n",
        "try: \n",
        "  clip_guidance_schedule\n",
        "  clip_guidance_index = clip_guidance_schedule\n",
        "except:\n",
        "  clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "opt.W = (width//64)*64;\n",
        "opt.H = (height//64)*64;\n",
        "if opt.W != width or opt.H != height:\n",
        "    print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "opt.mag_mul = opt_mag_mul \n",
        "opt.ddim_eta = opt_ddim_eta\n",
        "opt.eta_end = opt_eta_end\n",
        "opt.temperature = opt_temperature\n",
        "opt.n_iter = how_many_batches\n",
        "opt.n_samples =  1\n",
        "opt.scale = latent_diffusion_guidance_scale\n",
        "opt.plms = opt_plms\n",
        "aug = augment_cuts\n",
        "\n",
        "#Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "if(len(clamp_index) == 2): \n",
        "  clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "else:\n",
        "  clamp_index_variation = clamp_index\n",
        "score_corrector = DotMap()\n",
        "\n",
        "\n",
        "def modify_score(e_t, e_t_uncond):\n",
        "        if(score_modifier is False):\n",
        "          return e_t\n",
        "        else:\n",
        "          e_t_d = (e_t - e_t_uncond)\n",
        "          s = torch.quantile(\n",
        "              rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "              threshold_percentile,\n",
        "              dim = -1\n",
        "          )\n",
        "\n",
        "        s.clamp_(min = 1.)\n",
        "        s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "        if ths_method == \"softsign\":\n",
        "            e_t_d = F.softsign(e_t_d) / s \n",
        "        elif ths_method == \"clamp\":\n",
        "            e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "        e_t = e_t_uncond + e_t_d\n",
        "        return(e_t)\n",
        "          \n",
        "score_corrector.modify_score = modify_score\n",
        "\n",
        "def dynamic_thresholding(pred_x0,t):\n",
        "    return(pred_x0)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "generate_video = False\n",
        "if generate_video: \n",
        "    fps = 24\n",
        "    p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "do_run()\n",
        "if generate_video: \n",
        "    p.stdin.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "qnxQppe_b3P9"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#@markdown ### **Run 5.** Basic settings\n",
        "\n",
        "#@markdown We're still figuring out default settings. Experiment and <a href=\"https://huggingface.co/datasets/multimodalart/latent-majesty-diffusion-settings\">share your settings with us</a>.\n",
        "\n",
        "width = 512 #@param{type: 'integer'}\n",
        "height = 256 #@param{type: 'integer'}\n",
        "\n",
        "clamp_index = [2.1, 2.4] #@param{type: 'raw'}\n",
        "\n",
        "latent_diffusion_guidance_scale = 9 #@param {type:\"number\"}\n",
        "clip_guidance_scale = 16000 #@param{type: 'integer'}\n",
        "\n",
        "how_many_batches = 1#@param{type: 'integer'}\n",
        "aesthetic_loss_scale = 100 #@param{type: 'integer'}\n",
        "augment_cuts = True #@param{type:'boolean'}\n",
        "\n",
        "\n",
        "#@markdown\n",
        "\n",
        "#@markdown ### Custom saved settings\n",
        "#@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "custom_settings = '' #@param{type:'string'}\n",
        "settings_library = 'default' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "if(settings_library != 'None (use settings defined above)'):\n",
        "  custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "global_var_scope = globals()\n",
        "if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "  print('Loaded ', custom_settings)\n",
        "  try:\n",
        "    from configparser import ConfigParser\n",
        "  except ImportError:\n",
        "      from ConfigParser import ConfigParser\n",
        "  import configparser\n",
        "  \n",
        "  config = ConfigParser()\n",
        "  config.read(custom_settings)\n",
        "  #custom_settings_stream = fetch(custom_settings)\n",
        "  #Load CLIP models from config\n",
        "  if(config.has_section('clip_list')):\n",
        "    clip_incoming_list = config.items('clip_list')\n",
        "    clip_incoming_models = clip_incoming_list[0]\n",
        "    incoming_perceptors = eval(clip_incoming_models[1])\n",
        "    if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "      clip_load_list = incoming_perceptors\n",
        "      clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "  #Load settings from config and replace variables\n",
        "  if(config.has_section('basic_settings')):\n",
        "    basic_settings = config.items('basic_settings')\n",
        "    for basic_setting in basic_settings:\n",
        "      global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "  \n",
        "  if(config.has_section('advanced_settings')):\n",
        "    advanced_settings = config.items('advanced_settings')\n",
        "    for advanced_setting in advanced_settings:\n",
        "      global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "  custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "prompts = clip_prompts\n",
        "opt.prompt = latent_prompts\n",
        "opt.uc = latent_negatives\n",
        "custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "aes_scale = aesthetic_loss_scale\n",
        "try: \n",
        "  clip_guidance_schedule\n",
        "  clip_guidance_index = clip_guidance_schedule\n",
        "except:\n",
        "  clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "opt.W = (width//64)*64;\n",
        "opt.H = (height//64)*64;\n",
        "if opt.W != width or opt.H != height:\n",
        "    print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "opt.mag_mul = opt_mag_mul \n",
        "opt.ddim_eta = opt_ddim_eta\n",
        "opt.eta_end = opt_eta_end\n",
        "opt.temperature = opt_temperature\n",
        "opt.n_iter = how_many_batches\n",
        "opt.n_samples =  1\n",
        "opt.scale = latent_diffusion_guidance_scale\n",
        "opt.plms = opt_plms\n",
        "aug = augment_cuts\n",
        "\n",
        "#Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "if(len(clamp_index) == 2): \n",
        "  clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "else:\n",
        "  clamp_index_variation = clamp_index\n",
        "score_corrector = DotMap()\n",
        "\n",
        "\n",
        "def modify_score(e_t, e_t_uncond):\n",
        "        if(score_modifier is False):\n",
        "          return e_t\n",
        "        else:\n",
        "          e_t_d = (e_t - e_t_uncond)\n",
        "          s = torch.quantile(\n",
        "              rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "              threshold_percentile,\n",
        "              dim = -1\n",
        "          )\n",
        "\n",
        "        s.clamp_(min = 1.)\n",
        "        s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "        if ths_method == \"softsign\":\n",
        "            e_t_d = F.softsign(e_t_d) / s \n",
        "        elif ths_method == \"clamp\":\n",
        "            e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "        e_t = e_t_uncond + e_t_d\n",
        "        return(e_t)\n",
        "          \n",
        "score_corrector.modify_score = modify_score\n",
        "\n",
        "def dynamic_thresholding(pred_x0,t):\n",
        "    return(pred_x0)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "generate_video = False\n",
        "if generate_video: \n",
        "    fps = 24\n",
        "    p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "do_run()\n",
        "if generate_video: \n",
        "    p.stdin.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "v81FkQyQb3P9"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#@markdown ### **Run 6.** Basic Settings\n",
        "\n",
        "width = 256 #@param{type: 'integer'}\n",
        "height = 384 #@param{type: 'integer'}\n",
        "\n",
        "clamp_index = [2.4, 2.1] #@param{type: 'raw'}\n",
        "\n",
        "latent_diffusion_guidance_scale = 15 #@param {type:\"number\"}\n",
        "clip_guidance_scale = 20000 #@param{type: 'integer'}\n",
        "\n",
        "how_many_batches = 1 #@param{type: 'integer'}\n",
        "aesthetic_loss_scale = 100 #@param{type: 'integer'}\n",
        "augment_cuts = True #@param{type:'boolean'}\n",
        "\n",
        "\n",
        "#@markdown\n",
        "\n",
        "#@markdown ### Custom saved settings\n",
        "#@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "custom_settings = '' #@param{type:'string'}\n",
        "settings_library = 'default' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "if(settings_library != 'None (use settings defined above)'):\n",
        "  custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "global_var_scope = globals()\n",
        "if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "  print('Loaded ', custom_settings)\n",
        "  try:\n",
        "    from configparser import ConfigParser\n",
        "  except ImportError:\n",
        "      from ConfigParser import ConfigParser\n",
        "  import configparser\n",
        "  \n",
        "  config = ConfigParser()\n",
        "  config.read(custom_settings)\n",
        "  #custom_settings_stream = fetch(custom_settings)\n",
        "  #Load CLIP models from config\n",
        "  if(config.has_section('clip_list')):\n",
        "    clip_incoming_list = config.items('clip_list')\n",
        "    clip_incoming_models = clip_incoming_list[0]\n",
        "    incoming_perceptors = eval(clip_incoming_models[1])\n",
        "    if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "      clip_load_list = incoming_perceptors\n",
        "      clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "  #Load settings from config and replace variables\n",
        "  if(config.has_section('basic_settings')):\n",
        "    basic_settings = config.items('basic_settings')\n",
        "    for basic_setting in basic_settings:\n",
        "      global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "  \n",
        "  if(config.has_section('advanced_settings')):\n",
        "    advanced_settings = config.items('advanced_settings')\n",
        "    for advanced_setting in advanced_settings:\n",
        "      global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "  custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "prompts = clip_prompts\n",
        "opt.prompt = latent_prompts\n",
        "opt.uc = latent_negatives\n",
        "custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "aes_scale = aesthetic_loss_scale\n",
        "try: \n",
        "  clip_guidance_schedule\n",
        "  clip_guidance_index = clip_guidance_schedule\n",
        "except:\n",
        "  clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "opt.W = (width//64)*64;\n",
        "opt.H = (height//64)*64;\n",
        "if opt.W != width or opt.H != height:\n",
        "    print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "opt.mag_mul = opt_mag_mul \n",
        "opt.ddim_eta = opt_ddim_eta\n",
        "opt.eta_end = opt_eta_end\n",
        "opt.temperature = opt_temperature\n",
        "opt.n_iter = how_many_batches\n",
        "opt.n_samples =  1\n",
        "opt.scale = latent_diffusion_guidance_scale\n",
        "opt.plms = opt_plms\n",
        "aug = augment_cuts\n",
        "\n",
        "#Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "if(len(clamp_index) == 2): \n",
        "  clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "else:\n",
        "  clamp_index_variation = clamp_index\n",
        "score_corrector = DotMap()\n",
        "\n",
        "\n",
        "def modify_score(e_t, e_t_uncond):\n",
        "        if(score_modifier is False):\n",
        "          return e_t\n",
        "        else:\n",
        "          e_t_d = (e_t - e_t_uncond)\n",
        "          s = torch.quantile(\n",
        "              rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "              threshold_percentile,\n",
        "              dim = -1\n",
        "          )\n",
        "\n",
        "        s.clamp_(min = 1.)\n",
        "        s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "        if ths_method == \"softsign\":\n",
        "            e_t_d = F.softsign(e_t_d) / s \n",
        "        elif ths_method == \"clamp\":\n",
        "            e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "        e_t = e_t_uncond + e_t_d\n",
        "        return(e_t)\n",
        "          \n",
        "score_corrector.modify_score = modify_score\n",
        "\n",
        "def dynamic_thresholding(pred_x0,t):\n",
        "    return(pred_x0)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "generate_video = False\n",
        "if generate_video: \n",
        "    fps = 24\n",
        "    p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "do_run()\n",
        "if generate_video: \n",
        "    p.stdin.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "HVkB131rb3P9"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#@markdown ### **Run 7.** Basic Settings\n",
        "\n",
        "width = 384 #@param{type: 'integer'}\n",
        "height = 384 #@param{type: 'integer'}\n",
        "\n",
        "clamp_index = [0.6, 0.6] #@param{type: 'raw'}\n",
        "\n",
        "latent_diffusion_guidance_scale = 11 #@param {type:\"number\"}\n",
        "clip_guidance_scale = 39999 #@param{type: 'integer'}\n",
        "\n",
        "how_many_batches = 1 #@param{type: 'integer'}\n",
        "aesthetic_loss_scale = 100 #@param{type: 'integer'}\n",
        "augment_cuts = True #@param{type:'boolean'}\n",
        "\n",
        "\n",
        "#@markdown ### Custom saved settings\n",
        "#@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "custom_settings = '' #@param{type:'string'}\n",
        "settings_library = 'coherent_pizzapigeon' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "if(settings_library != 'None (use settings defined above)'):\n",
        "  custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "global_var_scope = globals()\n",
        "if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "  print('Loaded ', custom_settings)\n",
        "  try:\n",
        "    from configparser import ConfigParser\n",
        "  except ImportError:\n",
        "      from ConfigParser import ConfigParser\n",
        "  import configparser\n",
        "  \n",
        "  config = ConfigParser()\n",
        "  config.read(custom_settings)\n",
        "  #custom_settings_stream = fetch(custom_settings)\n",
        "  #Load CLIP models from config\n",
        "  if(config.has_section('clip_list')):\n",
        "    clip_incoming_list = config.items('clip_list')\n",
        "    clip_incoming_models = clip_incoming_list[0]\n",
        "    incoming_perceptors = eval(clip_incoming_models[1])\n",
        "    if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "      clip_load_list = incoming_perceptors\n",
        "      clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "  #Load settings from config and replace variables\n",
        "  if(config.has_section('basic_settings')):\n",
        "    basic_settings = config.items('basic_settings')\n",
        "    for basic_setting in basic_settings:\n",
        "      global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "  \n",
        "  if(config.has_section('advanced_settings')):\n",
        "    advanced_settings = config.items('advanced_settings')\n",
        "    for advanced_setting in advanced_settings:\n",
        "      global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "  custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "prompts = clip_prompts\n",
        "opt.prompt = latent_prompts\n",
        "opt.uc = latent_negatives\n",
        "custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "aes_scale = aesthetic_loss_scale\n",
        "try: \n",
        "  clip_guidance_schedule\n",
        "  clip_guidance_index = clip_guidance_schedule\n",
        "except:\n",
        "  clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "opt.W = (width//64)*64;\n",
        "opt.H = (height//64)*64;\n",
        "if opt.W != width or opt.H != height:\n",
        "    print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "opt.mag_mul = opt_mag_mul \n",
        "opt.ddim_eta = opt_ddim_eta\n",
        "opt.eta_end = opt_eta_end\n",
        "opt.temperature = opt_temperature\n",
        "opt.n_iter = how_many_batches\n",
        "opt.n_samples =  1\n",
        "opt.scale = latent_diffusion_guidance_scale\n",
        "opt.plms = opt_plms\n",
        "aug = augment_cuts\n",
        "\n",
        "#Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "if(len(clamp_index) == 2): \n",
        "  clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "else:\n",
        "  clamp_index_variation = clamp_index\n",
        "score_corrector = DotMap()\n",
        "\n",
        "\n",
        "def modify_score(e_t, e_t_uncond):\n",
        "        if(score_modifier is False):\n",
        "          return e_t\n",
        "        else:\n",
        "          e_t_d = (e_t - e_t_uncond)\n",
        "          s = torch.quantile(\n",
        "              rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "              threshold_percentile,\n",
        "              dim = -1\n",
        "          )\n",
        "\n",
        "        s.clamp_(min = 1.)\n",
        "        s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "        if ths_method == \"softsign\":\n",
        "            e_t_d = F.softsign(e_t_d) / s \n",
        "        elif ths_method == \"clamp\":\n",
        "            e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "        e_t = e_t_uncond + e_t_d\n",
        "        return(e_t)\n",
        "          \n",
        "score_corrector.modify_score = modify_score\n",
        "\n",
        "def dynamic_thresholding(pred_x0,t):\n",
        "    return(pred_x0)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "generate_video = False\n",
        "if generate_video: \n",
        "    fps = 24\n",
        "    p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "do_run()\n",
        "if generate_video: \n",
        "    p.stdin.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ILRvlbnbb3P-"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#@markdown ### **Run 8.** Basic Settings\n",
        "\n",
        "width =  256#@param{type: 'integer'}\n",
        "height =  384#@param{type: 'integer'}\n",
        "\n",
        "clamp_index = [1, 1] #@param{type: 'raw'}\n",
        "\n",
        "latent_diffusion_guidance_scale = 10 #@param {type:\"number\"}\n",
        "clip_guidance_scale =  50000#@param{type: 'integer'}\n",
        "\n",
        "how_many_batches =  1#@param{type: 'integer'}\n",
        "\n",
        "aesthetic_loss_scale = 100 #@param{type: 'integer'}\n",
        "augment_cuts=True #@param{type:'boolean'}\n",
        "\n",
        "\n",
        "#@markdown ### Custom saved settings\n",
        "#@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "custom_settings = '' #@param{type:'string'}\n",
        "settings_library = 'coherent_pizzapigeon' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "if(settings_library != 'None (use settings defined above)'):\n",
        "  custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "global_var_scope = globals()\n",
        "if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "  print('Loaded ', custom_settings)\n",
        "  try:\n",
        "    from configparser import ConfigParser\n",
        "  except ImportError:\n",
        "      from ConfigParser import ConfigParser\n",
        "  import configparser\n",
        "  \n",
        "  config = ConfigParser()\n",
        "  config.read(custom_settings)\n",
        "  #custom_settings_stream = fetch(custom_settings)\n",
        "  #Load CLIP models from config\n",
        "  if(config.has_section('clip_list')):\n",
        "    clip_incoming_list = config.items('clip_list')\n",
        "    clip_incoming_models = clip_incoming_list[0]\n",
        "    incoming_perceptors = eval(clip_incoming_models[1])\n",
        "    if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "      clip_load_list = incoming_perceptors\n",
        "      clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "  #Load settings from config and replace variables\n",
        "  if(config.has_section('basic_settings')):\n",
        "    basic_settings = config.items('basic_settings')\n",
        "    for basic_setting in basic_settings:\n",
        "      global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "  \n",
        "  if(config.has_section('advanced_settings')):\n",
        "    advanced_settings = config.items('advanced_settings')\n",
        "    for advanced_setting in advanced_settings:\n",
        "      global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "  custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "prompts = clip_prompts\n",
        "opt.prompt = latent_prompts\n",
        "opt.uc = latent_negatives\n",
        "custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "aes_scale = aesthetic_loss_scale\n",
        "try: \n",
        "  clip_guidance_schedule\n",
        "  clip_guidance_index = clip_guidance_schedule\n",
        "except:\n",
        "  clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "opt.W = (width//64)*64;\n",
        "opt.H = (height//64)*64;\n",
        "if opt.W != width or opt.H != height:\n",
        "    print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "opt.mag_mul = opt_mag_mul \n",
        "opt.ddim_eta = opt_ddim_eta\n",
        "opt.eta_end = opt_eta_end\n",
        "opt.temperature = opt_temperature\n",
        "opt.n_iter = how_many_batches\n",
        "opt.n_samples =  1\n",
        "opt.scale = latent_diffusion_guidance_scale\n",
        "opt.plms = opt_plms\n",
        "aug = augment_cuts\n",
        "\n",
        "#Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "if(len(clamp_index) == 2): \n",
        "  clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "else:\n",
        "  clamp_index_variation = clamp_index\n",
        "score_corrector = DotMap()\n",
        "\n",
        "\n",
        "def modify_score(e_t, e_t_uncond):\n",
        "        if(score_modifier is False):\n",
        "          return e_t\n",
        "        else:\n",
        "          e_t_d = (e_t - e_t_uncond)\n",
        "          s = torch.quantile(\n",
        "              rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "              threshold_percentile,\n",
        "              dim = -1\n",
        "          )\n",
        "\n",
        "        s.clamp_(min = 1.)\n",
        "        s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "        if ths_method == \"softsign\":\n",
        "            e_t_d = F.softsign(e_t_d) / s \n",
        "        elif ths_method == \"clamp\":\n",
        "            e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "        e_t = e_t_uncond + e_t_d\n",
        "        return(e_t)\n",
        "          \n",
        "score_corrector.modify_score = modify_score\n",
        "\n",
        "def dynamic_thresholding(pred_x0,t):\n",
        "    return(pred_x0)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "generate_video = False\n",
        "if generate_video: \n",
        "    fps = 24\n",
        "    p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "do_run()\n",
        "if generate_video: \n",
        "    p.stdin.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "AXQ_WxILb3P-"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#@markdown ### **Run 9.** Basic Settings\n",
        "\n",
        "width = 384 #@param{type: 'integer'}\n",
        "height = 256 #@param{type: 'integer'}\n",
        "\n",
        "clamp_index = [1, 1] #@param{type: 'raw'}\n",
        "\n",
        "latent_diffusion_guidance_scale = 13 #@param {type:\"number\"}\n",
        "clip_guidance_scale = 24000 #@param{type: 'integer'}\n",
        "\n",
        "how_many_batches =  1#@param{type: 'integer'}\n",
        "aesthetic_loss_scale =  1#@param{type: 'integer'}\n",
        "augment_cuts = True #@param{type:'boolean'}\n",
        "\n",
        "\n",
        "#@markdown ### Custom saved settings\n",
        "#@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "custom_settings = '' #@param{type:'string'}\n",
        "settings_library = 'makeitrad_defaults' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "if(settings_library != 'None (use settings defined above)'):\n",
        "  custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "global_var_scope = globals()\n",
        "if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "  print('Loaded ', custom_settings)\n",
        "  try:\n",
        "    from configparser import ConfigParser\n",
        "  except ImportError:\n",
        "      from ConfigParser import ConfigParser\n",
        "  import configparser\n",
        "  \n",
        "  config = ConfigParser()\n",
        "  config.read(custom_settings)\n",
        "  #custom_settings_stream = fetch(custom_settings)\n",
        "  #Load CLIP models from config\n",
        "  if(config.has_section('clip_list')):\n",
        "    clip_incoming_list = config.items('clip_list')\n",
        "    clip_incoming_models = clip_incoming_list[0]\n",
        "    incoming_perceptors = eval(clip_incoming_models[1])\n",
        "    if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "      clip_load_list = incoming_perceptors\n",
        "      clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "  #Load settings from config and replace variables\n",
        "  if(config.has_section('basic_settings')):\n",
        "    basic_settings = config.items('basic_settings')\n",
        "    for basic_setting in basic_settings:\n",
        "      global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "  \n",
        "  if(config.has_section('advanced_settings')):\n",
        "    advanced_settings = config.items('advanced_settings')\n",
        "    for advanced_setting in advanced_settings:\n",
        "      global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "  custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "prompts = clip_prompts\n",
        "opt.prompt = latent_prompts\n",
        "opt.uc = latent_negatives\n",
        "custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "aes_scale = aesthetic_loss_scale\n",
        "try: \n",
        "  clip_guidance_schedule\n",
        "  clip_guidance_index = clip_guidance_schedule\n",
        "except:\n",
        "  clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "opt.W = (width//64)*64;\n",
        "opt.H = (height//64)*64;\n",
        "if opt.W != width or opt.H != height:\n",
        "    print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "opt.mag_mul = opt_mag_mul \n",
        "opt.ddim_eta = opt_ddim_eta\n",
        "opt.eta_end = opt_eta_end\n",
        "opt.temperature = opt_temperature\n",
        "opt.n_iter = how_many_batches\n",
        "opt.n_samples =  1\n",
        "opt.scale = latent_diffusion_guidance_scale\n",
        "opt.plms = opt_plms\n",
        "aug = augment_cuts\n",
        "\n",
        "#Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "if(len(clamp_index) == 2): \n",
        "  clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "else:\n",
        "  clamp_index_variation = clamp_index\n",
        "score_corrector = DotMap()\n",
        "\n",
        "\n",
        "def modify_score(e_t, e_t_uncond):\n",
        "        if(score_modifier is False):\n",
        "          return e_t\n",
        "        else:\n",
        "          e_t_d = (e_t - e_t_uncond)\n",
        "          s = torch.quantile(\n",
        "              rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "              threshold_percentile,\n",
        "              dim = -1\n",
        "          )\n",
        "\n",
        "        s.clamp_(min = 1.)\n",
        "        s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "        if ths_method == \"softsign\":\n",
        "            e_t_d = F.softsign(e_t_d) / s \n",
        "        elif ths_method == \"clamp\":\n",
        "            e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "        e_t = e_t_uncond + e_t_d\n",
        "        return(e_t)\n",
        "          \n",
        "score_corrector.modify_score = modify_score\n",
        "\n",
        "def dynamic_thresholding(pred_x0,t):\n",
        "    return(pred_x0)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "generate_video = False\n",
        "if generate_video: \n",
        "    fps = 24\n",
        "    p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "do_run()\n",
        "if generate_video: \n",
        "    p.stdin.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "hiuS7MvXb3P-"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#@markdown ### **Run 10.** Basic Settings\n",
        "\n",
        "width = 256 #@param{type: 'integer'}\n",
        "height = 384 #@param{type: 'integer'}\n",
        "\n",
        "clamp_index = [1, 1] #@param{type: 'raw'}\n",
        "\n",
        "latent_diffusion_guidance_scale = 14 #@param {type:\"number\"}\n",
        "clip_guidance_scale = 8000 #@param{type: 'integer'}\n",
        "\n",
        "how_many_batches = 1 #@param{type: 'integer'}\n",
        "aesthetic_loss_scale = 10 #@param{type: 'integer'}\n",
        "augment_cuts = True #@param{type:'boolean'}\n",
        "\n",
        "\n",
        "#@markdown ### Custom saved settings\n",
        "#@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "custom_settings = '' #@param{type:'string'}\n",
        "settings_library = 'makeitrad_defaults' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "if(settings_library != 'None (use settings defined above)'):\n",
        "  custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "global_var_scope = globals()\n",
        "if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "  print('Loaded ', custom_settings)\n",
        "  try:\n",
        "    from configparser import ConfigParser\n",
        "  except ImportError:\n",
        "      from ConfigParser import ConfigParser\n",
        "  import configparser\n",
        "  \n",
        "  config = ConfigParser()\n",
        "  config.read(custom_settings)\n",
        "  #custom_settings_stream = fetch(custom_settings)\n",
        "  #Load CLIP models from config\n",
        "  if(config.has_section('clip_list')):\n",
        "    clip_incoming_list = config.items('clip_list')\n",
        "    clip_incoming_models = clip_incoming_list[0]\n",
        "    incoming_perceptors = eval(clip_incoming_models[1])\n",
        "    if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "      clip_load_list = incoming_perceptors\n",
        "      clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "  #Load settings from config and replace variables\n",
        "  if(config.has_section('basic_settings')):\n",
        "    basic_settings = config.items('basic_settings')\n",
        "    for basic_setting in basic_settings:\n",
        "      global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "  \n",
        "  if(config.has_section('advanced_settings')):\n",
        "    advanced_settings = config.items('advanced_settings')\n",
        "    for advanced_setting in advanced_settings:\n",
        "      global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "  custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "prompts = clip_prompts\n",
        "opt.prompt = latent_prompts\n",
        "opt.uc = latent_negatives\n",
        "custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "aes_scale = aesthetic_loss_scale\n",
        "try: \n",
        "  clip_guidance_schedule\n",
        "  clip_guidance_index = clip_guidance_schedule\n",
        "except:\n",
        "  clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "opt.W = (width//64)*64;\n",
        "opt.H = (height//64)*64;\n",
        "if opt.W != width or opt.H != height:\n",
        "    print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "opt.mag_mul = opt_mag_mul \n",
        "opt.ddim_eta = opt_ddim_eta\n",
        "opt.eta_end = opt_eta_end\n",
        "opt.temperature = opt_temperature\n",
        "opt.n_iter = how_many_batches\n",
        "opt.n_samples =  1\n",
        "opt.scale = latent_diffusion_guidance_scale\n",
        "opt.plms = opt_plms\n",
        "aug = augment_cuts\n",
        "\n",
        "#Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "if(len(clamp_index) == 2): \n",
        "  clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "else:\n",
        "  clamp_index_variation = clamp_index\n",
        "score_corrector = DotMap()\n",
        "\n",
        "\n",
        "def modify_score(e_t, e_t_uncond):\n",
        "        if(score_modifier is False):\n",
        "          return e_t\n",
        "        else:\n",
        "          e_t_d = (e_t - e_t_uncond)\n",
        "          s = torch.quantile(\n",
        "              rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "              threshold_percentile,\n",
        "              dim = -1\n",
        "          )\n",
        "\n",
        "        s.clamp_(min = 1.)\n",
        "        s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "        if ths_method == \"softsign\":\n",
        "            e_t_d = F.softsign(e_t_d) / s \n",
        "        elif ths_method == \"clamp\":\n",
        "            e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "        e_t = e_t_uncond + e_t_d\n",
        "        return(e_t)\n",
        "          \n",
        "score_corrector.modify_score = modify_score\n",
        "\n",
        "def dynamic_thresholding(pred_x0,t):\n",
        "    return(pred_x0)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "generate_video = False\n",
        "if generate_video: \n",
        "    fps = 24\n",
        "    p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "do_run()\n",
        "if generate_video: \n",
        "    p.stdin.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uTfUl4Fb3dz"
      },
      "source": [
        "### 𝗗ᴇᴋᴀ-𝗕ᴀᴛᴄʜ 𝗥ᴜɴ 𝗖ᴇʟʟ𝘀 **X5** - Schoolgirl"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "init_image = \"https://i.imgur.com/xisRRPZ.jpg\" #@param{type: 'string'}\n",
        "if(init_image == '' or init_image == 'None'):\n",
        "  init_image = None\n",
        "\n",
        "#default 0.9\n",
        "starting_timestep = 0.0 #@param{type: 'number'}\n",
        "\n",
        "init_mask = None #@param{type: 'string'}\n",
        "\n",
        "init_scale = 5000 #@param{type: 'integer'}\n",
        "\n",
        "#default 0.0\n",
        "init_brightness = 0.0 #@param{type: 'number'}\n",
        "\n",
        "#default 0.57\n",
        "init_noise = 0.0 #@param{type: 'number'}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "uf2eEl7Xb3dz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "AYjzSA7vb3dz"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#@markdown ### **Run 1.** Basic settings\n",
        "\n",
        "#@markdown We're still figuring out default settings. Experiment and <a href=\"https://huggingface.co/datasets/multimodalart/latent-majesty-diffusion-settings\">share your settings with us</a>.\n",
        "\n",
        "#@markdown ✦✦ TO DO: Add init image cut schedule toggle, init and config skip toggles. ✦✦\n",
        "\n",
        "width = 256 #@param{type: 'integer'}\n",
        "height = 384 #@param{type: 'integer'}\n",
        "\n",
        "clamp_index = [2.4, 2.1] #@param{type: 'raw'}\n",
        "\n",
        "latent_diffusion_guidance_scale = 12 #@param {type:\"number\"}\n",
        "clip_guidance_scale = 12000 #@param{type: 'integer'}\n",
        "\n",
        "how_many_batches = 1 #@param{type: 'integer'}\n",
        "\n",
        "aesthetic_loss_scale = 100 #@param{type: 'integer'}\n",
        "augment_cuts = True #@param{type:'boolean'}\n",
        "\n",
        "\n",
        "#@markdown ### Custom saved settings\n",
        "#@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "custom_settings = '' #@param{type:'string'}\n",
        "settings_library = 'None (use settings defined above)' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "if(settings_library != 'None (use settings defined above)'):\n",
        "  custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "global_var_scope = globals()\n",
        "if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "  print('Loaded ', custom_settings)\n",
        "  try:\n",
        "    from configparser import ConfigParser\n",
        "  except ImportError:\n",
        "      from ConfigParser import ConfigParser\n",
        "  import configparser\n",
        "  \n",
        "  config = ConfigParser()\n",
        "  config.read(custom_settings)\n",
        "  #custom_settings_stream = fetch(custom_settings)\n",
        "  #Load CLIP models from config\n",
        "  if(config.has_section('clip_list')):\n",
        "    clip_incoming_list = config.items('clip_list')\n",
        "    clip_incoming_models = clip_incoming_list[0]\n",
        "    incoming_perceptors = eval(clip_incoming_models[1])\n",
        "    if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "      clip_load_list = incoming_perceptors\n",
        "      clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "  #Load settings from config and replace variables\n",
        "  if(config.has_section('basic_settings')):\n",
        "    basic_settings = config.items('basic_settings')\n",
        "    for basic_setting in basic_settings:\n",
        "      global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "  \n",
        "  if(config.has_section('advanced_settings')):\n",
        "    advanced_settings = config.items('advanced_settings')\n",
        "    for advanced_setting in advanced_settings:\n",
        "      global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "  custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "prompts = clip_prompts\n",
        "opt.prompt = latent_prompts\n",
        "opt.uc = latent_negatives\n",
        "custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "aes_scale = aesthetic_loss_scale\n",
        "try: \n",
        "  clip_guidance_schedule\n",
        "  clip_guidance_index = clip_guidance_schedule\n",
        "except:\n",
        "  clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "opt.W = (width//64)*64;\n",
        "opt.H = (height//64)*64;\n",
        "if opt.W != width or opt.H != height:\n",
        "    print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "opt.mag_mul = opt_mag_mul \n",
        "opt.ddim_eta = opt_ddim_eta\n",
        "opt.eta_end = opt_eta_end\n",
        "opt.temperature = opt_temperature\n",
        "opt.n_iter = how_many_batches\n",
        "opt.n_samples =  1\n",
        "opt.scale = latent_diffusion_guidance_scale\n",
        "opt.plms = opt_plms\n",
        "aug = augment_cuts\n",
        "\n",
        "#Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "if(len(clamp_index) == 2): \n",
        "  clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "else:\n",
        "  clamp_index_variation = clamp_index\n",
        "score_corrector = DotMap()\n",
        "\n",
        "\n",
        "def modify_score(e_t, e_t_uncond):\n",
        "        if(score_modifier is False):\n",
        "          return e_t\n",
        "        else:\n",
        "          e_t_d = (e_t - e_t_uncond)\n",
        "          s = torch.quantile(\n",
        "              rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "              threshold_percentile,\n",
        "              dim = -1\n",
        "          )\n",
        "\n",
        "        s.clamp_(min = 1.)\n",
        "        s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "        if ths_method == \"softsign\":\n",
        "            e_t_d = F.softsign(e_t_d) / s \n",
        "        elif ths_method == \"clamp\":\n",
        "            e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "        e_t = e_t_uncond + e_t_d\n",
        "        return(e_t)\n",
        "          \n",
        "score_corrector.modify_score = modify_score\n",
        "\n",
        "def dynamic_thresholding(pred_x0,t):\n",
        "    return(pred_x0)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "generate_video = False\n",
        "if generate_video: \n",
        "    fps = 24\n",
        "    p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "do_run()\n",
        "if generate_video: \n",
        "    p.stdin.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "LG0Vl3A7b3d0"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#@markdown ### **Run 2.** Basic settings\n",
        "\n",
        "width = 256 #@param{type: 'integer'}\n",
        "height = 384 #@param{type: 'integer'}\n",
        "\n",
        "clamp_index = [2.1, 2.4] #@param{type: 'raw'}\n",
        "\n",
        "latent_diffusion_guidance_scale = 15 #@param {type:\"number\"}\n",
        "clip_guidance_scale = 50000 #@param{type: 'integer'}\n",
        "\n",
        "how_many_batches = 1 #@param{type: 'integer'}\n",
        "\n",
        "aesthetic_loss_scale = 200 #@param{type: 'integer'}\n",
        "augment_cuts = True #@param{type:'boolean'}\n",
        "\n",
        "\n",
        "#@markdown ### Custom saved settings\n",
        "#@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "custom_settings = '' #@param{type:'string'}\n",
        "settings_library = 'None (use settings defined above)' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "if(settings_library != 'None (use settings defined above)'):\n",
        "  custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "global_var_scope = globals()\n",
        "if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "  print('Loaded ', custom_settings)\n",
        "  try:\n",
        "    from configparser import ConfigParser\n",
        "  except ImportError:\n",
        "      from ConfigParser import ConfigParser\n",
        "  import configparser\n",
        "  \n",
        "  config = ConfigParser()\n",
        "  config.read(custom_settings)\n",
        "  #custom_settings_stream = fetch(custom_settings)\n",
        "  #Load CLIP models from config\n",
        "  if(config.has_section('clip_list')):\n",
        "    clip_incoming_list = config.items('clip_list')\n",
        "    clip_incoming_models = clip_incoming_list[0]\n",
        "    incoming_perceptors = eval(clip_incoming_models[1])\n",
        "    if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "      clip_load_list = incoming_perceptors\n",
        "      clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "  #Load settings from config and replace variables\n",
        "  if(config.has_section('basic_settings')):\n",
        "    basic_settings = config.items('basic_settings')\n",
        "    for basic_setting in basic_settings:\n",
        "      global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "  \n",
        "  if(config.has_section('advanced_settings')):\n",
        "    advanced_settings = config.items('advanced_settings')\n",
        "    for advanced_setting in advanced_settings:\n",
        "      global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "  custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "prompts = clip_prompts\n",
        "opt.prompt = latent_prompts\n",
        "opt.uc = latent_negatives\n",
        "custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "aes_scale = aesthetic_loss_scale\n",
        "try: \n",
        "  clip_guidance_schedule\n",
        "  clip_guidance_index = clip_guidance_schedule\n",
        "except:\n",
        "  clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "opt.W = (width//64)*64;\n",
        "opt.H = (height//64)*64;\n",
        "if opt.W != width or opt.H != height:\n",
        "    print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "opt.mag_mul = opt_mag_mul \n",
        "opt.ddim_eta = opt_ddim_eta\n",
        "opt.eta_end = opt_eta_end\n",
        "opt.temperature = opt_temperature\n",
        "opt.n_iter = how_many_batches\n",
        "opt.n_samples =  1\n",
        "opt.scale = latent_diffusion_guidance_scale\n",
        "opt.plms = opt_plms\n",
        "aug = augment_cuts\n",
        "\n",
        "#Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "if(len(clamp_index) == 2): \n",
        "  clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "else:\n",
        "  clamp_index_variation = clamp_index\n",
        "score_corrector = DotMap()\n",
        "\n",
        "\n",
        "def modify_score(e_t, e_t_uncond):\n",
        "        if(score_modifier is False):\n",
        "          return e_t\n",
        "        else:\n",
        "          e_t_d = (e_t - e_t_uncond)\n",
        "          s = torch.quantile(\n",
        "              rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "              threshold_percentile,\n",
        "              dim = -1\n",
        "          )\n",
        "\n",
        "        s.clamp_(min = 1.)\n",
        "        s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "        if ths_method == \"softsign\":\n",
        "            e_t_d = F.softsign(e_t_d) / s \n",
        "        elif ths_method == \"clamp\":\n",
        "            e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "        e_t = e_t_uncond + e_t_d\n",
        "        return(e_t)\n",
        "          \n",
        "score_corrector.modify_score = modify_score\n",
        "\n",
        "def dynamic_thresholding(pred_x0,t):\n",
        "    return(pred_x0)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "generate_video = False\n",
        "if generate_video: \n",
        "    fps = 24\n",
        "    p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "do_run()\n",
        "if generate_video: \n",
        "    p.stdin.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "0c4wnMx2b3d0"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#@markdown ### **Run 3.** Basic settings\n",
        "\n",
        "width = 512 #@param{type: 'integer'}\n",
        "height = 256 #@param{type: 'integer'}\n",
        "\n",
        "clamp_index = [2.1, 2.1] #@param{type: 'raw'}\n",
        "\n",
        "latent_diffusion_guidance_scale = 12 #@param {type:\"number\"}\n",
        "clip_guidance_scale = 50000 #@param{type: 'integer'}\n",
        "\n",
        "how_many_batches = 1 #@param{type: 'integer'}\n",
        "\n",
        "aesthetic_loss_scale = 200 #@param{type: 'integer'}\n",
        "augment_cuts = True #@param{type:'boolean'}\n",
        "\n",
        "\n",
        "#@markdown ### Custom saved settings\n",
        "#@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "custom_settings = '' #@param{type:'string'}\n",
        "settings_library = 'None (use settings defined above)' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "if(settings_library != 'None (use settings defined above)'):\n",
        "  custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "global_var_scope = globals()\n",
        "if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "  print('Loaded ', custom_settings)\n",
        "  try:\n",
        "    from configparser import ConfigParser\n",
        "  except ImportError:\n",
        "      from ConfigParser import ConfigParser\n",
        "  import configparser\n",
        "  \n",
        "  config = ConfigParser()\n",
        "  config.read(custom_settings)\n",
        "  #custom_settings_stream = fetch(custom_settings)\n",
        "  #Load CLIP models from config\n",
        "  if(config.has_section('clip_list')):\n",
        "    clip_incoming_list = config.items('clip_list')\n",
        "    clip_incoming_models = clip_incoming_list[0]\n",
        "    incoming_perceptors = eval(clip_incoming_models[1])\n",
        "    if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "      clip_load_list = incoming_perceptors\n",
        "      clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "  #Load settings from config and replace variables\n",
        "  if(config.has_section('basic_settings')):\n",
        "    basic_settings = config.items('basic_settings')\n",
        "    for basic_setting in basic_settings:\n",
        "      global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "  \n",
        "  if(config.has_section('advanced_settings')):\n",
        "    advanced_settings = config.items('advanced_settings')\n",
        "    for advanced_setting in advanced_settings:\n",
        "      global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "  custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "prompts = clip_prompts\n",
        "opt.prompt = latent_prompts\n",
        "opt.uc = latent_negatives\n",
        "custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "aes_scale = aesthetic_loss_scale\n",
        "try: \n",
        "  clip_guidance_schedule\n",
        "  clip_guidance_index = clip_guidance_schedule\n",
        "except:\n",
        "  clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "opt.W = (width//64)*64;\n",
        "opt.H = (height//64)*64;\n",
        "if opt.W != width or opt.H != height:\n",
        "    print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "opt.mag_mul = opt_mag_mul \n",
        "opt.ddim_eta = opt_ddim_eta\n",
        "opt.eta_end = opt_eta_end\n",
        "opt.temperature = opt_temperature\n",
        "opt.n_iter = how_many_batches\n",
        "opt.n_samples =  1\n",
        "opt.scale = latent_diffusion_guidance_scale\n",
        "opt.plms = opt_plms\n",
        "aug = augment_cuts\n",
        "\n",
        "#Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "if(len(clamp_index) == 2): \n",
        "  clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "else:\n",
        "  clamp_index_variation = clamp_index\n",
        "score_corrector = DotMap()\n",
        "\n",
        "\n",
        "def modify_score(e_t, e_t_uncond):\n",
        "        if(score_modifier is False):\n",
        "          return e_t\n",
        "        else:\n",
        "          e_t_d = (e_t - e_t_uncond)\n",
        "          s = torch.quantile(\n",
        "              rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "              threshold_percentile,\n",
        "              dim = -1\n",
        "          )\n",
        "\n",
        "        s.clamp_(min = 1.)\n",
        "        s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "        if ths_method == \"softsign\":\n",
        "            e_t_d = F.softsign(e_t_d) / s \n",
        "        elif ths_method == \"clamp\":\n",
        "            e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "        e_t = e_t_uncond + e_t_d\n",
        "        return(e_t)\n",
        "          \n",
        "score_corrector.modify_score = modify_score\n",
        "\n",
        "def dynamic_thresholding(pred_x0,t):\n",
        "    return(pred_x0)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "generate_video = False\n",
        "if generate_video: \n",
        "    fps = 24\n",
        "    p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "do_run()\n",
        "if generate_video: \n",
        "    p.stdin.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "iEOGw1OJb3d0"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#@markdown ### **Run 4.** Basic settings\n",
        "\n",
        "width = 256 #@param{type: 'integer'}\n",
        "height = 512 #@param{type: 'integer'}\n",
        "\n",
        "clamp_index = [1.5, 2.0] #@param{type: 'raw'}\n",
        "\n",
        "latent_diffusion_guidance_scale = 6 #@param {type:\"number\"}\n",
        "clip_guidance_scale = 36000 #@param{type: 'integer'}\n",
        "\n",
        "how_many_batches = 1 #@param{type: 'integer'}\n",
        "aesthetic_loss_scale = 100 #@param{type: 'integer'}\n",
        "augment_cuts = True #@param{type:'boolean'}\n",
        "\n",
        "\n",
        "#@markdown\n",
        "\n",
        "#@markdown ### Custom saved settings\n",
        "#@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "custom_settings = '' #@param{type:'string'}\n",
        "settings_library = 'None (use settings defined above)' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "if(settings_library != 'None (use settings defined above)'):\n",
        "  custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "global_var_scope = globals()\n",
        "if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "  print('Loaded ', custom_settings)\n",
        "  try:\n",
        "    from configparser import ConfigParser\n",
        "  except ImportError:\n",
        "      from ConfigParser import ConfigParser\n",
        "  import configparser\n",
        "  \n",
        "  config = ConfigParser()\n",
        "  config.read(custom_settings)\n",
        "  #custom_settings_stream = fetch(custom_settings)\n",
        "  #Load CLIP models from config\n",
        "  if(config.has_section('clip_list')):\n",
        "    clip_incoming_list = config.items('clip_list')\n",
        "    clip_incoming_models = clip_incoming_list[0]\n",
        "    incoming_perceptors = eval(clip_incoming_models[1])\n",
        "    if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "      clip_load_list = incoming_perceptors\n",
        "      clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "  #Load settings from config and replace variables\n",
        "  if(config.has_section('basic_settings')):\n",
        "    basic_settings = config.items('basic_settings')\n",
        "    for basic_setting in basic_settings:\n",
        "      global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "  \n",
        "  if(config.has_section('advanced_settings')):\n",
        "    advanced_settings = config.items('advanced_settings')\n",
        "    for advanced_setting in advanced_settings:\n",
        "      global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "  custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "prompts = clip_prompts\n",
        "opt.prompt = latent_prompts\n",
        "opt.uc = latent_negatives\n",
        "custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "aes_scale = aesthetic_loss_scale\n",
        "try: \n",
        "  clip_guidance_schedule\n",
        "  clip_guidance_index = clip_guidance_schedule\n",
        "except:\n",
        "  clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "opt.W = (width//64)*64;\n",
        "opt.H = (height//64)*64;\n",
        "if opt.W != width or opt.H != height:\n",
        "    print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "opt.mag_mul = opt_mag_mul \n",
        "opt.ddim_eta = opt_ddim_eta\n",
        "opt.eta_end = opt_eta_end\n",
        "opt.temperature = opt_temperature\n",
        "opt.n_iter = how_many_batches\n",
        "opt.n_samples =  1\n",
        "opt.scale = latent_diffusion_guidance_scale\n",
        "opt.plms = opt_plms\n",
        "aug = augment_cuts\n",
        "\n",
        "#Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "if(len(clamp_index) == 2): \n",
        "  clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "else:\n",
        "  clamp_index_variation = clamp_index\n",
        "score_corrector = DotMap()\n",
        "\n",
        "\n",
        "def modify_score(e_t, e_t_uncond):\n",
        "        if(score_modifier is False):\n",
        "          return e_t\n",
        "        else:\n",
        "          e_t_d = (e_t - e_t_uncond)\n",
        "          s = torch.quantile(\n",
        "              rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "              threshold_percentile,\n",
        "              dim = -1\n",
        "          )\n",
        "\n",
        "        s.clamp_(min = 1.)\n",
        "        s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "        if ths_method == \"softsign\":\n",
        "            e_t_d = F.softsign(e_t_d) / s \n",
        "        elif ths_method == \"clamp\":\n",
        "            e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "        e_t = e_t_uncond + e_t_d\n",
        "        return(e_t)\n",
        "          \n",
        "score_corrector.modify_score = modify_score\n",
        "\n",
        "def dynamic_thresholding(pred_x0,t):\n",
        "    return(pred_x0)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "generate_video = False\n",
        "if generate_video: \n",
        "    fps = 24\n",
        "    p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "do_run()\n",
        "if generate_video: \n",
        "    p.stdin.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tQmPkzchb3d1"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#@markdown ### **Run 5.** Basic settings\n",
        "\n",
        "#@markdown We're still figuring out default settings. Experiment and <a href=\"https://huggingface.co/datasets/multimodalart/latent-majesty-diffusion-settings\">share your settings with us</a>.\n",
        "\n",
        "width = 512 #@param{type: 'integer'}\n",
        "height = 256 #@param{type: 'integer'}\n",
        "\n",
        "clamp_index = [2.1, 2.4] #@param{type: 'raw'}\n",
        "\n",
        "latent_diffusion_guidance_scale = 9 #@param {type:\"number\"}\n",
        "clip_guidance_scale = 16000 #@param{type: 'integer'}\n",
        "\n",
        "how_many_batches = 1#@param{type: 'integer'}\n",
        "aesthetic_loss_scale = 100 #@param{type: 'integer'}\n",
        "augment_cuts = True #@param{type:'boolean'}\n",
        "\n",
        "\n",
        "#@markdown\n",
        "\n",
        "#@markdown ### Custom saved settings\n",
        "#@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "custom_settings = '' #@param{type:'string'}\n",
        "settings_library = 'default' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "if(settings_library != 'None (use settings defined above)'):\n",
        "  custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "global_var_scope = globals()\n",
        "if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "  print('Loaded ', custom_settings)\n",
        "  try:\n",
        "    from configparser import ConfigParser\n",
        "  except ImportError:\n",
        "      from ConfigParser import ConfigParser\n",
        "  import configparser\n",
        "  \n",
        "  config = ConfigParser()\n",
        "  config.read(custom_settings)\n",
        "  #custom_settings_stream = fetch(custom_settings)\n",
        "  #Load CLIP models from config\n",
        "  if(config.has_section('clip_list')):\n",
        "    clip_incoming_list = config.items('clip_list')\n",
        "    clip_incoming_models = clip_incoming_list[0]\n",
        "    incoming_perceptors = eval(clip_incoming_models[1])\n",
        "    if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "      clip_load_list = incoming_perceptors\n",
        "      clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "  #Load settings from config and replace variables\n",
        "  if(config.has_section('basic_settings')):\n",
        "    basic_settings = config.items('basic_settings')\n",
        "    for basic_setting in basic_settings:\n",
        "      global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "  \n",
        "  if(config.has_section('advanced_settings')):\n",
        "    advanced_settings = config.items('advanced_settings')\n",
        "    for advanced_setting in advanced_settings:\n",
        "      global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "  custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "prompts = clip_prompts\n",
        "opt.prompt = latent_prompts\n",
        "opt.uc = latent_negatives\n",
        "custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "aes_scale = aesthetic_loss_scale\n",
        "try: \n",
        "  clip_guidance_schedule\n",
        "  clip_guidance_index = clip_guidance_schedule\n",
        "except:\n",
        "  clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "opt.W = (width//64)*64;\n",
        "opt.H = (height//64)*64;\n",
        "if opt.W != width or opt.H != height:\n",
        "    print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "opt.mag_mul = opt_mag_mul \n",
        "opt.ddim_eta = opt_ddim_eta\n",
        "opt.eta_end = opt_eta_end\n",
        "opt.temperature = opt_temperature\n",
        "opt.n_iter = how_many_batches\n",
        "opt.n_samples =  1\n",
        "opt.scale = latent_diffusion_guidance_scale\n",
        "opt.plms = opt_plms\n",
        "aug = augment_cuts\n",
        "\n",
        "#Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "if(len(clamp_index) == 2): \n",
        "  clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "else:\n",
        "  clamp_index_variation = clamp_index\n",
        "score_corrector = DotMap()\n",
        "\n",
        "\n",
        "def modify_score(e_t, e_t_uncond):\n",
        "        if(score_modifier is False):\n",
        "          return e_t\n",
        "        else:\n",
        "          e_t_d = (e_t - e_t_uncond)\n",
        "          s = torch.quantile(\n",
        "              rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "              threshold_percentile,\n",
        "              dim = -1\n",
        "          )\n",
        "\n",
        "        s.clamp_(min = 1.)\n",
        "        s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "        if ths_method == \"softsign\":\n",
        "            e_t_d = F.softsign(e_t_d) / s \n",
        "        elif ths_method == \"clamp\":\n",
        "            e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "        e_t = e_t_uncond + e_t_d\n",
        "        return(e_t)\n",
        "          \n",
        "score_corrector.modify_score = modify_score\n",
        "\n",
        "def dynamic_thresholding(pred_x0,t):\n",
        "    return(pred_x0)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "generate_video = False\n",
        "if generate_video: \n",
        "    fps = 24\n",
        "    p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "do_run()\n",
        "if generate_video: \n",
        "    p.stdin.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "CkT73SIhb3d1"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#@markdown ### **Run 6.** Basic Settings\n",
        "\n",
        "width = 256 #@param{type: 'integer'}\n",
        "height = 384 #@param{type: 'integer'}\n",
        "\n",
        "clamp_index = [2.4, 2.1] #@param{type: 'raw'}\n",
        "\n",
        "latent_diffusion_guidance_scale = 15 #@param {type:\"number\"}\n",
        "clip_guidance_scale = 20000 #@param{type: 'integer'}\n",
        "\n",
        "how_many_batches = 1 #@param{type: 'integer'}\n",
        "aesthetic_loss_scale = 100 #@param{type: 'integer'}\n",
        "augment_cuts = True #@param{type:'boolean'}\n",
        "\n",
        "\n",
        "#@markdown\n",
        "\n",
        "#@markdown ### Custom saved settings\n",
        "#@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "custom_settings = '' #@param{type:'string'}\n",
        "settings_library = 'default' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "if(settings_library != 'None (use settings defined above)'):\n",
        "  custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "global_var_scope = globals()\n",
        "if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "  print('Loaded ', custom_settings)\n",
        "  try:\n",
        "    from configparser import ConfigParser\n",
        "  except ImportError:\n",
        "      from ConfigParser import ConfigParser\n",
        "  import configparser\n",
        "  \n",
        "  config = ConfigParser()\n",
        "  config.read(custom_settings)\n",
        "  #custom_settings_stream = fetch(custom_settings)\n",
        "  #Load CLIP models from config\n",
        "  if(config.has_section('clip_list')):\n",
        "    clip_incoming_list = config.items('clip_list')\n",
        "    clip_incoming_models = clip_incoming_list[0]\n",
        "    incoming_perceptors = eval(clip_incoming_models[1])\n",
        "    if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "      clip_load_list = incoming_perceptors\n",
        "      clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "  #Load settings from config and replace variables\n",
        "  if(config.has_section('basic_settings')):\n",
        "    basic_settings = config.items('basic_settings')\n",
        "    for basic_setting in basic_settings:\n",
        "      global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "  \n",
        "  if(config.has_section('advanced_settings')):\n",
        "    advanced_settings = config.items('advanced_settings')\n",
        "    for advanced_setting in advanced_settings:\n",
        "      global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "  custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "prompts = clip_prompts\n",
        "opt.prompt = latent_prompts\n",
        "opt.uc = latent_negatives\n",
        "custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "aes_scale = aesthetic_loss_scale\n",
        "try: \n",
        "  clip_guidance_schedule\n",
        "  clip_guidance_index = clip_guidance_schedule\n",
        "except:\n",
        "  clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "opt.W = (width//64)*64;\n",
        "opt.H = (height//64)*64;\n",
        "if opt.W != width or opt.H != height:\n",
        "    print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "opt.mag_mul = opt_mag_mul \n",
        "opt.ddim_eta = opt_ddim_eta\n",
        "opt.eta_end = opt_eta_end\n",
        "opt.temperature = opt_temperature\n",
        "opt.n_iter = how_many_batches\n",
        "opt.n_samples =  1\n",
        "opt.scale = latent_diffusion_guidance_scale\n",
        "opt.plms = opt_plms\n",
        "aug = augment_cuts\n",
        "\n",
        "#Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "if(len(clamp_index) == 2): \n",
        "  clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "else:\n",
        "  clamp_index_variation = clamp_index\n",
        "score_corrector = DotMap()\n",
        "\n",
        "\n",
        "def modify_score(e_t, e_t_uncond):\n",
        "        if(score_modifier is False):\n",
        "          return e_t\n",
        "        else:\n",
        "          e_t_d = (e_t - e_t_uncond)\n",
        "          s = torch.quantile(\n",
        "              rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "              threshold_percentile,\n",
        "              dim = -1\n",
        "          )\n",
        "\n",
        "        s.clamp_(min = 1.)\n",
        "        s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "        if ths_method == \"softsign\":\n",
        "            e_t_d = F.softsign(e_t_d) / s \n",
        "        elif ths_method == \"clamp\":\n",
        "            e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "        e_t = e_t_uncond + e_t_d\n",
        "        return(e_t)\n",
        "          \n",
        "score_corrector.modify_score = modify_score\n",
        "\n",
        "def dynamic_thresholding(pred_x0,t):\n",
        "    return(pred_x0)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "generate_video = False\n",
        "if generate_video: \n",
        "    fps = 24\n",
        "    p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "do_run()\n",
        "if generate_video: \n",
        "    p.stdin.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "qddhDG-Ob3d1"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#@markdown ### **Run 7.** Basic Settings\n",
        "\n",
        "width = 384 #@param{type: 'integer'}\n",
        "height = 384 #@param{type: 'integer'}\n",
        "\n",
        "clamp_index = [0.6, 0.6] #@param{type: 'raw'}\n",
        "\n",
        "latent_diffusion_guidance_scale = 11 #@param {type:\"number\"}\n",
        "clip_guidance_scale = 39999 #@param{type: 'integer'}\n",
        "\n",
        "how_many_batches = 1 #@param{type: 'integer'}\n",
        "aesthetic_loss_scale = 100 #@param{type: 'integer'}\n",
        "augment_cuts = True #@param{type:'boolean'}\n",
        "\n",
        "\n",
        "#@markdown ### Custom saved settings\n",
        "#@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "custom_settings = '' #@param{type:'string'}\n",
        "settings_library = 'coherent_pizzapigeon' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "if(settings_library != 'None (use settings defined above)'):\n",
        "  custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "global_var_scope = globals()\n",
        "if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "  print('Loaded ', custom_settings)\n",
        "  try:\n",
        "    from configparser import ConfigParser\n",
        "  except ImportError:\n",
        "      from ConfigParser import ConfigParser\n",
        "  import configparser\n",
        "  \n",
        "  config = ConfigParser()\n",
        "  config.read(custom_settings)\n",
        "  #custom_settings_stream = fetch(custom_settings)\n",
        "  #Load CLIP models from config\n",
        "  if(config.has_section('clip_list')):\n",
        "    clip_incoming_list = config.items('clip_list')\n",
        "    clip_incoming_models = clip_incoming_list[0]\n",
        "    incoming_perceptors = eval(clip_incoming_models[1])\n",
        "    if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "      clip_load_list = incoming_perceptors\n",
        "      clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "  #Load settings from config and replace variables\n",
        "  if(config.has_section('basic_settings')):\n",
        "    basic_settings = config.items('basic_settings')\n",
        "    for basic_setting in basic_settings:\n",
        "      global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "  \n",
        "  if(config.has_section('advanced_settings')):\n",
        "    advanced_settings = config.items('advanced_settings')\n",
        "    for advanced_setting in advanced_settings:\n",
        "      global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "  custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "prompts = clip_prompts\n",
        "opt.prompt = latent_prompts\n",
        "opt.uc = latent_negatives\n",
        "custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "aes_scale = aesthetic_loss_scale\n",
        "try: \n",
        "  clip_guidance_schedule\n",
        "  clip_guidance_index = clip_guidance_schedule\n",
        "except:\n",
        "  clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "opt.W = (width//64)*64;\n",
        "opt.H = (height//64)*64;\n",
        "if opt.W != width or opt.H != height:\n",
        "    print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "opt.mag_mul = opt_mag_mul \n",
        "opt.ddim_eta = opt_ddim_eta\n",
        "opt.eta_end = opt_eta_end\n",
        "opt.temperature = opt_temperature\n",
        "opt.n_iter = how_many_batches\n",
        "opt.n_samples =  1\n",
        "opt.scale = latent_diffusion_guidance_scale\n",
        "opt.plms = opt_plms\n",
        "aug = augment_cuts\n",
        "\n",
        "#Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "if(len(clamp_index) == 2): \n",
        "  clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "else:\n",
        "  clamp_index_variation = clamp_index\n",
        "score_corrector = DotMap()\n",
        "\n",
        "\n",
        "def modify_score(e_t, e_t_uncond):\n",
        "        if(score_modifier is False):\n",
        "          return e_t\n",
        "        else:\n",
        "          e_t_d = (e_t - e_t_uncond)\n",
        "          s = torch.quantile(\n",
        "              rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "              threshold_percentile,\n",
        "              dim = -1\n",
        "          )\n",
        "\n",
        "        s.clamp_(min = 1.)\n",
        "        s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "        if ths_method == \"softsign\":\n",
        "            e_t_d = F.softsign(e_t_d) / s \n",
        "        elif ths_method == \"clamp\":\n",
        "            e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "        e_t = e_t_uncond + e_t_d\n",
        "        return(e_t)\n",
        "          \n",
        "score_corrector.modify_score = modify_score\n",
        "\n",
        "def dynamic_thresholding(pred_x0,t):\n",
        "    return(pred_x0)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "generate_video = False\n",
        "if generate_video: \n",
        "    fps = 24\n",
        "    p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "do_run()\n",
        "if generate_video: \n",
        "    p.stdin.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "gpQ0lMGEb3d2"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#@markdown ### **Run 8.** Basic Settings\n",
        "\n",
        "width =  256#@param{type: 'integer'}\n",
        "height =  384#@param{type: 'integer'}\n",
        "\n",
        "clamp_index = [1, 1] #@param{type: 'raw'}\n",
        "\n",
        "latent_diffusion_guidance_scale = 10 #@param {type:\"number\"}\n",
        "clip_guidance_scale =  50000#@param{type: 'integer'}\n",
        "\n",
        "how_many_batches =  1#@param{type: 'integer'}\n",
        "\n",
        "aesthetic_loss_scale = 100 #@param{type: 'integer'}\n",
        "augment_cuts=True #@param{type:'boolean'}\n",
        "\n",
        "\n",
        "#@markdown ### Custom saved settings\n",
        "#@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "custom_settings = '' #@param{type:'string'}\n",
        "settings_library = 'coherent_pizzapigeon' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "if(settings_library != 'None (use settings defined above)'):\n",
        "  custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "global_var_scope = globals()\n",
        "if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "  print('Loaded ', custom_settings)\n",
        "  try:\n",
        "    from configparser import ConfigParser\n",
        "  except ImportError:\n",
        "      from ConfigParser import ConfigParser\n",
        "  import configparser\n",
        "  \n",
        "  config = ConfigParser()\n",
        "  config.read(custom_settings)\n",
        "  #custom_settings_stream = fetch(custom_settings)\n",
        "  #Load CLIP models from config\n",
        "  if(config.has_section('clip_list')):\n",
        "    clip_incoming_list = config.items('clip_list')\n",
        "    clip_incoming_models = clip_incoming_list[0]\n",
        "    incoming_perceptors = eval(clip_incoming_models[1])\n",
        "    if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "      clip_load_list = incoming_perceptors\n",
        "      clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "  #Load settings from config and replace variables\n",
        "  if(config.has_section('basic_settings')):\n",
        "    basic_settings = config.items('basic_settings')\n",
        "    for basic_setting in basic_settings:\n",
        "      global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "  \n",
        "  if(config.has_section('advanced_settings')):\n",
        "    advanced_settings = config.items('advanced_settings')\n",
        "    for advanced_setting in advanced_settings:\n",
        "      global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "  custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "prompts = clip_prompts\n",
        "opt.prompt = latent_prompts\n",
        "opt.uc = latent_negatives\n",
        "custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "aes_scale = aesthetic_loss_scale\n",
        "try: \n",
        "  clip_guidance_schedule\n",
        "  clip_guidance_index = clip_guidance_schedule\n",
        "except:\n",
        "  clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "opt.W = (width//64)*64;\n",
        "opt.H = (height//64)*64;\n",
        "if opt.W != width or opt.H != height:\n",
        "    print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "opt.mag_mul = opt_mag_mul \n",
        "opt.ddim_eta = opt_ddim_eta\n",
        "opt.eta_end = opt_eta_end\n",
        "opt.temperature = opt_temperature\n",
        "opt.n_iter = how_many_batches\n",
        "opt.n_samples =  1\n",
        "opt.scale = latent_diffusion_guidance_scale\n",
        "opt.plms = opt_plms\n",
        "aug = augment_cuts\n",
        "\n",
        "#Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "if(len(clamp_index) == 2): \n",
        "  clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "else:\n",
        "  clamp_index_variation = clamp_index\n",
        "score_corrector = DotMap()\n",
        "\n",
        "\n",
        "def modify_score(e_t, e_t_uncond):\n",
        "        if(score_modifier is False):\n",
        "          return e_t\n",
        "        else:\n",
        "          e_t_d = (e_t - e_t_uncond)\n",
        "          s = torch.quantile(\n",
        "              rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "              threshold_percentile,\n",
        "              dim = -1\n",
        "          )\n",
        "\n",
        "        s.clamp_(min = 1.)\n",
        "        s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "        if ths_method == \"softsign\":\n",
        "            e_t_d = F.softsign(e_t_d) / s \n",
        "        elif ths_method == \"clamp\":\n",
        "            e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "        e_t = e_t_uncond + e_t_d\n",
        "        return(e_t)\n",
        "          \n",
        "score_corrector.modify_score = modify_score\n",
        "\n",
        "def dynamic_thresholding(pred_x0,t):\n",
        "    return(pred_x0)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "generate_video = False\n",
        "if generate_video: \n",
        "    fps = 24\n",
        "    p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "do_run()\n",
        "if generate_video: \n",
        "    p.stdin.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ruv4a4Nkb3d2"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#@markdown ### **Run 9.** Basic Settings\n",
        "\n",
        "width = 384 #@param{type: 'integer'}\n",
        "height = 256 #@param{type: 'integer'}\n",
        "\n",
        "clamp_index = [1, 1] #@param{type: 'raw'}\n",
        "\n",
        "latent_diffusion_guidance_scale = 13 #@param {type:\"number\"}\n",
        "clip_guidance_scale = 24000 #@param{type: 'integer'}\n",
        "\n",
        "how_many_batches =  1#@param{type: 'integer'}\n",
        "aesthetic_loss_scale =  1#@param{type: 'integer'}\n",
        "augment_cuts = True #@param{type:'boolean'}\n",
        "\n",
        "\n",
        "#@markdown ### Custom saved settings\n",
        "#@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "custom_settings = '' #@param{type:'string'}\n",
        "settings_library = 'makeitrad_defaults' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "if(settings_library != 'None (use settings defined above)'):\n",
        "  custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "global_var_scope = globals()\n",
        "if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "  print('Loaded ', custom_settings)\n",
        "  try:\n",
        "    from configparser import ConfigParser\n",
        "  except ImportError:\n",
        "      from ConfigParser import ConfigParser\n",
        "  import configparser\n",
        "  \n",
        "  config = ConfigParser()\n",
        "  config.read(custom_settings)\n",
        "  #custom_settings_stream = fetch(custom_settings)\n",
        "  #Load CLIP models from config\n",
        "  if(config.has_section('clip_list')):\n",
        "    clip_incoming_list = config.items('clip_list')\n",
        "    clip_incoming_models = clip_incoming_list[0]\n",
        "    incoming_perceptors = eval(clip_incoming_models[1])\n",
        "    if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "      clip_load_list = incoming_perceptors\n",
        "      clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "  #Load settings from config and replace variables\n",
        "  if(config.has_section('basic_settings')):\n",
        "    basic_settings = config.items('basic_settings')\n",
        "    for basic_setting in basic_settings:\n",
        "      global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "  \n",
        "  if(config.has_section('advanced_settings')):\n",
        "    advanced_settings = config.items('advanced_settings')\n",
        "    for advanced_setting in advanced_settings:\n",
        "      global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "  custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "prompts = clip_prompts\n",
        "opt.prompt = latent_prompts\n",
        "opt.uc = latent_negatives\n",
        "custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "aes_scale = aesthetic_loss_scale\n",
        "try: \n",
        "  clip_guidance_schedule\n",
        "  clip_guidance_index = clip_guidance_schedule\n",
        "except:\n",
        "  clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "opt.W = (width//64)*64;\n",
        "opt.H = (height//64)*64;\n",
        "if opt.W != width or opt.H != height:\n",
        "    print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "opt.mag_mul = opt_mag_mul \n",
        "opt.ddim_eta = opt_ddim_eta\n",
        "opt.eta_end = opt_eta_end\n",
        "opt.temperature = opt_temperature\n",
        "opt.n_iter = how_many_batches\n",
        "opt.n_samples =  1\n",
        "opt.scale = latent_diffusion_guidance_scale\n",
        "opt.plms = opt_plms\n",
        "aug = augment_cuts\n",
        "\n",
        "#Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "if(len(clamp_index) == 2): \n",
        "  clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "else:\n",
        "  clamp_index_variation = clamp_index\n",
        "score_corrector = DotMap()\n",
        "\n",
        "\n",
        "def modify_score(e_t, e_t_uncond):\n",
        "        if(score_modifier is False):\n",
        "          return e_t\n",
        "        else:\n",
        "          e_t_d = (e_t - e_t_uncond)\n",
        "          s = torch.quantile(\n",
        "              rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "              threshold_percentile,\n",
        "              dim = -1\n",
        "          )\n",
        "\n",
        "        s.clamp_(min = 1.)\n",
        "        s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "        if ths_method == \"softsign\":\n",
        "            e_t_d = F.softsign(e_t_d) / s \n",
        "        elif ths_method == \"clamp\":\n",
        "            e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "        e_t = e_t_uncond + e_t_d\n",
        "        return(e_t)\n",
        "          \n",
        "score_corrector.modify_score = modify_score\n",
        "\n",
        "def dynamic_thresholding(pred_x0,t):\n",
        "    return(pred_x0)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "generate_video = False\n",
        "if generate_video: \n",
        "    fps = 24\n",
        "    p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "do_run()\n",
        "if generate_video: \n",
        "    p.stdin.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "lcgzfonKb3d2"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#@markdown ### **Run 10.** Basic Settings\n",
        "\n",
        "width = 256 #@param{type: 'integer'}\n",
        "height = 384 #@param{type: 'integer'}\n",
        "\n",
        "clamp_index = [1, 1] #@param{type: 'raw'}\n",
        "\n",
        "latent_diffusion_guidance_scale = 14 #@param {type:\"number\"}\n",
        "clip_guidance_scale = 8000 #@param{type: 'integer'}\n",
        "\n",
        "how_many_batches = 1 #@param{type: 'integer'}\n",
        "aesthetic_loss_scale = 10 #@param{type: 'integer'}\n",
        "augment_cuts = True #@param{type:'boolean'}\n",
        "\n",
        "\n",
        "#@markdown ### Custom saved settings\n",
        "#@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "custom_settings = '' #@param{type:'string'}\n",
        "settings_library = 'makeitrad_defaults' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "if(settings_library != 'None (use settings defined above)'):\n",
        "  custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "global_var_scope = globals()\n",
        "if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "  print('Loaded ', custom_settings)\n",
        "  try:\n",
        "    from configparser import ConfigParser\n",
        "  except ImportError:\n",
        "      from ConfigParser import ConfigParser\n",
        "  import configparser\n",
        "  \n",
        "  config = ConfigParser()\n",
        "  config.read(custom_settings)\n",
        "  #custom_settings_stream = fetch(custom_settings)\n",
        "  #Load CLIP models from config\n",
        "  if(config.has_section('clip_list')):\n",
        "    clip_incoming_list = config.items('clip_list')\n",
        "    clip_incoming_models = clip_incoming_list[0]\n",
        "    incoming_perceptors = eval(clip_incoming_models[1])\n",
        "    if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "      clip_load_list = incoming_perceptors\n",
        "      clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "  #Load settings from config and replace variables\n",
        "  if(config.has_section('basic_settings')):\n",
        "    basic_settings = config.items('basic_settings')\n",
        "    for basic_setting in basic_settings:\n",
        "      global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "  \n",
        "  if(config.has_section('advanced_settings')):\n",
        "    advanced_settings = config.items('advanced_settings')\n",
        "    for advanced_setting in advanced_settings:\n",
        "      global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "  custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "prompts = clip_prompts\n",
        "opt.prompt = latent_prompts\n",
        "opt.uc = latent_negatives\n",
        "custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "aes_scale = aesthetic_loss_scale\n",
        "try: \n",
        "  clip_guidance_schedule\n",
        "  clip_guidance_index = clip_guidance_schedule\n",
        "except:\n",
        "  clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "opt.W = (width//64)*64;\n",
        "opt.H = (height//64)*64;\n",
        "if opt.W != width or opt.H != height:\n",
        "    print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "opt.mag_mul = opt_mag_mul \n",
        "opt.ddim_eta = opt_ddim_eta\n",
        "opt.eta_end = opt_eta_end\n",
        "opt.temperature = opt_temperature\n",
        "opt.n_iter = how_many_batches\n",
        "opt.n_samples =  1\n",
        "opt.scale = latent_diffusion_guidance_scale\n",
        "opt.plms = opt_plms\n",
        "aug = augment_cuts\n",
        "\n",
        "#Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "if(len(clamp_index) == 2): \n",
        "  clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "else:\n",
        "  clamp_index_variation = clamp_index\n",
        "score_corrector = DotMap()\n",
        "\n",
        "\n",
        "def modify_score(e_t, e_t_uncond):\n",
        "        if(score_modifier is False):\n",
        "          return e_t\n",
        "        else:\n",
        "          e_t_d = (e_t - e_t_uncond)\n",
        "          s = torch.quantile(\n",
        "              rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "              threshold_percentile,\n",
        "              dim = -1\n",
        "          )\n",
        "\n",
        "        s.clamp_(min = 1.)\n",
        "        s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "        if ths_method == \"softsign\":\n",
        "            e_t_d = F.softsign(e_t_d) / s \n",
        "        elif ths_method == \"clamp\":\n",
        "            e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "        e_t = e_t_uncond + e_t_d\n",
        "        return(e_t)\n",
        "          \n",
        "score_corrector.modify_score = modify_score\n",
        "\n",
        "def dynamic_thresholding(pred_x0,t):\n",
        "    return(pred_x0)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "generate_video = False\n",
        "if generate_video: \n",
        "    fps = 24\n",
        "    p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "do_run()\n",
        "if generate_video: \n",
        "    p.stdin.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1QfynymcMTp"
      },
      "source": [
        "### 𝗗ᴇᴋᴀ-𝗕ᴀᴛᴄʜ 𝗥ᴜɴ 𝗖ᴇʟʟ𝘀 **X6** - Nati Ecchi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "init_image = \"https://i.imgur.com/tgwT3Pl.jpg\" #@param{type: 'string'}\n",
        "if(init_image == '' or init_image == 'None'):\n",
        "  init_image = None\n",
        "\n",
        "#default 0.9\n",
        "starting_timestep = 0.0 #@param{type: 'number'}\n",
        "\n",
        "init_mask = None #@param{type: 'string'}\n",
        "\n",
        "init_scale = 1000 #@param{type: 'integer'}\n",
        "\n",
        "#default 0.0\n",
        "init_brightness = 0.0 #@param{type: 'number'}\n",
        "\n",
        "#default 0.57\n",
        "init_noise = 0.0 #@param{type: 'number'}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "39vD0f4ocMTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "BcmuyYp0cMTp"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#@markdown ### **Run 1.** Basic settings\n",
        "\n",
        "#@markdown We're still figuring out default settings. Experiment and <a href=\"https://huggingface.co/datasets/multimodalart/latent-majesty-diffusion-settings\">share your settings with us</a>.\n",
        "\n",
        "#@markdown ✦✦ TO DO: Add init image cut schedule toggle, init and config skip toggles. ✦✦\n",
        "\n",
        "width = 256 #@param{type: 'integer'}\n",
        "height = 384 #@param{type: 'integer'}\n",
        "\n",
        "clamp_index = [2.4, 2.1] #@param{type: 'raw'}\n",
        "\n",
        "latent_diffusion_guidance_scale = 12 #@param {type:\"number\"}\n",
        "clip_guidance_scale = 12000 #@param{type: 'integer'}\n",
        "\n",
        "how_many_batches = 1 #@param{type: 'integer'}\n",
        "\n",
        "aesthetic_loss_scale = 100 #@param{type: 'integer'}\n",
        "augment_cuts = True #@param{type:'boolean'}\n",
        "\n",
        "\n",
        "#@markdown ### Custom saved settings\n",
        "#@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "custom_settings = '' #@param{type:'string'}\n",
        "settings_library = 'None (use settings defined above)' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "if(settings_library != 'None (use settings defined above)'):\n",
        "  custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "global_var_scope = globals()\n",
        "if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "  print('Loaded ', custom_settings)\n",
        "  try:\n",
        "    from configparser import ConfigParser\n",
        "  except ImportError:\n",
        "      from ConfigParser import ConfigParser\n",
        "  import configparser\n",
        "  \n",
        "  config = ConfigParser()\n",
        "  config.read(custom_settings)\n",
        "  #custom_settings_stream = fetch(custom_settings)\n",
        "  #Load CLIP models from config\n",
        "  if(config.has_section('clip_list')):\n",
        "    clip_incoming_list = config.items('clip_list')\n",
        "    clip_incoming_models = clip_incoming_list[0]\n",
        "    incoming_perceptors = eval(clip_incoming_models[1])\n",
        "    if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "      clip_load_list = incoming_perceptors\n",
        "      clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "  #Load settings from config and replace variables\n",
        "  if(config.has_section('basic_settings')):\n",
        "    basic_settings = config.items('basic_settings')\n",
        "    for basic_setting in basic_settings:\n",
        "      global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "  \n",
        "  if(config.has_section('advanced_settings')):\n",
        "    advanced_settings = config.items('advanced_settings')\n",
        "    for advanced_setting in advanced_settings:\n",
        "      global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "  custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "prompts = clip_prompts\n",
        "opt.prompt = latent_prompts\n",
        "opt.uc = latent_negatives\n",
        "custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "aes_scale = aesthetic_loss_scale\n",
        "try: \n",
        "  clip_guidance_schedule\n",
        "  clip_guidance_index = clip_guidance_schedule\n",
        "except:\n",
        "  clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "opt.W = (width//64)*64;\n",
        "opt.H = (height//64)*64;\n",
        "if opt.W != width or opt.H != height:\n",
        "    print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "opt.mag_mul = opt_mag_mul \n",
        "opt.ddim_eta = opt_ddim_eta\n",
        "opt.eta_end = opt_eta_end\n",
        "opt.temperature = opt_temperature\n",
        "opt.n_iter = how_many_batches\n",
        "opt.n_samples =  1\n",
        "opt.scale = latent_diffusion_guidance_scale\n",
        "opt.plms = opt_plms\n",
        "aug = augment_cuts\n",
        "\n",
        "#Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "if(len(clamp_index) == 2): \n",
        "  clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "else:\n",
        "  clamp_index_variation = clamp_index\n",
        "score_corrector = DotMap()\n",
        "\n",
        "\n",
        "def modify_score(e_t, e_t_uncond):\n",
        "        if(score_modifier is False):\n",
        "          return e_t\n",
        "        else:\n",
        "          e_t_d = (e_t - e_t_uncond)\n",
        "          s = torch.quantile(\n",
        "              rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "              threshold_percentile,\n",
        "              dim = -1\n",
        "          )\n",
        "\n",
        "        s.clamp_(min = 1.)\n",
        "        s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "        if ths_method == \"softsign\":\n",
        "            e_t_d = F.softsign(e_t_d) / s \n",
        "        elif ths_method == \"clamp\":\n",
        "            e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "        e_t = e_t_uncond + e_t_d\n",
        "        return(e_t)\n",
        "          \n",
        "score_corrector.modify_score = modify_score\n",
        "\n",
        "def dynamic_thresholding(pred_x0,t):\n",
        "    return(pred_x0)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "generate_video = False\n",
        "if generate_video: \n",
        "    fps = 24\n",
        "    p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "do_run()\n",
        "if generate_video: \n",
        "    p.stdin.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Hy-wX9HLcMTq"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#@markdown ### **Run 2.** Basic settings\n",
        "\n",
        "width = 256 #@param{type: 'integer'}\n",
        "height = 384 #@param{type: 'integer'}\n",
        "\n",
        "clamp_index = [2.1, 2.4] #@param{type: 'raw'}\n",
        "\n",
        "latent_diffusion_guidance_scale = 15 #@param {type:\"number\"}\n",
        "clip_guidance_scale = 50000 #@param{type: 'integer'}\n",
        "\n",
        "how_many_batches = 1 #@param{type: 'integer'}\n",
        "\n",
        "aesthetic_loss_scale = 200 #@param{type: 'integer'}\n",
        "augment_cuts = True #@param{type:'boolean'}\n",
        "\n",
        "\n",
        "#@markdown ### Custom saved settings\n",
        "#@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "custom_settings = '' #@param{type:'string'}\n",
        "settings_library = 'None (use settings defined above)' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "if(settings_library != 'None (use settings defined above)'):\n",
        "  custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "global_var_scope = globals()\n",
        "if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "  print('Loaded ', custom_settings)\n",
        "  try:\n",
        "    from configparser import ConfigParser\n",
        "  except ImportError:\n",
        "      from ConfigParser import ConfigParser\n",
        "  import configparser\n",
        "  \n",
        "  config = ConfigParser()\n",
        "  config.read(custom_settings)\n",
        "  #custom_settings_stream = fetch(custom_settings)\n",
        "  #Load CLIP models from config\n",
        "  if(config.has_section('clip_list')):\n",
        "    clip_incoming_list = config.items('clip_list')\n",
        "    clip_incoming_models = clip_incoming_list[0]\n",
        "    incoming_perceptors = eval(clip_incoming_models[1])\n",
        "    if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "      clip_load_list = incoming_perceptors\n",
        "      clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "  #Load settings from config and replace variables\n",
        "  if(config.has_section('basic_settings')):\n",
        "    basic_settings = config.items('basic_settings')\n",
        "    for basic_setting in basic_settings:\n",
        "      global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "  \n",
        "  if(config.has_section('advanced_settings')):\n",
        "    advanced_settings = config.items('advanced_settings')\n",
        "    for advanced_setting in advanced_settings:\n",
        "      global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "  custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "prompts = clip_prompts\n",
        "opt.prompt = latent_prompts\n",
        "opt.uc = latent_negatives\n",
        "custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "aes_scale = aesthetic_loss_scale\n",
        "try: \n",
        "  clip_guidance_schedule\n",
        "  clip_guidance_index = clip_guidance_schedule\n",
        "except:\n",
        "  clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "opt.W = (width//64)*64;\n",
        "opt.H = (height//64)*64;\n",
        "if opt.W != width or opt.H != height:\n",
        "    print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "opt.mag_mul = opt_mag_mul \n",
        "opt.ddim_eta = opt_ddim_eta\n",
        "opt.eta_end = opt_eta_end\n",
        "opt.temperature = opt_temperature\n",
        "opt.n_iter = how_many_batches\n",
        "opt.n_samples =  1\n",
        "opt.scale = latent_diffusion_guidance_scale\n",
        "opt.plms = opt_plms\n",
        "aug = augment_cuts\n",
        "\n",
        "#Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "if(len(clamp_index) == 2): \n",
        "  clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "else:\n",
        "  clamp_index_variation = clamp_index\n",
        "score_corrector = DotMap()\n",
        "\n",
        "\n",
        "def modify_score(e_t, e_t_uncond):\n",
        "        if(score_modifier is False):\n",
        "          return e_t\n",
        "        else:\n",
        "          e_t_d = (e_t - e_t_uncond)\n",
        "          s = torch.quantile(\n",
        "              rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "              threshold_percentile,\n",
        "              dim = -1\n",
        "          )\n",
        "\n",
        "        s.clamp_(min = 1.)\n",
        "        s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "        if ths_method == \"softsign\":\n",
        "            e_t_d = F.softsign(e_t_d) / s \n",
        "        elif ths_method == \"clamp\":\n",
        "            e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "        e_t = e_t_uncond + e_t_d\n",
        "        return(e_t)\n",
        "          \n",
        "score_corrector.modify_score = modify_score\n",
        "\n",
        "def dynamic_thresholding(pred_x0,t):\n",
        "    return(pred_x0)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "generate_video = False\n",
        "if generate_video: \n",
        "    fps = 24\n",
        "    p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "do_run()\n",
        "if generate_video: \n",
        "    p.stdin.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "-o8YoqgwcMTq"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#@markdown ### **Run 3.** Basic settings\n",
        "\n",
        "width = 256 #@param{type: 'integer'}\n",
        "height = 512 #@param{type: 'integer'}\n",
        "\n",
        "clamp_index = [2.1, 2.1] #@param{type: 'raw'}\n",
        "\n",
        "latent_diffusion_guidance_scale = 12 #@param {type:\"number\"}\n",
        "clip_guidance_scale = 50000 #@param{type: 'integer'}\n",
        "\n",
        "how_many_batches = 1 #@param{type: 'integer'}\n",
        "\n",
        "aesthetic_loss_scale = 200 #@param{type: 'integer'}\n",
        "augment_cuts = True #@param{type:'boolean'}\n",
        "\n",
        "\n",
        "#@markdown ### Custom saved settings\n",
        "#@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "custom_settings = '' #@param{type:'string'}\n",
        "settings_library = 'None (use settings defined above)' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "if(settings_library != 'None (use settings defined above)'):\n",
        "  custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "global_var_scope = globals()\n",
        "if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "  print('Loaded ', custom_settings)\n",
        "  try:\n",
        "    from configparser import ConfigParser\n",
        "  except ImportError:\n",
        "      from ConfigParser import ConfigParser\n",
        "  import configparser\n",
        "  \n",
        "  config = ConfigParser()\n",
        "  config.read(custom_settings)\n",
        "  #custom_settings_stream = fetch(custom_settings)\n",
        "  #Load CLIP models from config\n",
        "  if(config.has_section('clip_list')):\n",
        "    clip_incoming_list = config.items('clip_list')\n",
        "    clip_incoming_models = clip_incoming_list[0]\n",
        "    incoming_perceptors = eval(clip_incoming_models[1])\n",
        "    if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "      clip_load_list = incoming_perceptors\n",
        "      clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "  #Load settings from config and replace variables\n",
        "  if(config.has_section('basic_settings')):\n",
        "    basic_settings = config.items('basic_settings')\n",
        "    for basic_setting in basic_settings:\n",
        "      global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "  \n",
        "  if(config.has_section('advanced_settings')):\n",
        "    advanced_settings = config.items('advanced_settings')\n",
        "    for advanced_setting in advanced_settings:\n",
        "      global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "  custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "prompts = clip_prompts\n",
        "opt.prompt = latent_prompts\n",
        "opt.uc = latent_negatives\n",
        "custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "aes_scale = aesthetic_loss_scale\n",
        "try: \n",
        "  clip_guidance_schedule\n",
        "  clip_guidance_index = clip_guidance_schedule\n",
        "except:\n",
        "  clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "opt.W = (width//64)*64;\n",
        "opt.H = (height//64)*64;\n",
        "if opt.W != width or opt.H != height:\n",
        "    print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "opt.mag_mul = opt_mag_mul \n",
        "opt.ddim_eta = opt_ddim_eta\n",
        "opt.eta_end = opt_eta_end\n",
        "opt.temperature = opt_temperature\n",
        "opt.n_iter = how_many_batches\n",
        "opt.n_samples =  1\n",
        "opt.scale = latent_diffusion_guidance_scale\n",
        "opt.plms = opt_plms\n",
        "aug = augment_cuts\n",
        "\n",
        "#Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "if(len(clamp_index) == 2): \n",
        "  clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "else:\n",
        "  clamp_index_variation = clamp_index\n",
        "score_corrector = DotMap()\n",
        "\n",
        "\n",
        "def modify_score(e_t, e_t_uncond):\n",
        "        if(score_modifier is False):\n",
        "          return e_t\n",
        "        else:\n",
        "          e_t_d = (e_t - e_t_uncond)\n",
        "          s = torch.quantile(\n",
        "              rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "              threshold_percentile,\n",
        "              dim = -1\n",
        "          )\n",
        "\n",
        "        s.clamp_(min = 1.)\n",
        "        s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "        if ths_method == \"softsign\":\n",
        "            e_t_d = F.softsign(e_t_d) / s \n",
        "        elif ths_method == \"clamp\":\n",
        "            e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "        e_t = e_t_uncond + e_t_d\n",
        "        return(e_t)\n",
        "          \n",
        "score_corrector.modify_score = modify_score\n",
        "\n",
        "def dynamic_thresholding(pred_x0,t):\n",
        "    return(pred_x0)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "generate_video = False\n",
        "if generate_video: \n",
        "    fps = 24\n",
        "    p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "do_run()\n",
        "if generate_video: \n",
        "    p.stdin.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ucEE-LmpcMTq"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#@markdown ### **Run 4.** Basic settings\n",
        "\n",
        "width = 256 #@param{type: 'integer'}\n",
        "height = 512 #@param{type: 'integer'}\n",
        "\n",
        "clamp_index = [1.5, 2.0] #@param{type: 'raw'}\n",
        "\n",
        "latent_diffusion_guidance_scale = 6 #@param {type:\"number\"}\n",
        "clip_guidance_scale = 36000 #@param{type: 'integer'}\n",
        "\n",
        "how_many_batches = 1 #@param{type: 'integer'}\n",
        "aesthetic_loss_scale = 100 #@param{type: 'integer'}\n",
        "augment_cuts = True #@param{type:'boolean'}\n",
        "\n",
        "\n",
        "#@markdown\n",
        "\n",
        "#@markdown ### Custom saved settings\n",
        "#@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "custom_settings = '' #@param{type:'string'}\n",
        "settings_library = 'None (use settings defined above)' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "if(settings_library != 'None (use settings defined above)'):\n",
        "  custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "global_var_scope = globals()\n",
        "if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "  print('Loaded ', custom_settings)\n",
        "  try:\n",
        "    from configparser import ConfigParser\n",
        "  except ImportError:\n",
        "      from ConfigParser import ConfigParser\n",
        "  import configparser\n",
        "  \n",
        "  config = ConfigParser()\n",
        "  config.read(custom_settings)\n",
        "  #custom_settings_stream = fetch(custom_settings)\n",
        "  #Load CLIP models from config\n",
        "  if(config.has_section('clip_list')):\n",
        "    clip_incoming_list = config.items('clip_list')\n",
        "    clip_incoming_models = clip_incoming_list[0]\n",
        "    incoming_perceptors = eval(clip_incoming_models[1])\n",
        "    if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "      clip_load_list = incoming_perceptors\n",
        "      clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "  #Load settings from config and replace variables\n",
        "  if(config.has_section('basic_settings')):\n",
        "    basic_settings = config.items('basic_settings')\n",
        "    for basic_setting in basic_settings:\n",
        "      global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "  \n",
        "  if(config.has_section('advanced_settings')):\n",
        "    advanced_settings = config.items('advanced_settings')\n",
        "    for advanced_setting in advanced_settings:\n",
        "      global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "  custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "prompts = clip_prompts\n",
        "opt.prompt = latent_prompts\n",
        "opt.uc = latent_negatives\n",
        "custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "aes_scale = aesthetic_loss_scale\n",
        "try: \n",
        "  clip_guidance_schedule\n",
        "  clip_guidance_index = clip_guidance_schedule\n",
        "except:\n",
        "  clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "opt.W = (width//64)*64;\n",
        "opt.H = (height//64)*64;\n",
        "if opt.W != width or opt.H != height:\n",
        "    print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "opt.mag_mul = opt_mag_mul \n",
        "opt.ddim_eta = opt_ddim_eta\n",
        "opt.eta_end = opt_eta_end\n",
        "opt.temperature = opt_temperature\n",
        "opt.n_iter = how_many_batches\n",
        "opt.n_samples =  1\n",
        "opt.scale = latent_diffusion_guidance_scale\n",
        "opt.plms = opt_plms\n",
        "aug = augment_cuts\n",
        "\n",
        "#Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "if(len(clamp_index) == 2): \n",
        "  clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "else:\n",
        "  clamp_index_variation = clamp_index\n",
        "score_corrector = DotMap()\n",
        "\n",
        "\n",
        "def modify_score(e_t, e_t_uncond):\n",
        "        if(score_modifier is False):\n",
        "          return e_t\n",
        "        else:\n",
        "          e_t_d = (e_t - e_t_uncond)\n",
        "          s = torch.quantile(\n",
        "              rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "              threshold_percentile,\n",
        "              dim = -1\n",
        "          )\n",
        "\n",
        "        s.clamp_(min = 1.)\n",
        "        s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "        if ths_method == \"softsign\":\n",
        "            e_t_d = F.softsign(e_t_d) / s \n",
        "        elif ths_method == \"clamp\":\n",
        "            e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "        e_t = e_t_uncond + e_t_d\n",
        "        return(e_t)\n",
        "          \n",
        "score_corrector.modify_score = modify_score\n",
        "\n",
        "def dynamic_thresholding(pred_x0,t):\n",
        "    return(pred_x0)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "generate_video = False\n",
        "if generate_video: \n",
        "    fps = 24\n",
        "    p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "do_run()\n",
        "if generate_video: \n",
        "    p.stdin.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "iL4Ai-CacMTr"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#@markdown ### **Run 5.** Basic settings\n",
        "\n",
        "#@markdown We're still figuring out default settings. Experiment and <a href=\"https://huggingface.co/datasets/multimodalart/latent-majesty-diffusion-settings\">share your settings with us</a>.\n",
        "\n",
        "width = 256 #@param{type: 'integer'}\n",
        "height = 512 #@param{type: 'integer'}\n",
        "\n",
        "clamp_index = [2.1, 2.4] #@param{type: 'raw'}\n",
        "\n",
        "latent_diffusion_guidance_scale = 9 #@param {type:\"number\"}\n",
        "clip_guidance_scale = 16000 #@param{type: 'integer'}\n",
        "\n",
        "how_many_batches = 1#@param{type: 'integer'}\n",
        "aesthetic_loss_scale = 100 #@param{type: 'integer'}\n",
        "augment_cuts = True #@param{type:'boolean'}\n",
        "\n",
        "\n",
        "#@markdown\n",
        "\n",
        "#@markdown ### Custom saved settings\n",
        "#@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "custom_settings = '' #@param{type:'string'}\n",
        "settings_library = 'default' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "if(settings_library != 'None (use settings defined above)'):\n",
        "  custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "global_var_scope = globals()\n",
        "if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "  print('Loaded ', custom_settings)\n",
        "  try:\n",
        "    from configparser import ConfigParser\n",
        "  except ImportError:\n",
        "      from ConfigParser import ConfigParser\n",
        "  import configparser\n",
        "  \n",
        "  config = ConfigParser()\n",
        "  config.read(custom_settings)\n",
        "  #custom_settings_stream = fetch(custom_settings)\n",
        "  #Load CLIP models from config\n",
        "  if(config.has_section('clip_list')):\n",
        "    clip_incoming_list = config.items('clip_list')\n",
        "    clip_incoming_models = clip_incoming_list[0]\n",
        "    incoming_perceptors = eval(clip_incoming_models[1])\n",
        "    if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "      clip_load_list = incoming_perceptors\n",
        "      clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "  #Load settings from config and replace variables\n",
        "  if(config.has_section('basic_settings')):\n",
        "    basic_settings = config.items('basic_settings')\n",
        "    for basic_setting in basic_settings:\n",
        "      global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "  \n",
        "  if(config.has_section('advanced_settings')):\n",
        "    advanced_settings = config.items('advanced_settings')\n",
        "    for advanced_setting in advanced_settings:\n",
        "      global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "  custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "prompts = clip_prompts\n",
        "opt.prompt = latent_prompts\n",
        "opt.uc = latent_negatives\n",
        "custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "aes_scale = aesthetic_loss_scale\n",
        "try: \n",
        "  clip_guidance_schedule\n",
        "  clip_guidance_index = clip_guidance_schedule\n",
        "except:\n",
        "  clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "opt.W = (width//64)*64;\n",
        "opt.H = (height//64)*64;\n",
        "if opt.W != width or opt.H != height:\n",
        "    print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "opt.mag_mul = opt_mag_mul \n",
        "opt.ddim_eta = opt_ddim_eta\n",
        "opt.eta_end = opt_eta_end\n",
        "opt.temperature = opt_temperature\n",
        "opt.n_iter = how_many_batches\n",
        "opt.n_samples =  1\n",
        "opt.scale = latent_diffusion_guidance_scale\n",
        "opt.plms = opt_plms\n",
        "aug = augment_cuts\n",
        "\n",
        "#Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "if(len(clamp_index) == 2): \n",
        "  clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "else:\n",
        "  clamp_index_variation = clamp_index\n",
        "score_corrector = DotMap()\n",
        "\n",
        "\n",
        "def modify_score(e_t, e_t_uncond):\n",
        "        if(score_modifier is False):\n",
        "          return e_t\n",
        "        else:\n",
        "          e_t_d = (e_t - e_t_uncond)\n",
        "          s = torch.quantile(\n",
        "              rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "              threshold_percentile,\n",
        "              dim = -1\n",
        "          )\n",
        "\n",
        "        s.clamp_(min = 1.)\n",
        "        s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "        if ths_method == \"softsign\":\n",
        "            e_t_d = F.softsign(e_t_d) / s \n",
        "        elif ths_method == \"clamp\":\n",
        "            e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "        e_t = e_t_uncond + e_t_d\n",
        "        return(e_t)\n",
        "          \n",
        "score_corrector.modify_score = modify_score\n",
        "\n",
        "def dynamic_thresholding(pred_x0,t):\n",
        "    return(pred_x0)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "generate_video = False\n",
        "if generate_video: \n",
        "    fps = 24\n",
        "    p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "do_run()\n",
        "if generate_video: \n",
        "    p.stdin.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "zcmYRfugcMTs"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#@markdown ### **Run 6.** Basic Settings\n",
        "\n",
        "width = 256 #@param{type: 'integer'}\n",
        "height = 384 #@param{type: 'integer'}\n",
        "\n",
        "clamp_index = [2.4, 2.1] #@param{type: 'raw'}\n",
        "\n",
        "latent_diffusion_guidance_scale = 15 #@param {type:\"number\"}\n",
        "clip_guidance_scale = 20000 #@param{type: 'integer'}\n",
        "\n",
        "how_many_batches = 1 #@param{type: 'integer'}\n",
        "aesthetic_loss_scale = 100 #@param{type: 'integer'}\n",
        "augment_cuts = True #@param{type:'boolean'}\n",
        "\n",
        "\n",
        "#@markdown\n",
        "\n",
        "#@markdown ### Custom saved settings\n",
        "#@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "custom_settings = '' #@param{type:'string'}\n",
        "settings_library = 'default' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "if(settings_library != 'None (use settings defined above)'):\n",
        "  custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "global_var_scope = globals()\n",
        "if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "  print('Loaded ', custom_settings)\n",
        "  try:\n",
        "    from configparser import ConfigParser\n",
        "  except ImportError:\n",
        "      from ConfigParser import ConfigParser\n",
        "  import configparser\n",
        "  \n",
        "  config = ConfigParser()\n",
        "  config.read(custom_settings)\n",
        "  #custom_settings_stream = fetch(custom_settings)\n",
        "  #Load CLIP models from config\n",
        "  if(config.has_section('clip_list')):\n",
        "    clip_incoming_list = config.items('clip_list')\n",
        "    clip_incoming_models = clip_incoming_list[0]\n",
        "    incoming_perceptors = eval(clip_incoming_models[1])\n",
        "    if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "      clip_load_list = incoming_perceptors\n",
        "      clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "  #Load settings from config and replace variables\n",
        "  if(config.has_section('basic_settings')):\n",
        "    basic_settings = config.items('basic_settings')\n",
        "    for basic_setting in basic_settings:\n",
        "      global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "  \n",
        "  if(config.has_section('advanced_settings')):\n",
        "    advanced_settings = config.items('advanced_settings')\n",
        "    for advanced_setting in advanced_settings:\n",
        "      global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "  custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "prompts = clip_prompts\n",
        "opt.prompt = latent_prompts\n",
        "opt.uc = latent_negatives\n",
        "custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "aes_scale = aesthetic_loss_scale\n",
        "try: \n",
        "  clip_guidance_schedule\n",
        "  clip_guidance_index = clip_guidance_schedule\n",
        "except:\n",
        "  clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "opt.W = (width//64)*64;\n",
        "opt.H = (height//64)*64;\n",
        "if opt.W != width or opt.H != height:\n",
        "    print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "opt.mag_mul = opt_mag_mul \n",
        "opt.ddim_eta = opt_ddim_eta\n",
        "opt.eta_end = opt_eta_end\n",
        "opt.temperature = opt_temperature\n",
        "opt.n_iter = how_many_batches\n",
        "opt.n_samples =  1\n",
        "opt.scale = latent_diffusion_guidance_scale\n",
        "opt.plms = opt_plms\n",
        "aug = augment_cuts\n",
        "\n",
        "#Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "if(len(clamp_index) == 2): \n",
        "  clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "else:\n",
        "  clamp_index_variation = clamp_index\n",
        "score_corrector = DotMap()\n",
        "\n",
        "\n",
        "def modify_score(e_t, e_t_uncond):\n",
        "        if(score_modifier is False):\n",
        "          return e_t\n",
        "        else:\n",
        "          e_t_d = (e_t - e_t_uncond)\n",
        "          s = torch.quantile(\n",
        "              rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "              threshold_percentile,\n",
        "              dim = -1\n",
        "          )\n",
        "\n",
        "        s.clamp_(min = 1.)\n",
        "        s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "        if ths_method == \"softsign\":\n",
        "            e_t_d = F.softsign(e_t_d) / s \n",
        "        elif ths_method == \"clamp\":\n",
        "            e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "        e_t = e_t_uncond + e_t_d\n",
        "        return(e_t)\n",
        "          \n",
        "score_corrector.modify_score = modify_score\n",
        "\n",
        "def dynamic_thresholding(pred_x0,t):\n",
        "    return(pred_x0)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "generate_video = False\n",
        "if generate_video: \n",
        "    fps = 24\n",
        "    p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "do_run()\n",
        "if generate_video: \n",
        "    p.stdin.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "EtJ26oHycMTs"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#@markdown ### **Run 7.** Basic Settings\n",
        "\n",
        "width = 384 #@param{type: 'integer'}\n",
        "height = 384 #@param{type: 'integer'}\n",
        "\n",
        "clamp_index = [0.6, 0.6] #@param{type: 'raw'}\n",
        "\n",
        "latent_diffusion_guidance_scale = 11 #@param {type:\"number\"}\n",
        "clip_guidance_scale = 39999 #@param{type: 'integer'}\n",
        "\n",
        "how_many_batches = 1 #@param{type: 'integer'}\n",
        "aesthetic_loss_scale = 100 #@param{type: 'integer'}\n",
        "augment_cuts = True #@param{type:'boolean'}\n",
        "\n",
        "\n",
        "#@markdown ### Custom saved settings\n",
        "#@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "custom_settings = '' #@param{type:'string'}\n",
        "settings_library = 'coherent_pizzapigeon' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "if(settings_library != 'None (use settings defined above)'):\n",
        "  custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "global_var_scope = globals()\n",
        "if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "  print('Loaded ', custom_settings)\n",
        "  try:\n",
        "    from configparser import ConfigParser\n",
        "  except ImportError:\n",
        "      from ConfigParser import ConfigParser\n",
        "  import configparser\n",
        "  \n",
        "  config = ConfigParser()\n",
        "  config.read(custom_settings)\n",
        "  #custom_settings_stream = fetch(custom_settings)\n",
        "  #Load CLIP models from config\n",
        "  if(config.has_section('clip_list')):\n",
        "    clip_incoming_list = config.items('clip_list')\n",
        "    clip_incoming_models = clip_incoming_list[0]\n",
        "    incoming_perceptors = eval(clip_incoming_models[1])\n",
        "    if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "      clip_load_list = incoming_perceptors\n",
        "      clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "  #Load settings from config and replace variables\n",
        "  if(config.has_section('basic_settings')):\n",
        "    basic_settings = config.items('basic_settings')\n",
        "    for basic_setting in basic_settings:\n",
        "      global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "  \n",
        "  if(config.has_section('advanced_settings')):\n",
        "    advanced_settings = config.items('advanced_settings')\n",
        "    for advanced_setting in advanced_settings:\n",
        "      global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "  custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "prompts = clip_prompts\n",
        "opt.prompt = latent_prompts\n",
        "opt.uc = latent_negatives\n",
        "custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "aes_scale = aesthetic_loss_scale\n",
        "try: \n",
        "  clip_guidance_schedule\n",
        "  clip_guidance_index = clip_guidance_schedule\n",
        "except:\n",
        "  clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "opt.W = (width//64)*64;\n",
        "opt.H = (height//64)*64;\n",
        "if opt.W != width or opt.H != height:\n",
        "    print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "opt.mag_mul = opt_mag_mul \n",
        "opt.ddim_eta = opt_ddim_eta\n",
        "opt.eta_end = opt_eta_end\n",
        "opt.temperature = opt_temperature\n",
        "opt.n_iter = how_many_batches\n",
        "opt.n_samples =  1\n",
        "opt.scale = latent_diffusion_guidance_scale\n",
        "opt.plms = opt_plms\n",
        "aug = augment_cuts\n",
        "\n",
        "#Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "if(len(clamp_index) == 2): \n",
        "  clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "else:\n",
        "  clamp_index_variation = clamp_index\n",
        "score_corrector = DotMap()\n",
        "\n",
        "\n",
        "def modify_score(e_t, e_t_uncond):\n",
        "        if(score_modifier is False):\n",
        "          return e_t\n",
        "        else:\n",
        "          e_t_d = (e_t - e_t_uncond)\n",
        "          s = torch.quantile(\n",
        "              rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "              threshold_percentile,\n",
        "              dim = -1\n",
        "          )\n",
        "\n",
        "        s.clamp_(min = 1.)\n",
        "        s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "        if ths_method == \"softsign\":\n",
        "            e_t_d = F.softsign(e_t_d) / s \n",
        "        elif ths_method == \"clamp\":\n",
        "            e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "        e_t = e_t_uncond + e_t_d\n",
        "        return(e_t)\n",
        "          \n",
        "score_corrector.modify_score = modify_score\n",
        "\n",
        "def dynamic_thresholding(pred_x0,t):\n",
        "    return(pred_x0)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "generate_video = False\n",
        "if generate_video: \n",
        "    fps = 24\n",
        "    p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "do_run()\n",
        "if generate_video: \n",
        "    p.stdin.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "an2OiVD9cMTt"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#@markdown ### **Run 8.** Basic Settings\n",
        "\n",
        "width =  256#@param{type: 'integer'}\n",
        "height =  384#@param{type: 'integer'}\n",
        "\n",
        "clamp_index = [1, 1] #@param{type: 'raw'}\n",
        "\n",
        "latent_diffusion_guidance_scale = 10 #@param {type:\"number\"}\n",
        "clip_guidance_scale =  50000#@param{type: 'integer'}\n",
        "\n",
        "how_many_batches =  1#@param{type: 'integer'}\n",
        "\n",
        "aesthetic_loss_scale = 100 #@param{type: 'integer'}\n",
        "augment_cuts=True #@param{type:'boolean'}\n",
        "\n",
        "\n",
        "#@markdown ### Custom saved settings\n",
        "#@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "custom_settings = '' #@param{type:'string'}\n",
        "settings_library = 'coherent_pizzapigeon' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "if(settings_library != 'None (use settings defined above)'):\n",
        "  custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "global_var_scope = globals()\n",
        "if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "  print('Loaded ', custom_settings)\n",
        "  try:\n",
        "    from configparser import ConfigParser\n",
        "  except ImportError:\n",
        "      from ConfigParser import ConfigParser\n",
        "  import configparser\n",
        "  \n",
        "  config = ConfigParser()\n",
        "  config.read(custom_settings)\n",
        "  #custom_settings_stream = fetch(custom_settings)\n",
        "  #Load CLIP models from config\n",
        "  if(config.has_section('clip_list')):\n",
        "    clip_incoming_list = config.items('clip_list')\n",
        "    clip_incoming_models = clip_incoming_list[0]\n",
        "    incoming_perceptors = eval(clip_incoming_models[1])\n",
        "    if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "      clip_load_list = incoming_perceptors\n",
        "      clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "  #Load settings from config and replace variables\n",
        "  if(config.has_section('basic_settings')):\n",
        "    basic_settings = config.items('basic_settings')\n",
        "    for basic_setting in basic_settings:\n",
        "      global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "  \n",
        "  if(config.has_section('advanced_settings')):\n",
        "    advanced_settings = config.items('advanced_settings')\n",
        "    for advanced_setting in advanced_settings:\n",
        "      global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "  custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "prompts = clip_prompts\n",
        "opt.prompt = latent_prompts\n",
        "opt.uc = latent_negatives\n",
        "custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "aes_scale = aesthetic_loss_scale\n",
        "try: \n",
        "  clip_guidance_schedule\n",
        "  clip_guidance_index = clip_guidance_schedule\n",
        "except:\n",
        "  clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "opt.W = (width//64)*64;\n",
        "opt.H = (height//64)*64;\n",
        "if opt.W != width or opt.H != height:\n",
        "    print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "opt.mag_mul = opt_mag_mul \n",
        "opt.ddim_eta = opt_ddim_eta\n",
        "opt.eta_end = opt_eta_end\n",
        "opt.temperature = opt_temperature\n",
        "opt.n_iter = how_many_batches\n",
        "opt.n_samples =  1\n",
        "opt.scale = latent_diffusion_guidance_scale\n",
        "opt.plms = opt_plms\n",
        "aug = augment_cuts\n",
        "\n",
        "#Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "if(len(clamp_index) == 2): \n",
        "  clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "else:\n",
        "  clamp_index_variation = clamp_index\n",
        "score_corrector = DotMap()\n",
        "\n",
        "\n",
        "def modify_score(e_t, e_t_uncond):\n",
        "        if(score_modifier is False):\n",
        "          return e_t\n",
        "        else:\n",
        "          e_t_d = (e_t - e_t_uncond)\n",
        "          s = torch.quantile(\n",
        "              rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "              threshold_percentile,\n",
        "              dim = -1\n",
        "          )\n",
        "\n",
        "        s.clamp_(min = 1.)\n",
        "        s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "        if ths_method == \"softsign\":\n",
        "            e_t_d = F.softsign(e_t_d) / s \n",
        "        elif ths_method == \"clamp\":\n",
        "            e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "        e_t = e_t_uncond + e_t_d\n",
        "        return(e_t)\n",
        "          \n",
        "score_corrector.modify_score = modify_score\n",
        "\n",
        "def dynamic_thresholding(pred_x0,t):\n",
        "    return(pred_x0)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "generate_video = False\n",
        "if generate_video: \n",
        "    fps = 24\n",
        "    p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "do_run()\n",
        "if generate_video: \n",
        "    p.stdin.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "thYjoGsXcMTt"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#@markdown ### **Run 9.** Basic Settings\n",
        "\n",
        "width = 256 #@param{type: 'integer'}\n",
        "height = 512 #@param{type: 'integer'}\n",
        "\n",
        "clamp_index = [1, 1] #@param{type: 'raw'}\n",
        "\n",
        "latent_diffusion_guidance_scale = 13 #@param {type:\"number\"}\n",
        "clip_guidance_scale = 24000 #@param{type: 'integer'}\n",
        "\n",
        "how_many_batches =  1#@param{type: 'integer'}\n",
        "aesthetic_loss_scale =  1#@param{type: 'integer'}\n",
        "augment_cuts = True #@param{type:'boolean'}\n",
        "\n",
        "\n",
        "#@markdown ### Custom saved settings\n",
        "#@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "custom_settings = '' #@param{type:'string'}\n",
        "settings_library = 'makeitrad_defaults' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "if(settings_library != 'None (use settings defined above)'):\n",
        "  custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "global_var_scope = globals()\n",
        "if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "  print('Loaded ', custom_settings)\n",
        "  try:\n",
        "    from configparser import ConfigParser\n",
        "  except ImportError:\n",
        "      from ConfigParser import ConfigParser\n",
        "  import configparser\n",
        "  \n",
        "  config = ConfigParser()\n",
        "  config.read(custom_settings)\n",
        "  #custom_settings_stream = fetch(custom_settings)\n",
        "  #Load CLIP models from config\n",
        "  if(config.has_section('clip_list')):\n",
        "    clip_incoming_list = config.items('clip_list')\n",
        "    clip_incoming_models = clip_incoming_list[0]\n",
        "    incoming_perceptors = eval(clip_incoming_models[1])\n",
        "    if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "      clip_load_list = incoming_perceptors\n",
        "      clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "  #Load settings from config and replace variables\n",
        "  if(config.has_section('basic_settings')):\n",
        "    basic_settings = config.items('basic_settings')\n",
        "    for basic_setting in basic_settings:\n",
        "      global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "  \n",
        "  if(config.has_section('advanced_settings')):\n",
        "    advanced_settings = config.items('advanced_settings')\n",
        "    for advanced_setting in advanced_settings:\n",
        "      global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "  custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "prompts = clip_prompts\n",
        "opt.prompt = latent_prompts\n",
        "opt.uc = latent_negatives\n",
        "custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "aes_scale = aesthetic_loss_scale\n",
        "try: \n",
        "  clip_guidance_schedule\n",
        "  clip_guidance_index = clip_guidance_schedule\n",
        "except:\n",
        "  clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "opt.W = (width//64)*64;\n",
        "opt.H = (height//64)*64;\n",
        "if opt.W != width or opt.H != height:\n",
        "    print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "opt.mag_mul = opt_mag_mul \n",
        "opt.ddim_eta = opt_ddim_eta\n",
        "opt.eta_end = opt_eta_end\n",
        "opt.temperature = opt_temperature\n",
        "opt.n_iter = how_many_batches\n",
        "opt.n_samples =  1\n",
        "opt.scale = latent_diffusion_guidance_scale\n",
        "opt.plms = opt_plms\n",
        "aug = augment_cuts\n",
        "\n",
        "#Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "if(len(clamp_index) == 2): \n",
        "  clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "else:\n",
        "  clamp_index_variation = clamp_index\n",
        "score_corrector = DotMap()\n",
        "\n",
        "\n",
        "def modify_score(e_t, e_t_uncond):\n",
        "        if(score_modifier is False):\n",
        "          return e_t\n",
        "        else:\n",
        "          e_t_d = (e_t - e_t_uncond)\n",
        "          s = torch.quantile(\n",
        "              rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "              threshold_percentile,\n",
        "              dim = -1\n",
        "          )\n",
        "\n",
        "        s.clamp_(min = 1.)\n",
        "        s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "        if ths_method == \"softsign\":\n",
        "            e_t_d = F.softsign(e_t_d) / s \n",
        "        elif ths_method == \"clamp\":\n",
        "            e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "        e_t = e_t_uncond + e_t_d\n",
        "        return(e_t)\n",
        "          \n",
        "score_corrector.modify_score = modify_score\n",
        "\n",
        "def dynamic_thresholding(pred_x0,t):\n",
        "    return(pred_x0)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "generate_video = False\n",
        "if generate_video: \n",
        "    fps = 24\n",
        "    p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "do_run()\n",
        "if generate_video: \n",
        "    p.stdin.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "PB16f_T2cMTt"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#@markdown ### **Run 10.** Basic Settings\n",
        "\n",
        "width = 256 #@param{type: 'integer'}\n",
        "height = 384 #@param{type: 'integer'}\n",
        "\n",
        "clamp_index = [1, 1] #@param{type: 'raw'}\n",
        "\n",
        "latent_diffusion_guidance_scale = 14 #@param {type:\"number\"}\n",
        "clip_guidance_scale = 8000 #@param{type: 'integer'}\n",
        "\n",
        "how_many_batches = 1 #@param{type: 'integer'}\n",
        "aesthetic_loss_scale = 10 #@param{type: 'integer'}\n",
        "augment_cuts = True #@param{type:'boolean'}\n",
        "\n",
        "\n",
        "#@markdown ### Custom saved settings\n",
        "#@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "custom_settings = '' #@param{type:'string'}\n",
        "settings_library = 'makeitrad_defaults' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "if(settings_library != 'None (use settings defined above)'):\n",
        "  custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "global_var_scope = globals()\n",
        "if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "  print('Loaded ', custom_settings)\n",
        "  try:\n",
        "    from configparser import ConfigParser\n",
        "  except ImportError:\n",
        "      from ConfigParser import ConfigParser\n",
        "  import configparser\n",
        "  \n",
        "  config = ConfigParser()\n",
        "  config.read(custom_settings)\n",
        "  #custom_settings_stream = fetch(custom_settings)\n",
        "  #Load CLIP models from config\n",
        "  if(config.has_section('clip_list')):\n",
        "    clip_incoming_list = config.items('clip_list')\n",
        "    clip_incoming_models = clip_incoming_list[0]\n",
        "    incoming_perceptors = eval(clip_incoming_models[1])\n",
        "    if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "      clip_load_list = incoming_perceptors\n",
        "      clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "  #Load settings from config and replace variables\n",
        "  if(config.has_section('basic_settings')):\n",
        "    basic_settings = config.items('basic_settings')\n",
        "    for basic_setting in basic_settings:\n",
        "      global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "  \n",
        "  if(config.has_section('advanced_settings')):\n",
        "    advanced_settings = config.items('advanced_settings')\n",
        "    for advanced_setting in advanced_settings:\n",
        "      global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "  custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "prompts = clip_prompts\n",
        "opt.prompt = latent_prompts\n",
        "opt.uc = latent_negatives\n",
        "custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "aes_scale = aesthetic_loss_scale\n",
        "try: \n",
        "  clip_guidance_schedule\n",
        "  clip_guidance_index = clip_guidance_schedule\n",
        "except:\n",
        "  clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "opt.W = (width//64)*64;\n",
        "opt.H = (height//64)*64;\n",
        "if opt.W != width or opt.H != height:\n",
        "    print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "opt.mag_mul = opt_mag_mul \n",
        "opt.ddim_eta = opt_ddim_eta\n",
        "opt.eta_end = opt_eta_end\n",
        "opt.temperature = opt_temperature\n",
        "opt.n_iter = how_many_batches\n",
        "opt.n_samples =  1\n",
        "opt.scale = latent_diffusion_guidance_scale\n",
        "opt.plms = opt_plms\n",
        "aug = augment_cuts\n",
        "\n",
        "#Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "if(len(clamp_index) == 2): \n",
        "  clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "else:\n",
        "  clamp_index_variation = clamp_index\n",
        "score_corrector = DotMap()\n",
        "\n",
        "\n",
        "def modify_score(e_t, e_t_uncond):\n",
        "        if(score_modifier is False):\n",
        "          return e_t\n",
        "        else:\n",
        "          e_t_d = (e_t - e_t_uncond)\n",
        "          s = torch.quantile(\n",
        "              rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "              threshold_percentile,\n",
        "              dim = -1\n",
        "          )\n",
        "\n",
        "        s.clamp_(min = 1.)\n",
        "        s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "        if ths_method == \"softsign\":\n",
        "            e_t_d = F.softsign(e_t_d) / s \n",
        "        elif ths_method == \"clamp\":\n",
        "            e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "        e_t = e_t_uncond + e_t_d\n",
        "        return(e_t)\n",
        "          \n",
        "score_corrector.modify_score = modify_score\n",
        "\n",
        "def dynamic_thresholding(pred_x0,t):\n",
        "    return(pred_x0)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "generate_video = False\n",
        "if generate_video: \n",
        "    fps = 24\n",
        "    p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "do_run()\n",
        "if generate_video: \n",
        "    p.stdin.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDwZtERfcchW"
      },
      "source": [
        "### 𝗗ᴇᴋᴀ-𝗕ᴀᴛᴄʜ 𝗥ᴜɴ 𝗖ᴇʟʟ𝘀 **X7** - Ahegao Double Peace"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "init_image = \"https://i.imgur.com/QAUVIZj.jpg\" #@param{type: 'string'}\n",
        "if(init_image == '' or init_image == 'None'):\n",
        "  init_image = None\n",
        "\n",
        "#default 0.9\n",
        "starting_timestep = 0.0 #@param{type: 'number'}\n",
        "\n",
        "init_mask = None #@param{type: 'string'}\n",
        "\n",
        "init_scale = 1000 #@param{type: 'integer'}\n",
        "\n",
        "#default 0.0\n",
        "init_brightness = 0.0 #@param{type: 'number'}\n",
        "\n",
        "#default 0.57\n",
        "init_noise = 0.0 #@param{type: 'number'}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "aa-hfJg_cchW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "dK0O2vPJcchX"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#@markdown ### **Run 1.** Basic settings\n",
        "\n",
        "#@markdown We're still figuring out default settings. Experiment and <a href=\"https://huggingface.co/datasets/multimodalart/latent-majesty-diffusion-settings\">share your settings with us</a>.\n",
        "\n",
        "#@markdown ✦✦ TO DO: Add init image cut schedule toggle, init and config skip toggles. ✦✦\n",
        "\n",
        "width = 256 #@param{type: 'integer'}\n",
        "height = 384 #@param{type: 'integer'}\n",
        "\n",
        "clamp_index = [2.4, 2.1] #@param{type: 'raw'}\n",
        "\n",
        "latent_diffusion_guidance_scale = 12 #@param {type:\"number\"}\n",
        "clip_guidance_scale = 12000 #@param{type: 'integer'}\n",
        "\n",
        "how_many_batches = 1 #@param{type: 'integer'}\n",
        "\n",
        "aesthetic_loss_scale = 100 #@param{type: 'integer'}\n",
        "augment_cuts = True #@param{type:'boolean'}\n",
        "\n",
        "\n",
        "#@markdown ### Custom saved settings\n",
        "#@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "custom_settings = '' #@param{type:'string'}\n",
        "settings_library = 'None (use settings defined above)' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "if(settings_library != 'None (use settings defined above)'):\n",
        "  custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "global_var_scope = globals()\n",
        "if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "  print('Loaded ', custom_settings)\n",
        "  try:\n",
        "    from configparser import ConfigParser\n",
        "  except ImportError:\n",
        "      from ConfigParser import ConfigParser\n",
        "  import configparser\n",
        "  \n",
        "  config = ConfigParser()\n",
        "  config.read(custom_settings)\n",
        "  #custom_settings_stream = fetch(custom_settings)\n",
        "  #Load CLIP models from config\n",
        "  if(config.has_section('clip_list')):\n",
        "    clip_incoming_list = config.items('clip_list')\n",
        "    clip_incoming_models = clip_incoming_list[0]\n",
        "    incoming_perceptors = eval(clip_incoming_models[1])\n",
        "    if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "      clip_load_list = incoming_perceptors\n",
        "      clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "  #Load settings from config and replace variables\n",
        "  if(config.has_section('basic_settings')):\n",
        "    basic_settings = config.items('basic_settings')\n",
        "    for basic_setting in basic_settings:\n",
        "      global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "  \n",
        "  if(config.has_section('advanced_settings')):\n",
        "    advanced_settings = config.items('advanced_settings')\n",
        "    for advanced_setting in advanced_settings:\n",
        "      global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "  custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "prompts = clip_prompts\n",
        "opt.prompt = latent_prompts\n",
        "opt.uc = latent_negatives\n",
        "custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "aes_scale = aesthetic_loss_scale\n",
        "try: \n",
        "  clip_guidance_schedule\n",
        "  clip_guidance_index = clip_guidance_schedule\n",
        "except:\n",
        "  clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "opt.W = (width//64)*64;\n",
        "opt.H = (height//64)*64;\n",
        "if opt.W != width or opt.H != height:\n",
        "    print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "opt.mag_mul = opt_mag_mul \n",
        "opt.ddim_eta = opt_ddim_eta\n",
        "opt.eta_end = opt_eta_end\n",
        "opt.temperature = opt_temperature\n",
        "opt.n_iter = how_many_batches\n",
        "opt.n_samples =  1\n",
        "opt.scale = latent_diffusion_guidance_scale\n",
        "opt.plms = opt_plms\n",
        "aug = augment_cuts\n",
        "\n",
        "#Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "if(len(clamp_index) == 2): \n",
        "  clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "else:\n",
        "  clamp_index_variation = clamp_index\n",
        "score_corrector = DotMap()\n",
        "\n",
        "\n",
        "def modify_score(e_t, e_t_uncond):\n",
        "        if(score_modifier is False):\n",
        "          return e_t\n",
        "        else:\n",
        "          e_t_d = (e_t - e_t_uncond)\n",
        "          s = torch.quantile(\n",
        "              rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "              threshold_percentile,\n",
        "              dim = -1\n",
        "          )\n",
        "\n",
        "        s.clamp_(min = 1.)\n",
        "        s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "        if ths_method == \"softsign\":\n",
        "            e_t_d = F.softsign(e_t_d) / s \n",
        "        elif ths_method == \"clamp\":\n",
        "            e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "        e_t = e_t_uncond + e_t_d\n",
        "        return(e_t)\n",
        "          \n",
        "score_corrector.modify_score = modify_score\n",
        "\n",
        "def dynamic_thresholding(pred_x0,t):\n",
        "    return(pred_x0)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "generate_video = False\n",
        "if generate_video: \n",
        "    fps = 24\n",
        "    p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "do_run()\n",
        "if generate_video: \n",
        "    p.stdin.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "dd6wTpgkcchX"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#@markdown ### **Run 2.** Basic settings\n",
        "\n",
        "width = 256 #@param{type: 'integer'}\n",
        "height = 384 #@param{type: 'integer'}\n",
        "\n",
        "clamp_index = [2.1, 2.4] #@param{type: 'raw'}\n",
        "\n",
        "latent_diffusion_guidance_scale = 15 #@param {type:\"number\"}\n",
        "clip_guidance_scale = 50000 #@param{type: 'integer'}\n",
        "\n",
        "how_many_batches = 1 #@param{type: 'integer'}\n",
        "\n",
        "aesthetic_loss_scale = 200 #@param{type: 'integer'}\n",
        "augment_cuts = True #@param{type:'boolean'}\n",
        "\n",
        "\n",
        "#@markdown ### Custom saved settings\n",
        "#@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "custom_settings = '' #@param{type:'string'}\n",
        "settings_library = 'None (use settings defined above)' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "if(settings_library != 'None (use settings defined above)'):\n",
        "  custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "global_var_scope = globals()\n",
        "if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "  print('Loaded ', custom_settings)\n",
        "  try:\n",
        "    from configparser import ConfigParser\n",
        "  except ImportError:\n",
        "      from ConfigParser import ConfigParser\n",
        "  import configparser\n",
        "  \n",
        "  config = ConfigParser()\n",
        "  config.read(custom_settings)\n",
        "  #custom_settings_stream = fetch(custom_settings)\n",
        "  #Load CLIP models from config\n",
        "  if(config.has_section('clip_list')):\n",
        "    clip_incoming_list = config.items('clip_list')\n",
        "    clip_incoming_models = clip_incoming_list[0]\n",
        "    incoming_perceptors = eval(clip_incoming_models[1])\n",
        "    if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "      clip_load_list = incoming_perceptors\n",
        "      clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "  #Load settings from config and replace variables\n",
        "  if(config.has_section('basic_settings')):\n",
        "    basic_settings = config.items('basic_settings')\n",
        "    for basic_setting in basic_settings:\n",
        "      global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "  \n",
        "  if(config.has_section('advanced_settings')):\n",
        "    advanced_settings = config.items('advanced_settings')\n",
        "    for advanced_setting in advanced_settings:\n",
        "      global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "  custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "prompts = clip_prompts\n",
        "opt.prompt = latent_prompts\n",
        "opt.uc = latent_negatives\n",
        "custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "aes_scale = aesthetic_loss_scale\n",
        "try: \n",
        "  clip_guidance_schedule\n",
        "  clip_guidance_index = clip_guidance_schedule\n",
        "except:\n",
        "  clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "opt.W = (width//64)*64;\n",
        "opt.H = (height//64)*64;\n",
        "if opt.W != width or opt.H != height:\n",
        "    print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "opt.mag_mul = opt_mag_mul \n",
        "opt.ddim_eta = opt_ddim_eta\n",
        "opt.eta_end = opt_eta_end\n",
        "opt.temperature = opt_temperature\n",
        "opt.n_iter = how_many_batches\n",
        "opt.n_samples =  1\n",
        "opt.scale = latent_diffusion_guidance_scale\n",
        "opt.plms = opt_plms\n",
        "aug = augment_cuts\n",
        "\n",
        "#Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "if(len(clamp_index) == 2): \n",
        "  clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "else:\n",
        "  clamp_index_variation = clamp_index\n",
        "score_corrector = DotMap()\n",
        "\n",
        "\n",
        "def modify_score(e_t, e_t_uncond):\n",
        "        if(score_modifier is False):\n",
        "          return e_t\n",
        "        else:\n",
        "          e_t_d = (e_t - e_t_uncond)\n",
        "          s = torch.quantile(\n",
        "              rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "              threshold_percentile,\n",
        "              dim = -1\n",
        "          )\n",
        "\n",
        "        s.clamp_(min = 1.)\n",
        "        s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "        if ths_method == \"softsign\":\n",
        "            e_t_d = F.softsign(e_t_d) / s \n",
        "        elif ths_method == \"clamp\":\n",
        "            e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "        e_t = e_t_uncond + e_t_d\n",
        "        return(e_t)\n",
        "          \n",
        "score_corrector.modify_score = modify_score\n",
        "\n",
        "def dynamic_thresholding(pred_x0,t):\n",
        "    return(pred_x0)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "generate_video = False\n",
        "if generate_video: \n",
        "    fps = 24\n",
        "    p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "do_run()\n",
        "if generate_video: \n",
        "    p.stdin.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "JFbXgve2cchY"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#@markdown ### **Run 3.** Basic settings\n",
        "\n",
        "width = 512 #@param{type: 'integer'}\n",
        "height = 256 #@param{type: 'integer'}\n",
        "\n",
        "clamp_index = [2.1, 2.1] #@param{type: 'raw'}\n",
        "\n",
        "latent_diffusion_guidance_scale = 12 #@param {type:\"number\"}\n",
        "clip_guidance_scale = 50000 #@param{type: 'integer'}\n",
        "\n",
        "how_many_batches = 1 #@param{type: 'integer'}\n",
        "\n",
        "aesthetic_loss_scale = 200 #@param{type: 'integer'}\n",
        "augment_cuts = True #@param{type:'boolean'}\n",
        "\n",
        "\n",
        "#@markdown ### Custom saved settings\n",
        "#@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "custom_settings = '' #@param{type:'string'}\n",
        "settings_library = 'None (use settings defined above)' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "if(settings_library != 'None (use settings defined above)'):\n",
        "  custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "global_var_scope = globals()\n",
        "if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "  print('Loaded ', custom_settings)\n",
        "  try:\n",
        "    from configparser import ConfigParser\n",
        "  except ImportError:\n",
        "      from ConfigParser import ConfigParser\n",
        "  import configparser\n",
        "  \n",
        "  config = ConfigParser()\n",
        "  config.read(custom_settings)\n",
        "  #custom_settings_stream = fetch(custom_settings)\n",
        "  #Load CLIP models from config\n",
        "  if(config.has_section('clip_list')):\n",
        "    clip_incoming_list = config.items('clip_list')\n",
        "    clip_incoming_models = clip_incoming_list[0]\n",
        "    incoming_perceptors = eval(clip_incoming_models[1])\n",
        "    if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "      clip_load_list = incoming_perceptors\n",
        "      clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "  #Load settings from config and replace variables\n",
        "  if(config.has_section('basic_settings')):\n",
        "    basic_settings = config.items('basic_settings')\n",
        "    for basic_setting in basic_settings:\n",
        "      global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "  \n",
        "  if(config.has_section('advanced_settings')):\n",
        "    advanced_settings = config.items('advanced_settings')\n",
        "    for advanced_setting in advanced_settings:\n",
        "      global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "  custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "prompts = clip_prompts\n",
        "opt.prompt = latent_prompts\n",
        "opt.uc = latent_negatives\n",
        "custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "aes_scale = aesthetic_loss_scale\n",
        "try: \n",
        "  clip_guidance_schedule\n",
        "  clip_guidance_index = clip_guidance_schedule\n",
        "except:\n",
        "  clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "opt.W = (width//64)*64;\n",
        "opt.H = (height//64)*64;\n",
        "if opt.W != width or opt.H != height:\n",
        "    print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "opt.mag_mul = opt_mag_mul \n",
        "opt.ddim_eta = opt_ddim_eta\n",
        "opt.eta_end = opt_eta_end\n",
        "opt.temperature = opt_temperature\n",
        "opt.n_iter = how_many_batches\n",
        "opt.n_samples =  1\n",
        "opt.scale = latent_diffusion_guidance_scale\n",
        "opt.plms = opt_plms\n",
        "aug = augment_cuts\n",
        "\n",
        "#Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "if(len(clamp_index) == 2): \n",
        "  clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "else:\n",
        "  clamp_index_variation = clamp_index\n",
        "score_corrector = DotMap()\n",
        "\n",
        "\n",
        "def modify_score(e_t, e_t_uncond):\n",
        "        if(score_modifier is False):\n",
        "          return e_t\n",
        "        else:\n",
        "          e_t_d = (e_t - e_t_uncond)\n",
        "          s = torch.quantile(\n",
        "              rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "              threshold_percentile,\n",
        "              dim = -1\n",
        "          )\n",
        "\n",
        "        s.clamp_(min = 1.)\n",
        "        s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "        if ths_method == \"softsign\":\n",
        "            e_t_d = F.softsign(e_t_d) / s \n",
        "        elif ths_method == \"clamp\":\n",
        "            e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "        e_t = e_t_uncond + e_t_d\n",
        "        return(e_t)\n",
        "          \n",
        "score_corrector.modify_score = modify_score\n",
        "\n",
        "def dynamic_thresholding(pred_x0,t):\n",
        "    return(pred_x0)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "generate_video = False\n",
        "if generate_video: \n",
        "    fps = 24\n",
        "    p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "do_run()\n",
        "if generate_video: \n",
        "    p.stdin.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "-SJYlUSFcchY"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#@markdown ### **Run 4.** Basic settings\n",
        "\n",
        "width = 256 #@param{type: 'integer'}\n",
        "height = 512 #@param{type: 'integer'}\n",
        "\n",
        "clamp_index = [1.5, 2.0] #@param{type: 'raw'}\n",
        "\n",
        "latent_diffusion_guidance_scale = 6 #@param {type:\"number\"}\n",
        "clip_guidance_scale = 36000 #@param{type: 'integer'}\n",
        "\n",
        "how_many_batches = 1 #@param{type: 'integer'}\n",
        "aesthetic_loss_scale = 100 #@param{type: 'integer'}\n",
        "augment_cuts = True #@param{type:'boolean'}\n",
        "\n",
        "\n",
        "#@markdown\n",
        "\n",
        "#@markdown ### Custom saved settings\n",
        "#@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "custom_settings = '' #@param{type:'string'}\n",
        "settings_library = 'None (use settings defined above)' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "if(settings_library != 'None (use settings defined above)'):\n",
        "  custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "global_var_scope = globals()\n",
        "if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "  print('Loaded ', custom_settings)\n",
        "  try:\n",
        "    from configparser import ConfigParser\n",
        "  except ImportError:\n",
        "      from ConfigParser import ConfigParser\n",
        "  import configparser\n",
        "  \n",
        "  config = ConfigParser()\n",
        "  config.read(custom_settings)\n",
        "  #custom_settings_stream = fetch(custom_settings)\n",
        "  #Load CLIP models from config\n",
        "  if(config.has_section('clip_list')):\n",
        "    clip_incoming_list = config.items('clip_list')\n",
        "    clip_incoming_models = clip_incoming_list[0]\n",
        "    incoming_perceptors = eval(clip_incoming_models[1])\n",
        "    if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "      clip_load_list = incoming_perceptors\n",
        "      clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "  #Load settings from config and replace variables\n",
        "  if(config.has_section('basic_settings')):\n",
        "    basic_settings = config.items('basic_settings')\n",
        "    for basic_setting in basic_settings:\n",
        "      global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "  \n",
        "  if(config.has_section('advanced_settings')):\n",
        "    advanced_settings = config.items('advanced_settings')\n",
        "    for advanced_setting in advanced_settings:\n",
        "      global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "  custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "prompts = clip_prompts\n",
        "opt.prompt = latent_prompts\n",
        "opt.uc = latent_negatives\n",
        "custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "aes_scale = aesthetic_loss_scale\n",
        "try: \n",
        "  clip_guidance_schedule\n",
        "  clip_guidance_index = clip_guidance_schedule\n",
        "except:\n",
        "  clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "opt.W = (width//64)*64;\n",
        "opt.H = (height//64)*64;\n",
        "if opt.W != width or opt.H != height:\n",
        "    print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "opt.mag_mul = opt_mag_mul \n",
        "opt.ddim_eta = opt_ddim_eta\n",
        "opt.eta_end = opt_eta_end\n",
        "opt.temperature = opt_temperature\n",
        "opt.n_iter = how_many_batches\n",
        "opt.n_samples =  1\n",
        "opt.scale = latent_diffusion_guidance_scale\n",
        "opt.plms = opt_plms\n",
        "aug = augment_cuts\n",
        "\n",
        "#Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "if(len(clamp_index) == 2): \n",
        "  clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "else:\n",
        "  clamp_index_variation = clamp_index\n",
        "score_corrector = DotMap()\n",
        "\n",
        "\n",
        "def modify_score(e_t, e_t_uncond):\n",
        "        if(score_modifier is False):\n",
        "          return e_t\n",
        "        else:\n",
        "          e_t_d = (e_t - e_t_uncond)\n",
        "          s = torch.quantile(\n",
        "              rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "              threshold_percentile,\n",
        "              dim = -1\n",
        "          )\n",
        "\n",
        "        s.clamp_(min = 1.)\n",
        "        s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "        if ths_method == \"softsign\":\n",
        "            e_t_d = F.softsign(e_t_d) / s \n",
        "        elif ths_method == \"clamp\":\n",
        "            e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "        e_t = e_t_uncond + e_t_d\n",
        "        return(e_t)\n",
        "          \n",
        "score_corrector.modify_score = modify_score\n",
        "\n",
        "def dynamic_thresholding(pred_x0,t):\n",
        "    return(pred_x0)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "generate_video = False\n",
        "if generate_video: \n",
        "    fps = 24\n",
        "    p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "do_run()\n",
        "if generate_video: \n",
        "    p.stdin.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "W2DIFVzYcchZ"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#@markdown ### **Run 5.** Basic settings\n",
        "\n",
        "#@markdown We're still figuring out default settings. Experiment and <a href=\"https://huggingface.co/datasets/multimodalart/latent-majesty-diffusion-settings\">share your settings with us</a>.\n",
        "\n",
        "width = 512 #@param{type: 'integer'}\n",
        "height = 256 #@param{type: 'integer'}\n",
        "\n",
        "clamp_index = [2.1, 2.4] #@param{type: 'raw'}\n",
        "\n",
        "latent_diffusion_guidance_scale = 9 #@param {type:\"number\"}\n",
        "clip_guidance_scale = 16000 #@param{type: 'integer'}\n",
        "\n",
        "how_many_batches = 1#@param{type: 'integer'}\n",
        "aesthetic_loss_scale = 100 #@param{type: 'integer'}\n",
        "augment_cuts = True #@param{type:'boolean'}\n",
        "\n",
        "\n",
        "#@markdown\n",
        "\n",
        "#@markdown ### Custom saved settings\n",
        "#@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "custom_settings = '' #@param{type:'string'}\n",
        "settings_library = 'default' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "if(settings_library != 'None (use settings defined above)'):\n",
        "  custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "global_var_scope = globals()\n",
        "if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "  print('Loaded ', custom_settings)\n",
        "  try:\n",
        "    from configparser import ConfigParser\n",
        "  except ImportError:\n",
        "      from ConfigParser import ConfigParser\n",
        "  import configparser\n",
        "  \n",
        "  config = ConfigParser()\n",
        "  config.read(custom_settings)\n",
        "  #custom_settings_stream = fetch(custom_settings)\n",
        "  #Load CLIP models from config\n",
        "  if(config.has_section('clip_list')):\n",
        "    clip_incoming_list = config.items('clip_list')\n",
        "    clip_incoming_models = clip_incoming_list[0]\n",
        "    incoming_perceptors = eval(clip_incoming_models[1])\n",
        "    if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "      clip_load_list = incoming_perceptors\n",
        "      clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "  #Load settings from config and replace variables\n",
        "  if(config.has_section('basic_settings')):\n",
        "    basic_settings = config.items('basic_settings')\n",
        "    for basic_setting in basic_settings:\n",
        "      global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "  \n",
        "  if(config.has_section('advanced_settings')):\n",
        "    advanced_settings = config.items('advanced_settings')\n",
        "    for advanced_setting in advanced_settings:\n",
        "      global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "  custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "prompts = clip_prompts\n",
        "opt.prompt = latent_prompts\n",
        "opt.uc = latent_negatives\n",
        "custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "aes_scale = aesthetic_loss_scale\n",
        "try: \n",
        "  clip_guidance_schedule\n",
        "  clip_guidance_index = clip_guidance_schedule\n",
        "except:\n",
        "  clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "opt.W = (width//64)*64;\n",
        "opt.H = (height//64)*64;\n",
        "if opt.W != width or opt.H != height:\n",
        "    print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "opt.mag_mul = opt_mag_mul \n",
        "opt.ddim_eta = opt_ddim_eta\n",
        "opt.eta_end = opt_eta_end\n",
        "opt.temperature = opt_temperature\n",
        "opt.n_iter = how_many_batches\n",
        "opt.n_samples =  1\n",
        "opt.scale = latent_diffusion_guidance_scale\n",
        "opt.plms = opt_plms\n",
        "aug = augment_cuts\n",
        "\n",
        "#Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "if(len(clamp_index) == 2): \n",
        "  clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "else:\n",
        "  clamp_index_variation = clamp_index\n",
        "score_corrector = DotMap()\n",
        "\n",
        "\n",
        "def modify_score(e_t, e_t_uncond):\n",
        "        if(score_modifier is False):\n",
        "          return e_t\n",
        "        else:\n",
        "          e_t_d = (e_t - e_t_uncond)\n",
        "          s = torch.quantile(\n",
        "              rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "              threshold_percentile,\n",
        "              dim = -1\n",
        "          )\n",
        "\n",
        "        s.clamp_(min = 1.)\n",
        "        s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "        if ths_method == \"softsign\":\n",
        "            e_t_d = F.softsign(e_t_d) / s \n",
        "        elif ths_method == \"clamp\":\n",
        "            e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "        e_t = e_t_uncond + e_t_d\n",
        "        return(e_t)\n",
        "          \n",
        "score_corrector.modify_score = modify_score\n",
        "\n",
        "def dynamic_thresholding(pred_x0,t):\n",
        "    return(pred_x0)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "generate_video = False\n",
        "if generate_video: \n",
        "    fps = 24\n",
        "    p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "do_run()\n",
        "if generate_video: \n",
        "    p.stdin.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "opPbn34VcchZ"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#@markdown ### **Run 6.** Basic Settings\n",
        "\n",
        "width = 256 #@param{type: 'integer'}\n",
        "height = 384 #@param{type: 'integer'}\n",
        "\n",
        "clamp_index = [2.4, 2.1] #@param{type: 'raw'}\n",
        "\n",
        "latent_diffusion_guidance_scale = 15 #@param {type:\"number\"}\n",
        "clip_guidance_scale = 20000 #@param{type: 'integer'}\n",
        "\n",
        "how_many_batches = 1 #@param{type: 'integer'}\n",
        "aesthetic_loss_scale = 100 #@param{type: 'integer'}\n",
        "augment_cuts = True #@param{type:'boolean'}\n",
        "\n",
        "\n",
        "#@markdown\n",
        "\n",
        "#@markdown ### Custom saved settings\n",
        "#@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "custom_settings = '' #@param{type:'string'}\n",
        "settings_library = 'default' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "if(settings_library != 'None (use settings defined above)'):\n",
        "  custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "global_var_scope = globals()\n",
        "if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "  print('Loaded ', custom_settings)\n",
        "  try:\n",
        "    from configparser import ConfigParser\n",
        "  except ImportError:\n",
        "      from ConfigParser import ConfigParser\n",
        "  import configparser\n",
        "  \n",
        "  config = ConfigParser()\n",
        "  config.read(custom_settings)\n",
        "  #custom_settings_stream = fetch(custom_settings)\n",
        "  #Load CLIP models from config\n",
        "  if(config.has_section('clip_list')):\n",
        "    clip_incoming_list = config.items('clip_list')\n",
        "    clip_incoming_models = clip_incoming_list[0]\n",
        "    incoming_perceptors = eval(clip_incoming_models[1])\n",
        "    if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "      clip_load_list = incoming_perceptors\n",
        "      clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "  #Load settings from config and replace variables\n",
        "  if(config.has_section('basic_settings')):\n",
        "    basic_settings = config.items('basic_settings')\n",
        "    for basic_setting in basic_settings:\n",
        "      global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "  \n",
        "  if(config.has_section('advanced_settings')):\n",
        "    advanced_settings = config.items('advanced_settings')\n",
        "    for advanced_setting in advanced_settings:\n",
        "      global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "  custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "prompts = clip_prompts\n",
        "opt.prompt = latent_prompts\n",
        "opt.uc = latent_negatives\n",
        "custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "aes_scale = aesthetic_loss_scale\n",
        "try: \n",
        "  clip_guidance_schedule\n",
        "  clip_guidance_index = clip_guidance_schedule\n",
        "except:\n",
        "  clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "opt.W = (width//64)*64;\n",
        "opt.H = (height//64)*64;\n",
        "if opt.W != width or opt.H != height:\n",
        "    print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "opt.mag_mul = opt_mag_mul \n",
        "opt.ddim_eta = opt_ddim_eta\n",
        "opt.eta_end = opt_eta_end\n",
        "opt.temperature = opt_temperature\n",
        "opt.n_iter = how_many_batches\n",
        "opt.n_samples =  1\n",
        "opt.scale = latent_diffusion_guidance_scale\n",
        "opt.plms = opt_plms\n",
        "aug = augment_cuts\n",
        "\n",
        "#Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "if(len(clamp_index) == 2): \n",
        "  clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "else:\n",
        "  clamp_index_variation = clamp_index\n",
        "score_corrector = DotMap()\n",
        "\n",
        "\n",
        "def modify_score(e_t, e_t_uncond):\n",
        "        if(score_modifier is False):\n",
        "          return e_t\n",
        "        else:\n",
        "          e_t_d = (e_t - e_t_uncond)\n",
        "          s = torch.quantile(\n",
        "              rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "              threshold_percentile,\n",
        "              dim = -1\n",
        "          )\n",
        "\n",
        "        s.clamp_(min = 1.)\n",
        "        s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "        if ths_method == \"softsign\":\n",
        "            e_t_d = F.softsign(e_t_d) / s \n",
        "        elif ths_method == \"clamp\":\n",
        "            e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "        e_t = e_t_uncond + e_t_d\n",
        "        return(e_t)\n",
        "          \n",
        "score_corrector.modify_score = modify_score\n",
        "\n",
        "def dynamic_thresholding(pred_x0,t):\n",
        "    return(pred_x0)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "generate_video = False\n",
        "if generate_video: \n",
        "    fps = 24\n",
        "    p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "do_run()\n",
        "if generate_video: \n",
        "    p.stdin.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "TwSh3lXJcchZ"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#@markdown ### **Run 7.** Basic Settings\n",
        "\n",
        "width = 384 #@param{type: 'integer'}\n",
        "height = 384 #@param{type: 'integer'}\n",
        "\n",
        "clamp_index = [0.6, 0.6] #@param{type: 'raw'}\n",
        "\n",
        "latent_diffusion_guidance_scale = 11 #@param {type:\"number\"}\n",
        "clip_guidance_scale = 39999 #@param{type: 'integer'}\n",
        "\n",
        "how_many_batches = 1 #@param{type: 'integer'}\n",
        "aesthetic_loss_scale = 100 #@param{type: 'integer'}\n",
        "augment_cuts = True #@param{type:'boolean'}\n",
        "\n",
        "\n",
        "#@markdown ### Custom saved settings\n",
        "#@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "custom_settings = '' #@param{type:'string'}\n",
        "settings_library = 'coherent_pizzapigeon' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "if(settings_library != 'None (use settings defined above)'):\n",
        "  custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "global_var_scope = globals()\n",
        "if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "  print('Loaded ', custom_settings)\n",
        "  try:\n",
        "    from configparser import ConfigParser\n",
        "  except ImportError:\n",
        "      from ConfigParser import ConfigParser\n",
        "  import configparser\n",
        "  \n",
        "  config = ConfigParser()\n",
        "  config.read(custom_settings)\n",
        "  #custom_settings_stream = fetch(custom_settings)\n",
        "  #Load CLIP models from config\n",
        "  if(config.has_section('clip_list')):\n",
        "    clip_incoming_list = config.items('clip_list')\n",
        "    clip_incoming_models = clip_incoming_list[0]\n",
        "    incoming_perceptors = eval(clip_incoming_models[1])\n",
        "    if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "      clip_load_list = incoming_perceptors\n",
        "      clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "  #Load settings from config and replace variables\n",
        "  if(config.has_section('basic_settings')):\n",
        "    basic_settings = config.items('basic_settings')\n",
        "    for basic_setting in basic_settings:\n",
        "      global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "  \n",
        "  if(config.has_section('advanced_settings')):\n",
        "    advanced_settings = config.items('advanced_settings')\n",
        "    for advanced_setting in advanced_settings:\n",
        "      global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "  custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "prompts = clip_prompts\n",
        "opt.prompt = latent_prompts\n",
        "opt.uc = latent_negatives\n",
        "custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "aes_scale = aesthetic_loss_scale\n",
        "try: \n",
        "  clip_guidance_schedule\n",
        "  clip_guidance_index = clip_guidance_schedule\n",
        "except:\n",
        "  clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "opt.W = (width//64)*64;\n",
        "opt.H = (height//64)*64;\n",
        "if opt.W != width or opt.H != height:\n",
        "    print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "opt.mag_mul = opt_mag_mul \n",
        "opt.ddim_eta = opt_ddim_eta\n",
        "opt.eta_end = opt_eta_end\n",
        "opt.temperature = opt_temperature\n",
        "opt.n_iter = how_many_batches\n",
        "opt.n_samples =  1\n",
        "opt.scale = latent_diffusion_guidance_scale\n",
        "opt.plms = opt_plms\n",
        "aug = augment_cuts\n",
        "\n",
        "#Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "if(len(clamp_index) == 2): \n",
        "  clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "else:\n",
        "  clamp_index_variation = clamp_index\n",
        "score_corrector = DotMap()\n",
        "\n",
        "\n",
        "def modify_score(e_t, e_t_uncond):\n",
        "        if(score_modifier is False):\n",
        "          return e_t\n",
        "        else:\n",
        "          e_t_d = (e_t - e_t_uncond)\n",
        "          s = torch.quantile(\n",
        "              rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "              threshold_percentile,\n",
        "              dim = -1\n",
        "          )\n",
        "\n",
        "        s.clamp_(min = 1.)\n",
        "        s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "        if ths_method == \"softsign\":\n",
        "            e_t_d = F.softsign(e_t_d) / s \n",
        "        elif ths_method == \"clamp\":\n",
        "            e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "        e_t = e_t_uncond + e_t_d\n",
        "        return(e_t)\n",
        "          \n",
        "score_corrector.modify_score = modify_score\n",
        "\n",
        "def dynamic_thresholding(pred_x0,t):\n",
        "    return(pred_x0)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "generate_video = False\n",
        "if generate_video: \n",
        "    fps = 24\n",
        "    p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "do_run()\n",
        "if generate_video: \n",
        "    p.stdin.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "3jSP_V7Eccha"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#@markdown ### **Run 8.** Basic Settings\n",
        "\n",
        "width =  256#@param{type: 'integer'}\n",
        "height =  384#@param{type: 'integer'}\n",
        "\n",
        "clamp_index = [1, 1] #@param{type: 'raw'}\n",
        "\n",
        "latent_diffusion_guidance_scale = 10 #@param {type:\"number\"}\n",
        "clip_guidance_scale =  50000#@param{type: 'integer'}\n",
        "\n",
        "how_many_batches =  1#@param{type: 'integer'}\n",
        "\n",
        "aesthetic_loss_scale = 100 #@param{type: 'integer'}\n",
        "augment_cuts=True #@param{type:'boolean'}\n",
        "\n",
        "\n",
        "#@markdown ### Custom saved settings\n",
        "#@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "custom_settings = '' #@param{type:'string'}\n",
        "settings_library = 'coherent_pizzapigeon' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "if(settings_library != 'None (use settings defined above)'):\n",
        "  custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "global_var_scope = globals()\n",
        "if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "  print('Loaded ', custom_settings)\n",
        "  try:\n",
        "    from configparser import ConfigParser\n",
        "  except ImportError:\n",
        "      from ConfigParser import ConfigParser\n",
        "  import configparser\n",
        "  \n",
        "  config = ConfigParser()\n",
        "  config.read(custom_settings)\n",
        "  #custom_settings_stream = fetch(custom_settings)\n",
        "  #Load CLIP models from config\n",
        "  if(config.has_section('clip_list')):\n",
        "    clip_incoming_list = config.items('clip_list')\n",
        "    clip_incoming_models = clip_incoming_list[0]\n",
        "    incoming_perceptors = eval(clip_incoming_models[1])\n",
        "    if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "      clip_load_list = incoming_perceptors\n",
        "      clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "  #Load settings from config and replace variables\n",
        "  if(config.has_section('basic_settings')):\n",
        "    basic_settings = config.items('basic_settings')\n",
        "    for basic_setting in basic_settings:\n",
        "      global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "  \n",
        "  if(config.has_section('advanced_settings')):\n",
        "    advanced_settings = config.items('advanced_settings')\n",
        "    for advanced_setting in advanced_settings:\n",
        "      global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "  custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "prompts = clip_prompts\n",
        "opt.prompt = latent_prompts\n",
        "opt.uc = latent_negatives\n",
        "custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "aes_scale = aesthetic_loss_scale\n",
        "try: \n",
        "  clip_guidance_schedule\n",
        "  clip_guidance_index = clip_guidance_schedule\n",
        "except:\n",
        "  clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "opt.W = (width//64)*64;\n",
        "opt.H = (height//64)*64;\n",
        "if opt.W != width or opt.H != height:\n",
        "    print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "opt.mag_mul = opt_mag_mul \n",
        "opt.ddim_eta = opt_ddim_eta\n",
        "opt.eta_end = opt_eta_end\n",
        "opt.temperature = opt_temperature\n",
        "opt.n_iter = how_many_batches\n",
        "opt.n_samples =  1\n",
        "opt.scale = latent_diffusion_guidance_scale\n",
        "opt.plms = opt_plms\n",
        "aug = augment_cuts\n",
        "\n",
        "#Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "if(len(clamp_index) == 2): \n",
        "  clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "else:\n",
        "  clamp_index_variation = clamp_index\n",
        "score_corrector = DotMap()\n",
        "\n",
        "\n",
        "def modify_score(e_t, e_t_uncond):\n",
        "        if(score_modifier is False):\n",
        "          return e_t\n",
        "        else:\n",
        "          e_t_d = (e_t - e_t_uncond)\n",
        "          s = torch.quantile(\n",
        "              rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "              threshold_percentile,\n",
        "              dim = -1\n",
        "          )\n",
        "\n",
        "        s.clamp_(min = 1.)\n",
        "        s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "        if ths_method == \"softsign\":\n",
        "            e_t_d = F.softsign(e_t_d) / s \n",
        "        elif ths_method == \"clamp\":\n",
        "            e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "        e_t = e_t_uncond + e_t_d\n",
        "        return(e_t)\n",
        "          \n",
        "score_corrector.modify_score = modify_score\n",
        "\n",
        "def dynamic_thresholding(pred_x0,t):\n",
        "    return(pred_x0)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "generate_video = False\n",
        "if generate_video: \n",
        "    fps = 24\n",
        "    p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "do_run()\n",
        "if generate_video: \n",
        "    p.stdin.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ZP5Z5N-Fccha"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#@markdown ### **Run 9.** Basic Settings\n",
        "\n",
        "width = 384 #@param{type: 'integer'}\n",
        "height = 256 #@param{type: 'integer'}\n",
        "\n",
        "clamp_index = [1, 1] #@param{type: 'raw'}\n",
        "\n",
        "latent_diffusion_guidance_scale = 13 #@param {type:\"number\"}\n",
        "clip_guidance_scale = 24000 #@param{type: 'integer'}\n",
        "\n",
        "how_many_batches =  1#@param{type: 'integer'}\n",
        "aesthetic_loss_scale =  1#@param{type: 'integer'}\n",
        "augment_cuts = True #@param{type:'boolean'}\n",
        "\n",
        "\n",
        "#@markdown ### Custom saved settings\n",
        "#@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "custom_settings = '' #@param{type:'string'}\n",
        "settings_library = 'makeitrad_defaults' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "if(settings_library != 'None (use settings defined above)'):\n",
        "  custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "global_var_scope = globals()\n",
        "if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "  print('Loaded ', custom_settings)\n",
        "  try:\n",
        "    from configparser import ConfigParser\n",
        "  except ImportError:\n",
        "      from ConfigParser import ConfigParser\n",
        "  import configparser\n",
        "  \n",
        "  config = ConfigParser()\n",
        "  config.read(custom_settings)\n",
        "  #custom_settings_stream = fetch(custom_settings)\n",
        "  #Load CLIP models from config\n",
        "  if(config.has_section('clip_list')):\n",
        "    clip_incoming_list = config.items('clip_list')\n",
        "    clip_incoming_models = clip_incoming_list[0]\n",
        "    incoming_perceptors = eval(clip_incoming_models[1])\n",
        "    if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "      clip_load_list = incoming_perceptors\n",
        "      clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "  #Load settings from config and replace variables\n",
        "  if(config.has_section('basic_settings')):\n",
        "    basic_settings = config.items('basic_settings')\n",
        "    for basic_setting in basic_settings:\n",
        "      global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "  \n",
        "  if(config.has_section('advanced_settings')):\n",
        "    advanced_settings = config.items('advanced_settings')\n",
        "    for advanced_setting in advanced_settings:\n",
        "      global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "  custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "prompts = clip_prompts\n",
        "opt.prompt = latent_prompts\n",
        "opt.uc = latent_negatives\n",
        "custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "aes_scale = aesthetic_loss_scale\n",
        "try: \n",
        "  clip_guidance_schedule\n",
        "  clip_guidance_index = clip_guidance_schedule\n",
        "except:\n",
        "  clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "opt.W = (width//64)*64;\n",
        "opt.H = (height//64)*64;\n",
        "if opt.W != width or opt.H != height:\n",
        "    print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "opt.mag_mul = opt_mag_mul \n",
        "opt.ddim_eta = opt_ddim_eta\n",
        "opt.eta_end = opt_eta_end\n",
        "opt.temperature = opt_temperature\n",
        "opt.n_iter = how_many_batches\n",
        "opt.n_samples =  1\n",
        "opt.scale = latent_diffusion_guidance_scale\n",
        "opt.plms = opt_plms\n",
        "aug = augment_cuts\n",
        "\n",
        "#Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "if(len(clamp_index) == 2): \n",
        "  clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "else:\n",
        "  clamp_index_variation = clamp_index\n",
        "score_corrector = DotMap()\n",
        "\n",
        "\n",
        "def modify_score(e_t, e_t_uncond):\n",
        "        if(score_modifier is False):\n",
        "          return e_t\n",
        "        else:\n",
        "          e_t_d = (e_t - e_t_uncond)\n",
        "          s = torch.quantile(\n",
        "              rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "              threshold_percentile,\n",
        "              dim = -1\n",
        "          )\n",
        "\n",
        "        s.clamp_(min = 1.)\n",
        "        s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "        if ths_method == \"softsign\":\n",
        "            e_t_d = F.softsign(e_t_d) / s \n",
        "        elif ths_method == \"clamp\":\n",
        "            e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "        e_t = e_t_uncond + e_t_d\n",
        "        return(e_t)\n",
        "          \n",
        "score_corrector.modify_score = modify_score\n",
        "\n",
        "def dynamic_thresholding(pred_x0,t):\n",
        "    return(pred_x0)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "generate_video = False\n",
        "if generate_video: \n",
        "    fps = 24\n",
        "    p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "do_run()\n",
        "if generate_video: \n",
        "    p.stdin.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "N5mB2Ucsccha"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#@markdown ### **Run 10.** Basic Settings\n",
        "\n",
        "width = 256 #@param{type: 'integer'}\n",
        "height = 384 #@param{type: 'integer'}\n",
        "\n",
        "clamp_index = [1, 1] #@param{type: 'raw'}\n",
        "\n",
        "latent_diffusion_guidance_scale = 14 #@param {type:\"number\"}\n",
        "clip_guidance_scale = 8000 #@param{type: 'integer'}\n",
        "\n",
        "how_many_batches = 1 #@param{type: 'integer'}\n",
        "aesthetic_loss_scale = 10 #@param{type: 'integer'}\n",
        "augment_cuts = True #@param{type:'boolean'}\n",
        "\n",
        "\n",
        "#@markdown ### Custom saved settings\n",
        "#@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "custom_settings = '' #@param{type:'string'}\n",
        "settings_library = 'makeitrad_defaults' #@param [\"None (use settings defined above)\", \"default\", \"defaults_v1_3\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\", \"coherent_pizzapigeon\", \"The_Vram_Goes_Brrrrrr\"]\n",
        "if(settings_library != 'None (use settings defined above)'):\n",
        "  custom_settings = f'latent-majesty-diffusion-settings/{settings_library}.cfg'\n",
        "\n",
        "global_var_scope = globals()\n",
        "if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "  print('Loaded ', custom_settings)\n",
        "  try:\n",
        "    from configparser import ConfigParser\n",
        "  except ImportError:\n",
        "      from ConfigParser import ConfigParser\n",
        "  import configparser\n",
        "  \n",
        "  config = ConfigParser()\n",
        "  config.read(custom_settings)\n",
        "  #custom_settings_stream = fetch(custom_settings)\n",
        "  #Load CLIP models from config\n",
        "  if(config.has_section('clip_list')):\n",
        "    clip_incoming_list = config.items('clip_list')\n",
        "    clip_incoming_models = clip_incoming_list[0]\n",
        "    incoming_perceptors = eval(clip_incoming_models[1])\n",
        "    if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "      clip_load_list = incoming_perceptors\n",
        "      clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "  #Load settings from config and replace variables\n",
        "  if(config.has_section('basic_settings')):\n",
        "    basic_settings = config.items('basic_settings')\n",
        "    for basic_setting in basic_settings:\n",
        "      global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "  \n",
        "  if(config.has_section('advanced_settings')):\n",
        "    advanced_settings = config.items('advanced_settings')\n",
        "    for advanced_setting in advanced_settings:\n",
        "      global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "  custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "prompts = clip_prompts\n",
        "opt.prompt = latent_prompts\n",
        "opt.uc = latent_negatives\n",
        "custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "aes_scale = aesthetic_loss_scale\n",
        "try: \n",
        "  clip_guidance_schedule\n",
        "  clip_guidance_index = clip_guidance_schedule\n",
        "except:\n",
        "  clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "opt.W = (width//64)*64;\n",
        "opt.H = (height//64)*64;\n",
        "if opt.W != width or opt.H != height:\n",
        "    print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "opt.mag_mul = opt_mag_mul \n",
        "opt.ddim_eta = opt_ddim_eta\n",
        "opt.eta_end = opt_eta_end\n",
        "opt.temperature = opt_temperature\n",
        "opt.n_iter = how_many_batches\n",
        "opt.n_samples =  1\n",
        "opt.scale = latent_diffusion_guidance_scale\n",
        "opt.plms = opt_plms\n",
        "aug = augment_cuts\n",
        "\n",
        "#Checks if it's not a normal schedule (legacy purposes to keep old configs compatible)\n",
        "if(len(clamp_index) == 2): \n",
        "  clamp_index_variation = np.linspace(clamp_index[0],clamp_index[1],1000) \n",
        "\n",
        "else:\n",
        "  clamp_index_variation = clamp_index\n",
        "score_corrector = DotMap()\n",
        "\n",
        "\n",
        "def modify_score(e_t, e_t_uncond):\n",
        "        if(score_modifier is False):\n",
        "          return e_t\n",
        "        else:\n",
        "          e_t_d = (e_t - e_t_uncond)\n",
        "          s = torch.quantile(\n",
        "              rearrange(e_t_d, 'b ... -> b (...)').abs().float(),\n",
        "              threshold_percentile,\n",
        "              dim = -1\n",
        "          )\n",
        "\n",
        "        s.clamp_(min = 1.)\n",
        "        s = s.view(-1, *((1,) * (e_t_d.ndim - 1)))\n",
        "        if ths_method == \"softsign\":\n",
        "            e_t_d = F.softsign(e_t_d) / s \n",
        "        elif ths_method == \"clamp\":\n",
        "            e_t_d = e_t_d.clamp(-s,s) / s * 1.3#1.2\n",
        "        e_t = e_t_uncond + e_t_d\n",
        "        return(e_t)\n",
        "          \n",
        "score_corrector.modify_score = modify_score\n",
        "\n",
        "def dynamic_thresholding(pred_x0,t):\n",
        "    return(pred_x0)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "generate_video = False\n",
        "if generate_video: \n",
        "    fps = 24\n",
        "    p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "do_run()\n",
        "if generate_video: \n",
        "    p.stdin.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVzXRDNo-Eqq"
      },
      "source": [
        "### Optional final steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "r2xJAfK7-Eqr"
      },
      "outputs": [],
      "source": [
        "\n",
        "#@markdown ### Save current settings\n",
        "#@markdown If you would like to save your current settings, uncheck `skip_saving` and run this cell. You will get a `custom_settings.cfg` file you can reuse and share. If you like your results, <a href=\"https://huggingface.co/datasets/multimodalart/latent-majesty-diffusion-settings\">share your settings with us on the settings library</a>\n",
        "\n",
        "#@markdown 📯😇 NOTICE: As arranged now, \"run all\" will save only the final cell's config. 👼🎺\n",
        "\n",
        "skip_saving = True #@param{type:'boolean'}\n",
        "if(not skip_saving):\n",
        "  data = generate_settings_file(add_prompts=False, add_dimensions=True)\n",
        "  text_file = open(\"custom_settings.cfg\", \"w\")\n",
        "  text_file.write(data)\n",
        "  text_file.close()\n",
        "  from google.colab import files\n",
        "  files.download('custom_settings.cfg')\n",
        "  print(\"Downloaded as custom_settings.cfg\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Send SMS on task completion\n",
        "\n",
        "#This site allows one free test message per day. May need new solution at some point.\n",
        "\n",
        "skip_SMS = True #@param{type:'boolean'}\n",
        "if(not skip_SMS):\n",
        "  import requests\n",
        "  resp = requests.post('https://textbelt.com/text', {\n",
        "    'phone': '', #enter your phone number\n",
        "    'message': 'Majesty Diffusion run completed successfully!',\n",
        "    'key': 'textbelt',\n",
        "  })\n",
        "  print(resp.json())"
      ],
      "metadata": {
        "cellView": "form",
        "id": "HGZjJXfAWtn6"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "WOAs3ZvLlktt",
        "2rAtY_wqZKSr",
        "uWLsDt7wkZfU",
        "xEVSOJ4f0B21",
        "VpR9JhyCu5iq",
        "N_Di3xFSXGWe",
        "X6MoCizPf-T9",
        "qIyeqAsO12sE",
        "hz-UUtoZLCzG",
        "P0w6W3qub2sP",
        "GwaBYdaVb3A2",
        "PzhuRi7zb3P7",
        "6uTfUl4Fb3dz",
        "P1QfynymcMTp",
        "NDwZtERfcchW",
        "yVzXRDNo-Eqq"
      ],
      "machine_shape": "hm",
      "name": "Majesty Diffusion Virgin Edition",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
